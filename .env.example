# AI-Augmented Personal Archive - Environment Configuration
# Copy this file to .env and customize the values for your setup

# ============================================
# AI MODEL CONFIGURATION
# ============================================

# Local LLM model for narrative generation
LOCAL_LLM_MODEL=microsoft/DialoGPT-medium

# Embedding model for semantic search
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Text-to-speech model
TTS_MODEL=espnet/kan-bayashi_ljspeech_vits

# Multimodal model for image understanding
MULTIMODAL_MODEL=openai/clip-vit-base-patch32

# ============================================
# AI PROCESSING CONFIGURATION
# ============================================

# Batch size for AI processing
AI_PROCESSING_BATCH_SIZE=32

# Maximum memory usage for AI models (in GB)
AI_MAX_MEMORY_GB=4

# Enable GPU acceleration (requires NVIDIA Docker)
ENABLE_GPU=false

# ============================================
# FEATURE TOGGLES
# ============================================

# Enable AI enhancement during ingestion
ENABLE_AI_ENHANCEMENT=true

# Enable enhanced QA with AI services
ENHANCED_QA_ENABLED=true

# ============================================
# EXTERNAL API KEYS (Optional)
# ============================================

# OpenAI API key (for fallback when local models fail)
OPENAI_API_KEY=

# ============================================
# DEVELOPMENT SETTINGS
# ============================================

# Enable debug logging
DEBUG_LOGGING=false

# Skip model downloads (for development)
SKIP_MODEL_DOWNLOADS=false