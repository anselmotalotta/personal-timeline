# ğŸ“Š Personal Timeline Project Analysis

## ğŸ¯ What This Project Does

**TimelineBuilder** is a Facebook Research project that creates a **searchable personal timeline** from your digital data across multiple services (Google Photos, Spotify, Amazon, Facebook, etc.).

### Key Features:
1. **Data Ingestion** - Import data from 9+ sources
2. **Enrichment** - Add AI-powered metadata (object detection, OCR, geolocation)
3. **Visualization** - ReactJS frontend to browse your timeline
4. **Question Answering** - LLM-powered QA system to query your personal data

---

## ğŸ—ï¸ Architecture

### Three Main Components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCKER COMPOSE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   BACKEND    â”‚  â”‚   FRONTEND   â”‚  â”‚      QA      â”‚ â”‚
â”‚  â”‚  (Ingestion) â”‚  â”‚   (ReactJS)  â”‚  â”‚  (PostText)  â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ Port: N/A    â”‚  â”‚ Port: 3000   â”‚  â”‚ Port: 8085   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                  â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                            â”‚                            â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                     â”‚  SQLite DB    â”‚                   â”‚
â”‚                     â”‚ (raw_data.db) â”‚                   â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
personal-timeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest/               # Backend: Data importers & enrichment
â”‚   â”‚   â”œâ”€â”€ importers/        # 9+ data source importers
â”‚   â”‚   â”‚   â”œâ”€â”€ create_facebook_LLEntries.py
â”‚   â”‚   â”‚   â”œâ”€â”€ create_google_photo_LLEntries.py
â”‚   â”‚   â”‚   â”œâ”€â”€ create_amazon_LLEntries.py
â”‚   â”‚   â”‚   â””â”€â”€ ... (more importers)
â”‚   â”‚   â”œâ”€â”€ enrichment/       # AI-powered enrichment
â”‚   â”‚   â”‚   â”œâ”€â”€ image_enrichment.py (object detection)
â”‚   â”‚   â”‚   â”œâ”€â”€ geo_enrichment.py (location data)
â”‚   â”‚   â”‚   â””â”€â”€ socratic/ (CLIP-based image understanding)
â”‚   â”‚   â””â”€â”€ derive_episodes.py # Group entries into episodes
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend/             # ReactJS visualization UI
â”‚   â”‚   â””â”€â”€ (React components for timeline view)
â”‚   â”‚
â”‚   â””â”€â”€ qa/                   # PostText QA engine
â”‚       â””â”€â”€ (LLM-based question answering)
â”‚
â”œâ”€â”€ personal-data/            # User data directory (created in ~/personal-data)
â”‚   â”œâ”€â”€ google_photos/
â”‚   â”œâ”€â”€ facebook/
â”‚   â”œâ”€â”€ spotify/
â”‚   â”œâ”€â”€ amazon/
â”‚   â””â”€â”€ app_data/            # Processed data (SQLite DB + CSVs)
â”‚
â”œâ”€â”€ sample_data/             # Anonymized test dataset
â”œâ”€â”€ notebooks/               # Jupyter tutorials
â”œâ”€â”€ docker-compose.yml       # Orchestration
â””â”€â”€ conf/ingest.conf        # Configuration
```

---

## ğŸ”„ Data Flow

### 1. Data Ingestion Pipeline

```
Raw Data (JSON/CSV/XML)
    â†“
Importers (parse & normalize)
    â†“
SQLite DB (raw_data.db)
    â†“
Enrichment (AI analysis)
    â†“
Episodes (grouped events)
    â†“
CSV exports + DB
```

### 2. Supported Data Sources

| Source | Input Format | Key Data | Notes |
|--------|-------------|----------|-------|
| **Facebook** | JSON (from Download Your Information) | Posts + Photos | âœ… Uses official FB export! |
| **Google Photos** | Takeout ZIP | Photos + metadata | Includes EXIF, location |
| **Google Timeline** | Takeout JSON | Location history | Semantic locations |
| **Spotify** | JSON export | Streaming history | Songs, albums, artists |
| **Amazon** | CSV | Purchase history | Retail orders |
| **Kindle** | CSV | Books | Digital purchases |
| **Apple Health** | XML | Exercise, calories | iWatch data |
| **Venmo** | CSV | Transactions | Payment history |
| **Libby** | JSON | Library books | Borrowed books |

---

## ğŸ¤– AI/ML Components

### 1. Image Enrichment (`image_enrichment.py`)
- **Object Detection** - Detects objects in photos
- **OCR** - Extracts text from images
- Uses pre-trained models (CLIP, vision transformers)

### 2. Socratic Module (`socratic/`)
- CLIP-based image understanding
- Generates natural language descriptions
- Extracts visual features for search

### 3. Geo Enrichment (`geo_enrichment.py`)
- Reverse geocoding (lat/long â†’ address)
- Timezone detection
- Location clustering

### 4. PostText QA Engine
- Three modes:
  - **ChatGPT** - General knowledge (no personal context)
  - **Retrieval-based** - Top-k relevant episodes
  - **View-based** - SQL queries over tabular data
- Can answer:
  - "Show me photos of plants in my neighborhood"
  - "How many books did I buy in April?"
  - "When did I last travel to Japan?"

---

## ğŸ”§ Key Technologies

- **Backend**: Python 3.10
- **Frontend**: ReactJS
- **Database**: SQLite
- **ML Libraries**: 
  - PyTorch, torchvision
  - Transformers (Hugging Face)
  - CLIP (OpenAI)
  - sentence-transformers
  - FAISS (vector search)
- **LLM Integration**: 
  - OpenAI API (GPT-3.5-turbo, GPT-4)
  - LangChain
- **Containerization**: Docker + Docker Compose
- **APIs Used**:
  - Google Maps API
  - Spotify API
  - OpenAI API

---

## ğŸ“Š Database Schema

The project creates:
1. **SQLite DB** (`raw_data.db`) - Raw imported data
2. **CSV Exports** - Processed views:
   - `books.csv`
   - `exercise.csv`
   - `photos.csv`
   - `places.csv`
   - `purchase.csv`
   - `streaming.csv`
   - `trips.csv`

---

## ğŸš€ How It Works (Step-by-Step)

### Setup Phase:
1. User runs `init.sh` â†’ creates `~/personal-data/` directory
2. User downloads data from services (FB, Google, Spotify, etc.)
3. User places data in appropriate folders
4. User sets API keys (Google Maps, Spotify, OpenAI)

### Ingestion Phase:
1. Run `docker-compose up -d backend`
2. Backend reads data from `personal-data/` folders
3. Importers parse each data source
4. Data is normalized and stored in SQLite
5. Enrichment runs (AI analysis on photos)
6. Episodes are derived (grouping related events)
7. CSV exports are generated

### Usage Phase:
1. **Visualization**: Browse timeline at `http://localhost:3000`
2. **QA**: Ask questions at `http://localhost:8085`

---

## âœ… Is It Working?

### Project Status: **ARCHIVED**

**Good News:**
- âœ… Complete, well-documented codebase
- âœ… Sample data provided for testing
- âœ… Docker setup simplifies deployment
- âœ… **FACEBOOK IMPORTER EXISTS** and uses official FB export!

**Potential Issues:**
- âš ï¸ Archived = No active maintenance
- âš ï¸ Dependencies may be outdated (OpenAI 0.28.1 is old)
- âš ï¸ Some API endpoints might have changed
- âš ï¸ Docker images need to be built (not pre-built)

**Can We Run It?**
- **YES**, but may need:
  - Dependency updates (OpenAI library v1.x is current, code uses 0.28.1)
  - API key updates
  - Docker Desktop installed
  - Sample data for testing (provided in repo)

---

## ğŸ¯ Most Relevant to Your Use Case

### **FACEBOOK POSTS IMPORTER** (`create_facebook_LLEntries.py`)

**How it works:**
1. Expects Facebook data from "Download Your Information" feature
2. Reads JSON files from `~/personal-data/facebook/posts/`
3. Extracts:
   - Posts with timestamps
   - Photos with EXIF data
   - Tagged people
   - GPS coordinates (if available)
4. Stores in SQLite for searching

**Key Code:**
```python
# Reads JSON files from Facebook export
json_files = self.get_type_files_deep(json_filepath, ...)
for json_file in json_files:
    post_data = json.loads(r)
    # Extracts media with timestamps
    all_media = self.find_all_in_haystack("timestamp", post_data, True)
    # Creates searchable entries
    obj = self.create_LLEntry(uri, latitude, longitude, taken_timestamp, tagged_people)
```

---

## ğŸ§ª Testing Strategy

### Option 1: Use Sample Data (Fastest)
The repo includes anonymized sample data in `sample_data/`:
- Pre-processed SQLite DB
- Sample CSVs
- Test images

### Option 2: Test with Your Facebook Export
1. Download your Facebook data (JSON format)
2. Place in `~/personal-data/facebook/posts/`
3. Run the backend ingestion
4. See if it parses correctly

---

## ğŸ” Next Steps

### To Test If It Works:

1. **Check sample data** (no setup needed)
2. **Run with Docker** (requires Docker Desktop)
3. **Try notebooks** (easier than full Docker setup)

**Which would you like to try first?**

---

## ğŸ’¡ Key Insights

1. **This is EXACTLY what you needed!** - Parses Facebook export (the "Download Your Information" feature)
2. **No API needed** - Uses your downloaded data directly
3. **More than posts** - Also handles photos, location, enrichment
4. **QA system** - Can search/query your posts naturally
5. **Production-quality** - From Facebook Research, well-architected

---

## âš ï¸ Limitations

1. **Archived** - No updates since archival
2. **Setup complexity** - Requires Docker, multiple API keys
3. **Heavy dependencies** - PyTorch, CLIP, transformers (large downloads)
4. **Privacy** - Runs locally but uses OpenAI API (data leaves machine)
5. **FB export only** - Can't fetch live data (but that's what you wanted!)

---

## ğŸ¤” Verdict

**Is it complete?** YES - Full working system

**Does it work?** PROBABLY - May need minor updates

**Is it useful?** YES - Does exactly what you need for Facebook posts

**Worth testing?** ABSOLUTELY - Best solution for parsing FB exports

