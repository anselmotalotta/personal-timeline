# Epic 1.2.2: Media Processing Infrastructure

**Phase**: 1 - Foundation & Core Infrastructure  
**Epic**: 1.2.2 Media Processing Infrastructure  
**Duration**: 2 weeks  
**Team Size**: 2 developers (Backend + Media Processing)  

---

## Goal

Build a comprehensive media processing infrastructure that can handle image and video files from various sources, extract metadata, generate thumbnails, perform AI-powered analysis (object detection, face recognition, scene analysis), and optimize storage while maintaining privacy and performance.

---

## Scope Assumptions

### Media Types & Formats
- **Images**: JPEG, PNG, GIF, WebP, HEIC, RAW formats
- **Videos**: MP4, MOV, AVI, MKV, WebM, M4V
- **Size Limits**: Up to 100MB per file, 10GB total per user initially
- **Resolution**: Support up to 4K images, 1080p videos

### Processing Capabilities
- **Metadata Extraction**: EXIF, GPS, camera info, timestamps
- **Thumbnail Generation**: Multiple sizes (150px, 300px, 600px)
- **AI Analysis**: Object detection, face recognition, scene classification
- **Optimization**: Compression, format conversion, progressive loading
- **Privacy**: Face blurring, location scrubbing, content filtering

### Storage Strategy
- **Original Files**: Preserved in original format
- **Processed Files**: Optimized versions for web display
- **Thumbnails**: Multiple sizes for different use cases
- **Metadata**: Structured data in database
- **CDN Integration**: Fast global delivery

---

## Success Criteria

- [ ] **Format Support**: Handle 95%+ of common image/video formats
- [ ] **Processing Speed**: < 30 seconds for images, < 2 minutes for videos
- [ ] **Quality Preservation**: Maintain visual quality while optimizing size
- [ ] **AI Accuracy**: 90%+ accuracy in object/face detection
- [ ] **Thumbnail Generation**: Multiple sizes generated automatically
- [ ] **Metadata Extraction**: Complete EXIF and technical metadata
- [ ] **Privacy Protection**: Configurable privacy features working correctly
- [ ] **Storage Optimization**: 50%+ size reduction while maintaining quality

---

## Non-Goals

- Real-time video streaming or live processing
- Advanced video editing capabilities
- 3D model or AR content processing
- Professional RAW photo editing features
- Social media-style filters and effects

---

## Risks & Mitigations

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Large file processing memory issues | High | Medium | Streaming processing, memory monitoring, chunked operations |
| AI model accuracy for personal photos | Medium | Medium | Multiple model ensemble, confidence scoring, manual review |
| Storage costs for large media collections | Medium | High | Intelligent compression, tiered storage, user quotas |
| Privacy violations in AI analysis | High | Low | Local processing options, data anonymization, user consent |
| Processing bottlenecks under load | Medium | Medium | Queue management, horizontal scaling, priority processing |

---

## Detailed Tasks

### Task 1: Core Media Processing Engine

#### 1.1 Media File Handler & Format Detection

**Media File Manager (apps/worker/media/file_manager.py):**
```python
import logging
import mimetypes
import hashlib
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import asyncio
from concurrent.futures import ThreadPoolExecutor
import magic
from PIL import Image, ExifTags
import cv2
import ffmpeg
from datetime import datetime
import json

logger = logging.getLogger(__name__)

class MediaFileInfo:
    """Container for media file information"""
    
    def __init__(self):
        self.file_path: str = ""
        self.file_size: int = 0
        self.mime_type: str = ""
        self.file_type: str = ""  # 'image' or 'video'
        self.format: str = ""
        self.dimensions: Optional[Tuple[int, int]] = None
        self.duration: Optional[float] = None
        self.checksum: str = ""
        self.created_at: Optional[datetime] = None
        self.modified_at: Optional[datetime] = None
        self.is_valid: bool = False
        self.error_message: str = ""

class MediaFileManager:
    """Manage media file operations and metadata extraction"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # Supported formats
        self.supported_image_formats = {
            'image/jpeg', 'image/jpg', 'image/png', 'image/gif', 
            'image/webp', 'image/bmp', 'image/tiff', 'image/heic'
        }
        
        self.supported_video_formats = {
            'video/mp4', 'video/quicktime', 'video/x-msvideo',
            'video/x-matroska', 'video/webm', 'video/x-m4v'
        }
        
        # Size limits
        self.max_image_size = 100 * 1024 * 1024  # 100MB
        self.max_video_size = 500 * 1024 * 1024  # 500MB
        self.max_image_dimensions = (8192, 8192)  # 8K max
        
        # Magic number detector for accurate file type detection
        self.magic = magic.Magic(mime=True)
    
    async def analyze_file(self, file_path: str) -> MediaFileInfo:
        """Analyze media file and extract basic information"""
        
        info = MediaFileInfo()
        info.file_path = file_path
        
        try:
            file_path_obj = Path(file_path)
            
            if not file_path_obj.exists():
                info.error_message = "File does not exist"
                return info
            
            # Basic file info
            stat = file_path_obj.stat()
            info.file_size = stat.st_size
            info.created_at = datetime.fromtimestamp(stat.st_ctime)
            info.modified_at = datetime.fromtimestamp(stat.st_mtime)
            
            # Generate checksum
            info.checksum = await self._calculate_checksum(file_path)
            
            # Detect MIME type using magic numbers
            loop = asyncio.get_event_loop()
            info.mime_type = await loop.run_in_executor(
                self.executor, self._detect_mime_type, file_path
            )
            
            # Determine file type
            if info.mime_type in self.supported_image_formats:
                info.file_type = "image"
                info.format = info.mime_type.split('/')[-1]
                
                # Validate size limits
                if info.file_size > self.max_image_size:
                    info.error_message = f"Image file too large: {info.file_size} bytes"
                    return info
                
                # Extract image-specific info
                await self._analyze_image(file_path, info)
                
            elif info.mime_type in self.supported_video_formats:
                info.file_type = "video"
                info.format = info.mime_type.split('/')[-1]
                
                # Validate size limits
                if info.file_size > self.max_video_size:
                    info.error_message = f"Video file too large: {info.file_size} bytes"
                    return info
                
                # Extract video-specific info
                await self._analyze_video(file_path, info)
                
            else:
                info.error_message = f"Unsupported file type: {info.mime_type}"
                return info
            
            info.is_valid = True
            logger.debug(f"Analyzed file: {file_path} - {info.file_type} {info.dimensions}")
            
        except Exception as e:
            logger.error(f"Error analyzing file {file_path}: {e}")
            info.error_message = str(e)
        
        return info
    
    def _detect_mime_type(self, file_path: str) -> str:
        """Detect MIME type using magic numbers"""
        try:
            # Use python-magic for accurate detection
            mime_type = self.magic.from_file(file_path)
            
            # Fallback to mimetypes module
            if not mime_type or mime_type == 'application/octet-stream':
                mime_type, _ = mimetypes.guess_type(file_path)
            
            return mime_type or 'application/octet-stream'
            
        except Exception as e:
            logger.warning(f"Error detecting MIME type for {file_path}: {e}")
            # Final fallback
            mime_type, _ = mimetypes.guess_type(file_path)
            return mime_type or 'application/octet-stream'
    
    async def _analyze_image(self, file_path: str, info: MediaFileInfo):
        """Analyze image file"""
        
        loop = asyncio.get_event_loop()
        
        try:
            # Use PIL to get image info
            with Image.open(file_path) as img:
                info.dimensions = img.size
                info.format = img.format.lower() if img.format else info.format
                
                # Validate dimensions
                if (info.dimensions[0] > self.max_image_dimensions[0] or 
                    info.dimensions[1] > self.max_image_dimensions[1]):
                    info.error_message = f"Image dimensions too large: {info.dimensions}"
                    info.is_valid = False
                    return
                
                # Check if image is corrupted by trying to load it
                try:
                    img.verify()
                except Exception:
                    # Re-open for further processing since verify() closes the image
                    img = Image.open(file_path)
                
        except Exception as e:
            logger.error(f"Error analyzing image {file_path}: {e}")
            info.error_message = f"Invalid image file: {str(e)}"
            info.is_valid = False
    
    async def _analyze_video(self, file_path: str, info: MediaFileInfo):
        """Analyze video file"""
        
        loop = asyncio.get_event_loop()
        
        try:
            # Use OpenCV to get basic video info
            cap = cv2.VideoCapture(file_path)
            
            if not cap.isOpened():
                info.error_message = "Cannot open video file"
                info.is_valid = False
                return
            
            # Get video properties
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            info.dimensions = (width, height)
            
            if fps > 0:
                info.duration = frame_count / fps
            
            cap.release()
            
            # Validate video
            if width <= 0 or height <= 0:
                info.error_message = "Invalid video dimensions"
                info.is_valid = False
                return
            
            if info.duration and info.duration > 3600:  # 1 hour max
                info.error_message = "Video too long (max 1 hour)"
                info.is_valid = False
                return
                
        except Exception as e:
            logger.error(f"Error analyzing video {file_path}: {e}")
            info.error_message = f"Invalid video file: {str(e)}"
            info.is_valid = False
    
    async def _calculate_checksum(self, file_path: str) -> str:
        """Calculate SHA-256 checksum of file"""
        
        loop = asyncio.get_event_loop()
        
        def _hash_file():
            hash_sha256 = hashlib.sha256()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        
        return await loop.run_in_executor(self.executor, _hash_file)
    
    async def validate_file_integrity(self, file_path: str, expected_checksum: str) -> bool:
        """Validate file integrity using checksum"""
        
        actual_checksum = await self._calculate_checksum(file_path)
        return actual_checksum == expected_checksum
    
    def get_supported_formats(self) -> Dict[str, List[str]]:
        """Get list of supported formats"""
        
        return {
            "images": list(self.supported_image_formats),
            "videos": list(self.supported_video_formats)
        }
    
    async def cleanup_temp_files(self, temp_dir: str):
        """Clean up temporary files"""
        
        try:
            temp_path = Path(temp_dir)
            if temp_path.exists() and temp_path.is_dir():
                for file_path in temp_path.rglob("*"):
                    if file_path.is_file():
                        file_path.unlink()
                temp_path.rmdir()
                logger.debug(f"Cleaned up temp directory: {temp_dir}")
        except Exception as e:
            logger.error(f"Error cleaning up temp files: {e}")
```

**Metadata Extractor (apps/worker/media/metadata_extractor.py):**
```python
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
import asyncio
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
import json

from PIL import Image, ExifTags
from PIL.ExifTags import TAGS, GPSTAGS
import cv2
import ffmpeg
from geopy.geocoders import Nominatim
import exifread

logger = logging.getLogger(__name__)

class MediaMetadataExtractor:
    """Extract comprehensive metadata from media files"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=2)
        self.geocoder = Nominatim(user_agent="personal-timeline")
    
    async def extract_image_metadata(self, file_path: str) -> Dict[str, Any]:
        """Extract comprehensive metadata from image file"""
        
        metadata = {
            "exif": {},
            "camera": {},
            "location": {},
            "technical": {},
            "timestamps": {},
            "processing_info": {}
        }
        
        try:
            loop = asyncio.get_event_loop()
            
            # Extract EXIF data using PIL
            pil_exif = await loop.run_in_executor(
                self.executor, self._extract_pil_exif, file_path
            )
            metadata["exif"].update(pil_exif)
            
            # Extract additional EXIF data using exifread
            exifread_data = await loop.run_in_executor(
                self.executor, self._extract_exifread_data, file_path
            )
            metadata["exif"].update(exifread_data)
            
            # Process camera information
            metadata["camera"] = self._process_camera_info(metadata["exif"])
            
            # Process location information
            metadata["location"] = await self._process_location_info(metadata["exif"])
            
            # Process timestamps
            metadata["timestamps"] = self._process_timestamps(metadata["exif"])
            
            # Technical information
            metadata["technical"] = await self._extract_technical_info(file_path)
            
            logger.debug(f"Extracted image metadata for {file_path}")
            
        except Exception as e:
            logger.error(f"Error extracting image metadata from {file_path}: {e}")
            metadata["processing_info"]["error"] = str(e)
        
        return metadata
    
    async def extract_video_metadata(self, file_path: str) -> Dict[str, Any]:
        """Extract comprehensive metadata from video file"""
        
        metadata = {
            "video": {},
            "audio": {},
            "technical": {},
            "timestamps": {},
            "location": {},
            "processing_info": {}
        }
        
        try:
            loop = asyncio.get_event_loop()
            
            # Extract using ffprobe
            ffprobe_data = await loop.run_in_executor(
                self.executor, self._extract_ffprobe_data, file_path
            )
            
            # Process video stream info
            metadata["video"] = self._process_video_stream_info(ffprobe_data)
            
            # Process audio stream info
            metadata["audio"] = self._process_audio_stream_info(ffprobe_data)
            
            # Process technical info
            metadata["technical"] = self._process_video_technical_info(ffprobe_data)
            
            # Process timestamps
            metadata["timestamps"] = self._process_video_timestamps(ffprobe_data)
            
            # Extract location from metadata if available
            metadata["location"] = await self._process_video_location_info(ffprobe_data)
            
            logger.debug(f"Extracted video metadata for {file_path}")
            
        except Exception as e:
            logger.error(f"Error extracting video metadata from {file_path}: {e}")
            metadata["processing_info"]["error"] = str(e)
        
        return metadata
    
    def _extract_pil_exif(self, file_path: str) -> Dict[str, Any]:
        """Extract EXIF data using PIL"""
        
        exif_data = {}
        
        try:
            with Image.open(file_path) as img:
                exif = img.getexif()
                
                if exif:
                    for tag_id, value in exif.items():
                        tag = TAGS.get(tag_id, tag_id)
                        
                        # Handle GPS info separately
                        if tag == "GPSInfo":
                            gps_data = {}
                            for gps_tag_id, gps_value in value.items():
                                gps_tag = GPSTAGS.get(gps_tag_id, gps_tag_id)
                                gps_data[gps_tag] = gps_value
                            exif_data["GPSInfo"] = gps_data
                        else:
                            # Convert bytes to string for JSON serialization
                            if isinstance(value, bytes):
                                try:
                                    value = value.decode('utf-8')
                                except UnicodeDecodeError:
                                    value = str(value)
                            
                            exif_data[tag] = value
                            
        except Exception as e:
            logger.warning(f"Error extracting PIL EXIF from {file_path}: {e}")
        
        return exif_data
    
    def _extract_exifread_data(self, file_path: str) -> Dict[str, Any]:
        """Extract additional EXIF data using exifread"""
        
        exif_data = {}
        
        try:
            with open(file_path, 'rb') as f:
                tags = exifread.process_file(f, details=False)
                
                for tag, value in tags.items():
                    # Skip thumbnail data
                    if 'thumbnail' in tag.lower():
                        continue
                    
                    # Convert to string for JSON serialization
                    exif_data[tag] = str(value)
                    
        except Exception as e:
            logger.warning(f"Error extracting exifread data from {file_path}: {e}")
        
        return exif_data
    
    def _extract_ffprobe_data(self, file_path: str) -> Dict[str, Any]:
        """Extract video metadata using ffprobe"""
        
        try:
            probe = ffmpeg.probe(file_path)
            return probe
        except Exception as e:
            logger.error(f"Error running ffprobe on {file_path}: {e}")
            return {}
    
    def _process_camera_info(self, exif_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process camera-related information from EXIF"""
        
        camera_info = {}
        
        # Camera make and model
        if "Make" in exif_data:
            camera_info["make"] = exif_data["Make"]
        if "Model" in exif_data:
            camera_info["model"] = exif_data["Model"]
        
        # Lens information
        if "LensModel" in exif_data:
            camera_info["lens_model"] = exif_data["LensModel"]
        if "LensMake" in exif_data:
            camera_info["lens_make"] = exif_data["LensMake"]
        
        # Camera settings
        if "FNumber" in exif_data:
            camera_info["aperture"] = exif_data["FNumber"]
        if "ExposureTime" in exif_data:
            camera_info["shutter_speed"] = exif_data["ExposureTime"]
        if "ISOSpeedRatings" in exif_data:
            camera_info["iso"] = exif_data["ISOSpeedRatings"]
        if "FocalLength" in exif_data:
            camera_info["focal_length"] = exif_data["FocalLength"]
        
        # Flash information
        if "Flash" in exif_data:
            camera_info["flash"] = exif_data["Flash"]
        
        # White balance
        if "WhiteBalance" in exif_data:
            camera_info["white_balance"] = exif_data["WhiteBalance"]
        
        return camera_info
    
    async def _process_location_info(self, exif_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process GPS location information from EXIF"""
        
        location_info = {}
        
        try:
            gps_info = exif_data.get("GPSInfo", {})
            
            if not gps_info:
                return location_info
            
            # Extract coordinates
            lat, lon = self._extract_gps_coordinates(gps_info)
            
            if lat is not None and lon is not None:
                location_info["latitude"] = lat
                location_info["longitude"] = lon
                
                # Reverse geocoding to get address
                try:
                    location = await asyncio.get_event_loop().run_in_executor(
                        self.executor, self.geocoder.reverse, f"{lat}, {lon}"
                    )
                    
                    if location:
                        location_info["address"] = location.address
                        
                        # Extract address components
                        if hasattr(location, 'raw') and 'address' in location.raw:
                            address_components = location.raw['address']
                            location_info["city"] = address_components.get('city', '')
                            location_info["state"] = address_components.get('state', '')
                            location_info["country"] = address_components.get('country', '')
                            
                except Exception as e:
                    logger.warning(f"Error in reverse geocoding: {e}")
            
            # GPS altitude
            if "GPSAltitude" in gps_info:
                location_info["altitude"] = gps_info["GPSAltitude"]
            
            # GPS timestamp
            if "GPSTimeStamp" in gps_info and "GPSDateStamp" in gps_info:
                try:
                    gps_time = gps_info["GPSTimeStamp"]
                    gps_date = gps_info["GPSDateStamp"]
                    
                    # Combine date and time
                    if isinstance(gps_time, (list, tuple)) and len(gps_time) >= 3:
                        time_str = f"{int(gps_time[0]):02d}:{int(gps_time[1]):02d}:{int(gps_time[2]):02d}"
                        datetime_str = f"{gps_date} {time_str}"
                        location_info["gps_timestamp"] = datetime_str
                        
                except Exception as e:
                    logger.warning(f"Error processing GPS timestamp: {e}")
                    
        except Exception as e:
            logger.error(f"Error processing location info: {e}")
        
        return location_info
    
    def _extract_gps_coordinates(self, gps_info: Dict[str, Any]) -> tuple:
        """Extract latitude and longitude from GPS info"""
        
        try:
            lat_ref = gps_info.get("GPSLatitudeRef", "N")
            lat_data = gps_info.get("GPSLatitude")
            lon_ref = gps_info.get("GPSLongitudeRef", "E")
            lon_data = gps_info.get("GPSLongitude")
            
            if not lat_data or not lon_data:
                return None, None
            
            # Convert DMS to decimal degrees
            def dms_to_decimal(dms_data, ref):
                if isinstance(dms_data, (list, tuple)) and len(dms_data) >= 3:
                    degrees = float(dms_data[0])
                    minutes = float(dms_data[1])
                    seconds = float(dms_data[2])
                    
                    decimal = degrees + minutes/60 + seconds/3600
                    
                    if ref in ['S', 'W']:
                        decimal = -decimal
                    
                    return decimal
                return None
            
            latitude = dms_to_decimal(lat_data, lat_ref)
            longitude = dms_to_decimal(lon_data, lon_ref)
            
            return latitude, longitude
            
        except Exception as e:
            logger.error(f"Error extracting GPS coordinates: {e}")
            return None, None
    
    def _process_timestamps(self, exif_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process timestamp information from EXIF"""
        
        timestamps = {}
        
        # Original date/time
        if "DateTime" in exif_data:
            timestamps["datetime"] = exif_data["DateTime"]
        
        # Original date/time
        if "DateTimeOriginal" in exif_data:
            timestamps["datetime_original"] = exif_data["DateTimeOriginal"]
        
        # Digitized date/time
        if "DateTimeDigitized" in exif_data:
            timestamps["datetime_digitized"] = exif_data["DateTimeDigitized"]
        
        # Subsecond information
        if "SubSecTime" in exif_data:
            timestamps["subsec_time"] = exif_data["SubSecTime"]
        if "SubSecTimeOriginal" in exif_data:
            timestamps["subsec_time_original"] = exif_data["SubSecTimeOriginal"]
        if "SubSecTimeDigitized" in exif_data:
            timestamps["subsec_time_digitized"] = exif_data["SubSecTimeDigitized"]
        
        return timestamps
    
    async def _extract_technical_info(self, file_path: str) -> Dict[str, Any]:
        """Extract technical information about the image"""
        
        technical_info = {}
        
        try:
            with Image.open(file_path) as img:
                technical_info["format"] = img.format
                technical_info["mode"] = img.mode
                technical_info["size"] = img.size
                
                # Color profile information
                if hasattr(img, 'info'):
                    if 'icc_profile' in img.info:
                        technical_info["has_color_profile"] = True
                    if 'transparency' in img.info:
                        technical_info["has_transparency"] = True
                
                # Animation info for GIFs
                if img.format == 'GIF':
                    technical_info["is_animated"] = getattr(img, 'is_animated', False)
                    if technical_info["is_animated"]:
                        technical_info["n_frames"] = getattr(img, 'n_frames', 1)
                        
        except Exception as e:
            logger.error(f"Error extracting technical info: {e}")
        
        return technical_info
    
    def _process_video_stream_info(self, ffprobe_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process video stream information"""
        
        video_info = {}
        
        try:
            streams = ffprobe_data.get("streams", [])
            
            for stream in streams:
                if stream.get("codec_type") == "video":
                    video_info["codec"] = stream.get("codec_name")
                    video_info["width"] = stream.get("width")
                    video_info["height"] = stream.get("height")
                    video_info["fps"] = stream.get("r_frame_rate")
                    video_info["bitrate"] = stream.get("bit_rate")
                    video_info["pixel_format"] = stream.get("pix_fmt")
                    video_info["duration"] = stream.get("duration")
                    
                    # Color information
                    video_info["color_space"] = stream.get("color_space")
                    video_info["color_range"] = stream.get("color_range")
                    
                    break
                    
        except Exception as e:
            logger.error(f"Error processing video stream info: {e}")
        
        return video_info
    
    def _process_audio_stream_info(self, ffprobe_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process audio stream information"""
        
        audio_info = {}
        
        try:
            streams = ffprobe_data.get("streams", [])
            
            for stream in streams:
                if stream.get("codec_type") == "audio":
                    audio_info["codec"] = stream.get("codec_name")
                    audio_info["sample_rate"] = stream.get("sample_rate")
                    audio_info["channels"] = stream.get("channels")
                    audio_info["bitrate"] = stream.get("bit_rate")
                    audio_info["duration"] = stream.get("duration")
                    
                    break
                    
        except Exception as e:
            logger.error(f"Error processing audio stream info: {e}")
        
        return audio_info
    
    def _process_video_technical_info(self, ffprobe_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process technical information about the video"""
        
        technical_info = {}
        
        try:
            format_info = ffprobe_data.get("format", {})
            
            technical_info["format_name"] = format_info.get("format_name")
            technical_info["duration"] = format_info.get("duration")
            technical_info["size"] = format_info.get("size")
            technical_info["bitrate"] = format_info.get("bit_rate")
            
            # Container metadata
            tags = format_info.get("tags", {})
            if tags:
                technical_info["metadata"] = tags
                
        except Exception as e:
            logger.error(f"Error processing video technical info: {e}")
        
        return technical_info
    
    def _process_video_timestamps(self, ffprobe_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process timestamp information from video"""
        
        timestamps = {}
        
        try:
            format_info = ffprobe_data.get("format", {})
            tags = format_info.get("tags", {})
            
            # Common timestamp fields
            timestamp_fields = [
                "creation_time", "date", "DATE", "CREATION_TIME",
                "com.apple.quicktime.creationdate"
            ]
            
            for field in timestamp_fields:
                if field in tags:
                    timestamps[field.lower()] = tags[field]
                    
        except Exception as e:
            logger.error(f"Error processing video timestamps: {e}")
        
        return timestamps
    
    async def _process_video_location_info(self, ffprobe_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process location information from video metadata"""
        
        location_info = {}
        
        try:
            format_info = ffprobe_data.get("format", {})
            tags = format_info.get("tags", {})
            
            # Look for GPS coordinates in metadata
            gps_fields = [
                "location", "GPS", "com.apple.quicktime.location.ISO6709"
            ]
            
            for field in gps_fields:
                if field in tags:
                    location_data = tags[field]
                    
                    # Parse ISO 6709 format: +40.7589-073.9851+000.000/
                    if field == "com.apple.quicktime.location.ISO6709":
                        coords = self._parse_iso6709(location_data)
                        if coords:
                            location_info["latitude"] = coords[0]
                            location_info["longitude"] = coords[1]
                            if len(coords) > 2:
                                location_info["altitude"] = coords[2]
                    
                    break
                    
        except Exception as e:
            logger.error(f"Error processing video location info: {e}")
        
        return location_info
    
    def _parse_iso6709(self, iso6709_string: str) -> Optional[List[float]]:
        """Parse ISO 6709 coordinate string"""
        
        try:
            import re
            
            # Pattern for ISO 6709: +40.7589-073.9851+000.000/
            pattern = r'([+-]\d+\.?\d*)([+-]\d+\.?\d*)([+-]\d+\.?\d*)?'
            match = re.match(pattern, iso6709_string)
            
            if match:
                lat = float(match.group(1))
                lon = float(match.group(2))
                alt = float(match.group(3)) if match.group(3) else None
                
                coords = [lat, lon]
                if alt is not None:
                    coords.append(alt)
                
                return coords
                
        except Exception as e:
            logger.error(f"Error parsing ISO 6709 string: {e}")
        
        return None
```

**Deliverables:**
- [ ] Comprehensive media file manager with format detection
- [ ] Metadata extraction for images and videos
- [ ] EXIF data processing with GPS coordinates
- [ ] Video metadata extraction using FFmpeg
- [ ] File integrity validation with checksums
- [ ] Support for all major image and video formats

#### 1.2 Thumbnail Generation & Image Optimization

**Thumbnail Generator (apps/worker/media/thumbnail_generator.py):**
```python
import logging
from typing import Dict, List, Tuple, Optional, Any
import asyncio
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
import tempfile
import os

from PIL import Image, ImageOps, ImageFilter
import cv2
import ffmpeg
import numpy as np

logger = logging.getLogger(__name__)

class ThumbnailConfig:
    """Configuration for thumbnail generation"""
    
    def __init__(self):
        # Standard thumbnail sizes
        self.sizes = {
            "small": (150, 150),
            "medium": (300, 300),
            "large": (600, 600),
            "preview": (1200, 1200)  # For preview/lightbox
        }
        
        # Quality settings
        self.jpeg_quality = 85
        self.webp_quality = 80
        self.png_optimize = True
        
        # Video thumbnail settings
        self.video_thumbnail_time = 5.0  # seconds into video
        self.video_thumbnail_format = "JPEG"
        
        # Processing options
        self.preserve_aspect_ratio = True
        self.use_smart_cropping = True
        self.apply_sharpening = True
        self.background_color = (255, 255, 255)  # White background for transparency

class ThumbnailGenerator:
    """Generate thumbnails and optimized versions of media files"""
    
    def __init__(self, config: Optional[ThumbnailConfig] = None):
        self.config = config or ThumbnailConfig()
        self.executor = ThreadPoolExecutor(max_workers=2)
    
    async def generate_image_thumbnails(
        self, 
        source_path: str, 
        output_dir: str
    ) -> Dict[str, str]:
        """Generate thumbnails for an image file"""
        
        thumbnails = {}
        
        try:
            # Ensure output directory exists
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            
            loop = asyncio.get_event_loop()
            
            # Generate thumbnails for each size
            for size_name, dimensions in self.config.sizes.items():
                output_path = os.path.join(
                    output_dir, 
                    f"thumb_{size_name}_{Path(source_path).stem}.jpg"
                )
                
                success = await loop.run_in_executor(
                    self.executor,
                    self._generate_image_thumbnail,
                    source_path,
                    output_path,
                    dimensions
                )
                
                if success:
                    thumbnails[size_name] = output_path
                    logger.debug(f"Generated {size_name} thumbnail: {output_path}")
                else:
                    logger.warning(f"Failed to generate {size_name} thumbnail for {source_path}")
            
        except Exception as e:
            logger.error(f"Error generating image thumbnails for {source_path}: {e}")
        
        return thumbnails
    
    async def generate_video_thumbnails(
        self, 
        source_path: str, 
        output_dir: str
    ) -> Dict[str, str]:
        """Generate thumbnails for a video file"""
        
        thumbnails = {}
        
        try:
            # Ensure output directory exists
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            
            loop = asyncio.get_event_loop()
            
            # First, extract a frame from the video
            temp_frame_path = await loop.run_in_executor(
                self.executor,
                self._extract_video_frame,
                source_path,
                output_dir
            )
            
            if not temp_frame_path:
                logger.error(f"Failed to extract frame from video: {source_path}")
                return thumbnails
            
            # Generate thumbnails from the extracted frame
            for size_name, dimensions in self.config.sizes.items():
                output_path = os.path.join(
                    output_dir,
                    f"thumb_{size_name}_{Path(source_path).stem}.jpg"
                )
                
                success = await loop.run_in_executor(
                    self.executor,
                    self._generate_image_thumbnail,
                    temp_frame_path,
                    output_path,
                    dimensions
                )
                
                if success:
                    thumbnails[size_name] = output_path
                    logger.debug(f"Generated {size_name} video thumbnail: {output_path}")
            
            # Clean up temporary frame
            try:
                os.unlink(temp_frame_path)
            except:
                pass
            
        except Exception as e:
            logger.error(f"Error generating video thumbnails for {source_path}: {e}")
        
        return thumbnails
    
    def _generate_image_thumbnail(
        self, 
        source_path: str, 
        output_path: str, 
        size: Tuple[int, int]
    ) -> bool:
        """Generate a single image thumbnail"""
        
        try:
            with Image.open(source_path) as img:
                # Convert to RGB if necessary (handles RGBA, P, etc.)
                if img.mode in ('RGBA', 'LA', 'P'):
                    # Create a white background
                    background = Image.new('RGB', img.size, self.config.background_color)
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                    img = background
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # Apply EXIF orientation
                img = ImageOps.exif_transpose(img)
                
                # Smart cropping or regular resize
                if self.config.use_smart_cropping:
                    thumbnail = self._smart_crop_and_resize(img, size)
                else:
                    thumbnail = self._simple_resize(img, size)
                
                # Apply sharpening for small thumbnails
                if self.config.apply_sharpening and min(size) <= 300:
                    thumbnail = thumbnail.filter(ImageFilter.UnsharpMask(radius=0.5, percent=50))
                
                # Save with optimization
                save_kwargs = {
                    'quality': self.config.jpeg_quality,
                    'optimize': True,
                    'progressive': True
                }
                
                thumbnail.save(output_path, 'JPEG', **save_kwargs)
                
                return True
                
        except Exception as e:
            logger.error(f"Error generating thumbnail {output_path}: {e}")
            return False
    
    def _smart_crop_and_resize(self, img: Image.Image, target_size: Tuple[int, int]) -> Image.Image:
        """Smart crop and resize using face detection or entropy-based cropping"""
        
        try:
            # Try face detection first
            face_crop = self._crop_to_faces(img, target_size)
            if face_crop:
                return face_crop
            
            # Fall back to entropy-based cropping
            return self._entropy_crop_and_resize(img, target_size)
            
        except Exception as e:
            logger.warning(f"Smart cropping failed, using simple resize: {e}")
            return self._simple_resize(img, target_size)
    
    def _crop_to_faces(self, img: Image.Image, target_size: Tuple[int, int]) -> Optional[Image.Image]:
        """Crop image to focus on detected faces"""
        
        try:
            # Convert PIL image to OpenCV format
            cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            
            # Load face detection classifier
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            
            # Detect faces
            gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) == 0:
                return None
            
            # Calculate bounding box for all faces
            x_min = min(face[0] for face in faces)
            y_min = min(face[1] for face in faces)
            x_max = max(face[0] + face[2] for face in faces)
            y_max = max(face[1] + face[3] for face in faces)
            
            # Add padding around faces
            padding = 0.3  # 30% padding
            width = x_max - x_min
            height = y_max - y_min
            
            x_min = max(0, int(x_min - width * padding))
            y_min = max(0, int(y_min - height * padding))
            x_max = min(img.width, int(x_max + width * padding))
            y_max = min(img.height, int(y_max + height * padding))
            
            # Crop to face region
            face_crop = img.crop((x_min, y_min, x_max, y_max))
            
            # Resize to target size
            return self._simple_resize(face_crop, target_size)
            
        except Exception as e:
            logger.debug(f"Face detection failed: {e}")
            return None
    
    def _entropy_crop_and_resize(self, img: Image.Image, target_size: Tuple[int, int]) -> Image.Image:
        """Crop based on image entropy (most interesting regions)"""
        
        try:
            # Convert to grayscale for entropy calculation
            gray = img.convert('L')
            gray_array = np.array(gray)
            
            # Calculate target aspect ratio
            target_ratio = target_size[0] / target_size[1]
            img_ratio = img.width / img.height
            
            if abs(img_ratio - target_ratio) < 0.1:
                # Aspect ratios are close, just resize
                return self._simple_resize(img, target_size)
            
            # Determine crop dimensions
            if img_ratio > target_ratio:
                # Image is wider, crop width
                new_width = int(img.height * target_ratio)
                new_height = img.height
                
                # Find best horizontal position using entropy
                best_x = self._find_best_crop_position(gray_array, new_width, 'horizontal')
                crop_box = (best_x, 0, best_x + new_width, new_height)
            else:
                # Image is taller, crop height
                new_width = img.width
                new_height = int(img.width / target_ratio)
                
                # Find best vertical position using entropy
                best_y = self._find_best_crop_position(gray_array, new_height, 'vertical')
                crop_box = (0, best_y, new_width, best_y + new_height)
            
            # Crop and resize
            cropped = img.crop(crop_box)
            return self._simple_resize(cropped, target_size)
            
        except Exception as e:
            logger.warning(f"Entropy cropping failed: {e}")
            return self._simple_resize(img, target_size)
    
    def _find_best_crop_position(self, gray_array: np.ndarray, crop_size: int, direction: str) -> int:
        """Find the best crop position based on image entropy"""
        
        try:
            if direction == 'horizontal':
                max_pos = gray_array.shape[1] - crop_size
                entropies = []
                
                for x in range(0, max_pos + 1, max(1, max_pos // 20)):  # Sample 20 positions
                    crop_region = gray_array[:, x:x + crop_size]
                    entropy = self._calculate_entropy(crop_region)
                    entropies.append((entropy, x))
                
            else:  # vertical
                max_pos = gray_array.shape[0] - crop_size
                entropies = []
                
                for y in range(0, max_pos + 1, max(1, max_pos // 20)):  # Sample 20 positions
                    crop_region = gray_array[y:y + crop_size, :]
                    entropy = self._calculate_entropy(crop_region)
                    entropies.append((entropy, y))
            
            # Return position with highest entropy
            return max(entropies, key=lambda x: x[0])[1]
            
        except Exception:
            # Return center position as fallback
            if direction == 'horizontal':
                return (gray_array.shape[1] - crop_size) // 2
            else:
                return (gray_array.shape[0] - crop_size) // 2
    
    def _calculate_entropy(self, image_array: np.ndarray) -> float:
        """Calculate entropy of image region"""
        
        try:
            # Calculate histogram
            hist, _ = np.histogram(image_array, bins=256, range=(0, 256))
            
            # Normalize histogram
            hist = hist / hist.sum()
            
            # Calculate entropy
            entropy = -np.sum(hist * np.log2(hist + 1e-10))
            
            return entropy
            
        except Exception:
            return 0.0
    
    def _simple_resize(self, img: Image.Image, target_size: Tuple[int, int]) -> Image.Image:
        """Simple resize with aspect ratio preservation"""
        
        if self.config.preserve_aspect_ratio:
            img.thumbnail(target_size, Image.Resampling.LANCZOS)
            
            # Create a new image with the target size and paste the thumbnail
            new_img = Image.new('RGB', target_size, self.config.background_color)
            
            # Center the thumbnail
            x = (target_size[0] - img.width) // 2
            y = (target_size[1] - img.height) // 2
            new_img.paste(img, (x, y))
            
            return new_img
        else:
            return img.resize(target_size, Image.Resampling.LANCZOS)
    
    def _extract_video_frame(self, video_path: str, output_dir: str) -> Optional[str]:
        """Extract a frame from video for thumbnail generation"""
        
        try:
            output_path = os.path.join(output_dir, f"temp_frame_{Path(video_path).stem}.jpg")
            
            # Use ffmpeg to extract frame
            (
                ffmpeg
                .input(video_path, ss=self.config.video_thumbnail_time)
                .output(output_path, vframes=1, format='image2', vcodec='mjpeg')
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
            
            if os.path.exists(output_path):
                return output_path
            else:
                # Try extracting from the beginning if timestamp fails
                (
                    ffmpeg
                    .input(video_path, ss=0)
                    .output(output_path, vframes=1, format='image2', vcodec='mjpeg')
                    .overwrite_output()
                    .run(capture_stdout=True, capture_stderr=True)
                )
                
                return output_path if os.path.exists(output_path) else None
                
        except Exception as e:
            logger.error(f"Error extracting video frame: {e}")
            return None
    
    async def optimize_image(
        self, 
        source_path: str, 
        output_path: str, 
        max_dimension: int = 2048,
        quality: int = 85
    ) -> bool:
        """Optimize image for web display"""
        
        try:
            loop = asyncio.get_event_loop()
            
            return await loop.run_in_executor(
                self.executor,
                self._optimize_image_sync,
                source_path,
                output_path,
                max_dimension,
                quality
            )
            
        except Exception as e:
            logger.error(f"Error optimizing image {source_path}: {e}")
            return False
    
    def _optimize_image_sync(
        self, 
        source_path: str, 
        output_path: str, 
        max_dimension: int,
        quality: int
    ) -> bool:
        """Synchronous image optimization"""
        
        try:
            with Image.open(source_path) as img:
                # Apply EXIF orientation
                img = ImageOps.exif_transpose(img)
                
                # Convert to RGB if necessary
                if img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                    img = background
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # Resize if too large
                if max(img.size) > max_dimension:
                    img.thumbnail((max_dimension, max_dimension), Image.Resampling.LANCZOS)
                
                # Save optimized version
                save_kwargs = {
                    'quality': quality,
                    'optimize': True,
                    'progressive': True
                }
                
                img.save(output_path, 'JPEG', **save_kwargs)
                
                return True
                
        except Exception as e:
            logger.error(f"Error in sync image optimization: {e}")
            return False
    
    async def generate_progressive_jpeg(self, source_path: str, output_path: str) -> bool:
        """Generate progressive JPEG for better loading experience"""
        
        try:
            loop = asyncio.get_event_loop()
            
            return await loop.run_in_executor(
                self.executor,
                self._generate_progressive_jpeg_sync,
                source_path,
                output_path
            )
            
        except Exception as e:
            logger.error(f"Error generating progressive JPEG: {e}")
            return False
    
    def _generate_progressive_jpeg_sync(self, source_path: str, output_path: str) -> bool:
        """Generate progressive JPEG synchronously"""
        
        try:
            with Image.open(source_path) as img:
                # Apply EXIF orientation
                img = ImageOps.exif_transpose(img)
                
                # Convert to RGB
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # Save as progressive JPEG
                img.save(output_path, 'JPEG', quality=90, optimize=True, progressive=True)
                
                return True
                
        except Exception as e:
            logger.error(f"Error generating progressive JPEG: {e}")
            return False
```

**Deliverables:**
- [ ] Multi-size thumbnail generation system
- [ ] Smart cropping with face detection
- [ ] Entropy-based intelligent cropping
- [ ] Video frame extraction for thumbnails
- [ ] Image optimization for web display
- [ ] Progressive JPEG generation
- [ ] Configurable quality and size settings

### Task 2: AI-Powered Media Analysis

#### 2.1 Computer Vision Integration

**AI Vision Service (apps/worker/ai/vision_service.py):**
```python
import logging
from typing import Dict, List, Optional, Any, Tuple
import asyncio
from concurrent.futures import ThreadPoolExecutor
import numpy as np
import cv2
from PIL import Image
import torch
import torchvision.transforms as transforms
from transformers import pipeline, BlipProcessor, BlipForConditionalGeneration
import face_recognition
import json
from pathlib import Path

logger = logging.getLogger(__name__)

class VisionAnalysisResult:
    """Container for vision analysis results"""
    
    def __init__(self):
        self.objects: List[Dict[str, Any]] = []
        self.faces: List[Dict[str, Any]] = []
        self.scenes: List[Dict[str, Any]] = []
        self.text: List[Dict[str, Any]] = []
        self.colors: Dict[str, Any] = {}
        self.quality_metrics: Dict[str, Any] = {}
        self.description: str = ""
        self.confidence_score: float = 0.0
        self.processing_time: float = 0.0
        self.error_message: str = ""

class AIVisionService:
    """AI-powered computer vision analysis for images and videos"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=2)
        self.models_loaded = False
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # Model containers
        self.object_detector = None
        self.image_captioner = None
        self.scene_classifier = None
        self.text_detector = None
        
        # Face recognition settings
        self.face_recognition_tolerance = 0.6
        self.face_detection_model = "hog"  # or "cnn" for better accuracy
        
        # Initialize models asynchronously
        asyncio.create_task(self._initialize_models())
    
    async def _initialize_models(self):
        """Initialize AI models asynchronously"""
        
        try:
            logger.info("Initializing AI vision models...")
            
            loop = asyncio.get_event_loop()
            
            # Initialize models in executor to avoid blocking
            await loop.run_in_executor(self.executor, self._load_models)
            
            self.models_loaded = True
            logger.info("AI vision models loaded successfully")
            
        except Exception as e:
            logger.error(f"Error initializing AI models: {e}")
            self.models_loaded = False
    
    def _load_models(self):
        """Load AI models synchronously"""
        
        try:
            # Object detection model (YOLO or similar)
            self.object_detector = pipeline(
                "object-detection",
                model="facebook/detr-resnet-50",
                device=0 if torch.cuda.is_available() else -1
            )
            
            # Image captioning model
            self.image_captioner = pipeline(
                "image-to-text",
                model="Salesforce/blip-image-captioning-base",
                device=0 if torch.cuda.is_available() else -1
            )
            
            # Scene classification (using a general classification model)
            self.scene_classifier = pipeline(
                "image-classification",
                model="microsoft/resnet-50",
                device=0 if torch.cuda.is_available() else -1
            )
            
            logger.info("All AI models loaded successfully")
            
        except Exception as e:
            logger.error(f"Error loading AI models: {e}")
            raise
    
    async def analyze_image(self, image_path: str) -> VisionAnalysisResult:
        """Comprehensive AI analysis of an image"""
        
        result = VisionAnalysisResult()
        start_time = asyncio.get_event_loop().time()
        
        try:
            if not self.models_loaded:
                result.error_message = "AI models not loaded"
                return result
            
            # Load image
            image = Image.open(image_path).convert('RGB')
            cv_image = cv2.imread(image_path)
            cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
            
            # Run analysis tasks concurrently
            tasks = [
                self._detect_objects(image),
                self._detect_faces(cv_image_rgb),
                self._classify_scene(image),
                self._generate_description(image),
                self._analyze_colors(cv_image_rgb),
                self._assess_quality(cv_image_rgb)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            result.objects = results[0] if not isinstance(results[0], Exception) else []
            result.faces = results[1] if not isinstance(results[1], Exception) else []
            result.scenes = results[2] if not isinstance(results[2], Exception) else []
            result.description = results[3] if not isinstance(results[3], Exception) else ""
            result.colors = results[4] if not isinstance(results[4], Exception) else {}
            result.quality_metrics = results[5] if not isinstance(results[5], Exception) else {}
            
            # Calculate overall confidence
            result.confidence_score = self._calculate_confidence(result)
            
            # Processing time
            result.processing_time = asyncio.get_event_loop().time() - start_time
            
            logger.debug(f"Image analysis completed for {image_path} in {result.processing_time:.2f}s")
            
        except Exception as e:
            logger.error(f"Error analyzing image {image_path}: {e}")
            result.error_message = str(e)
        
        return result
    
    async def _detect_objects(self, image: Image.Image) -> List[Dict[str, Any]]:
        """Detect objects in the image"""
        
        try:
            loop = asyncio.get_event_loop()
            
            # Run object detection
            detections = await loop.run_in_executor(
                self.executor,
                self.object_detector,
                image
            )
            
            objects = []
            for detection in detections:
                obj = {
                    "label": detection["label"],
                    "confidence": detection["score"],
                    "bbox": detection["box"]  # {xmin, ymin, xmax, ymax}
                }
                objects.append(obj)
            
            # Sort by confidence
            objects.sort(key=lambda x: x["confidence"], reverse=True)
            
            return objects
            
        except Exception as e:
            logger.error(f"Error in object detection: {e}")
            return []
    
    async def _detect_faces(self, image_rgb: np.ndarray) -> List[Dict[str, Any]]:
        """Detect and analyze faces in the image"""
        
        try:
            loop = asyncio.get_event_loop()
            
            # Run face detection
            face_data = await loop.run_in_executor(
                self.executor,
                self._detect_faces_sync,
                image_rgb
            )
            
            return face_data
            
        except Exception as e:
            logger.error(f"Error in face detection: {e}")
            return []
    
    def _detect_faces_sync(self, image_rgb: np.ndarray) -> List[Dict[str, Any]]:
        """Synchronous face detection"""
        
        try:
            # Find face locations
            face_locations = face_recognition.face_locations(
                image_rgb, 
                model=self.face_detection_model
            )
            
            # Get face encodings
            face_encodings = face_recognition.face_encodings(
                image_rgb, 
                face_locations
            )
            
            faces = []
            for i, (location, encoding) in enumerate(zip(face_locations, face_encodings)):
                top, right, bottom, left = location
                
                face_data = {
                    "face_id": i,
                    "bbox": {
                        "top": top,
                        "right": right,
                        "bottom": bottom,
                        "left": left
                    },
                    "encoding": encoding.tolist(),  # For face recognition
                    "confidence": 0.9,  # face_recognition doesn't provide confidence
                    "attributes": self._analyze_face_attributes(image_rgb, location)
                }
                
                faces.append(face_data)
            
            return faces
            
        except Exception as e:
            logger.error(f"Error in synchronous face detection: {e}")
            return []
    
    def _analyze_face_attributes(self, image_rgb: np.ndarray, location: Tuple[int, int, int, int]) -> Dict[str, Any]:
        """Analyze face attributes (age, gender, emotion estimation)"""
        
        try:
            top, right, bottom, left = location
            
            # Extract face region
            face_image = image_rgb[top:bottom, left:right]
            
            # Basic attributes (placeholder - would use specialized models)
            attributes = {
                "estimated_age_range": "unknown",
                "estimated_gender": "unknown",
                "estimated_emotion": "neutral",
                "face_quality": self._assess_face_quality(face_image)
            }
            
            return attributes
            
        except Exception as e:
            logger.error(f"Error analyzing face attributes: {e}")
            return {}
    
    def _assess_face_quality(self, face_image: np.ndarray) -> Dict[str, Any]:
        """Assess face image quality"""
        
        try:
            # Calculate basic quality metrics
            height, width = face_image.shape[:2]
            
            # Blur detection using Laplacian variance
            gray = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)
            blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # Brightness assessment
            brightness = np.mean(gray)
            
            quality = {
                "size": {"width": width, "height": height},
                "blur_score": float(blur_score),
                "brightness": float(brightness),
                "is_good_quality": blur_score > 100 and 50 < brightness < 200
            }
            
            return quality
            
        except Exception as e:
            logger.error(f"Error assessing face quality: {e}")
            return {}
    
    async def _classify_scene(self, image: Image.Image) -> List[Dict[str, Any]]:
        """Classify the scene/setting of the image"""
        
        try:
            loop = asyncio.get_event_loop()
            
            # Run scene classification
            classifications = await loop.run_in_executor(
                self.executor,
                self.scene_classifier,
                image
            )
            
            scenes = []
            for classification in classifications[:5]:  # Top 5 predictions
                scene = {
                    "label": classification["label"],
                    "confidence": classification["score"]
                }
                scenes.append(scene)
            
            return scenes
            
        except Exception as e:
            logger.error(f"Error in scene classification: {e}")
            return []
    
    async def _generate_description(self, image: Image.Image) -> str:
        """Generate natural language description of the image"""
        
        try:
            loop = asyncio.get_event_loop()
            
            # Generate caption
            captions = await loop.run_in_executor(
                self.executor,
                self.image_captioner,
                image
            )
            
            if captions and len(captions) > 0:
                return captions[0]["generated_text"]
            
            return ""
            
        except Exception as e:
            logger.error(f"Error generating image description: {e}")
            return ""
    
    async def _analyze_colors(self, image_rgb: np.ndarray) -> Dict[str, Any]:
        """Analyze color composition of the image"""
        
        try:
            loop = asyncio.get_event_loop()
            
            color_analysis = await loop.run_in_executor(
                self.executor,
                self._analyze_colors_sync,
                image_rgb
            )
            
            return color_analysis
            
        except Exception as e:
            logger.error(f"Error analyzing colors: {e}")
            return {}
    
    def _analyze_colors_sync(self, image_rgb: np.ndarray) -> Dict[str, Any]:
        """Synchronous color analysis"""
        
        try:
            # Reshape image for clustering
            pixels = image_rgb.reshape(-1, 3)
            
            # Use K-means to find dominant colors
            from sklearn.cluster import KMeans
            
            n_colors = 5
            kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)
            kmeans.fit(pixels)
            
            # Get dominant colors and their percentages
            colors = kmeans.cluster_centers_.astype(int)
            labels = kmeans.labels_
            
            # Calculate color percentages
            unique_labels, counts = np.unique(labels, return_counts=True)
            percentages = counts / len(labels) * 100
            
            dominant_colors = []
            for i, (color, percentage) in enumerate(zip(colors, percentages)):
                dominant_colors.append({
                    "rgb": color.tolist(),
                    "hex": "#{:02x}{:02x}{:02x}".format(color[0], color[1], color[2]),
                    "percentage": float(percentage)
                })
            
            # Sort by percentage
            dominant_colors.sort(key=lambda x: x["percentage"], reverse=True)
            
            # Calculate overall brightness and saturation
            hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)
            avg_brightness = np.mean(hsv[:, :, 2])
            avg_saturation = np.mean(hsv[:, :, 1])
            
            color_analysis = {
                "dominant_colors": dominant_colors,
                "average_brightness": float(avg_brightness),
                "average_saturation": float(avg_saturation),
                "color_temperature": self._estimate_color_temperature(image_rgb)
            }
            
            return color_analysis
            
        except Exception as e:
            logger.error(f"Error in synchronous color analysis: {e}")
            return {}
    
    def _estimate_color_temperature(self, image_rgb: np.ndarray) -> str:
        """Estimate color temperature (warm/cool)"""
        
        try:
            # Calculate average RGB values
            avg_r = np.mean(image_rgb[:, :, 0])
            avg_g = np.mean(image_rgb[:, :, 1])
            avg_b = np.mean(image_rgb[:, :, 2])
            
            # Simple heuristic for color temperature
            if avg_r > avg_b + 10:
                return "warm"
            elif avg_b > avg_r + 10:
                return "cool"
            else:
                return "neutral"
                
        except Exception:
            return "unknown"
    
    async def _assess_quality(self, image_rgb: np.ndarray) -> Dict[str, Any]:
        """Assess technical quality of the image"""
        
        try:
            loop = asyncio.get_event_loop()
            
            quality_metrics = await loop.run_in_executor(
                self.executor,
                self._assess_quality_sync,
                image_rgb
            )
            
            return quality_metrics
            
        except Exception as e:
            logger.error(f"Error assessing image quality: {e}")
            return {}
    
    def _assess_quality_sync(self, image_rgb: np.ndarray) -> Dict[str, Any]:
        """Synchronous quality assessment"""
        
        try:
            gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
            
            # Blur detection using Laplacian variance
            blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # Noise estimation
            noise_score = np.std(gray)
            
            # Contrast assessment
            contrast_score = gray.std()
            
            # Brightness assessment
            brightness_score = np.mean(gray)
            
            # Overall quality score (0-1)
            quality_score = min(1.0, (
                (blur_score / 1000) * 0.3 +
                (min(contrast_score / 50, 1.0)) * 0.3 +
                (1.0 - abs(brightness_score - 128) / 128) * 0.2 +
                (1.0 - min(noise_score / 50, 1.0)) * 0.2
            ))
            
            quality_metrics = {
                "blur_score": float(blur_score),
                "noise_score": float(noise_score),
                "contrast_score": float(contrast_score),
                "brightness_score": float(brightness_score),
                "overall_quality": float(quality_score),
                "is_high_quality": quality_score > 0.7
            }
            
            return quality_metrics
            
        except Exception as e:
            logger.error(f"Error in synchronous quality assessment: {e}")
            return {}
    
    def _calculate_confidence(self, result: VisionAnalysisResult) -> float:
        """Calculate overall confidence score for the analysis"""
        
        try:
            confidence_scores = []
            
            # Object detection confidence
            if result.objects:
                avg_obj_confidence = np.mean([obj["confidence"] for obj in result.objects])
                confidence_scores.append(avg_obj_confidence)
            
            # Scene classification confidence
            if result.scenes:
                avg_scene_confidence = np.mean([scene["confidence"] for scene in result.scenes])
                confidence_scores.append(avg_scene_confidence)
            
            # Face detection confidence
            if result.faces:
                avg_face_confidence = np.mean([face["confidence"] for face in result.faces])
                confidence_scores.append(avg_face_confidence)
            
            # Quality score as confidence indicator
            if result.quality_metrics and "overall_quality" in result.quality_metrics:
                confidence_scores.append(result.quality_metrics["overall_quality"])
            
            if confidence_scores:
                return float(np.mean(confidence_scores))
            else:
                return 0.5  # Default confidence
                
        except Exception as e:
            logger.error(f"Error calculating confidence: {e}")
            return 0.0
    
    async def analyze_video_frame(self, video_path: str, timestamp: float = 5.0) -> VisionAnalysisResult:
        """Analyze a specific frame from a video"""
        
        try:
            # Extract frame at timestamp
            cap = cv2.VideoCapture(video_path)
            
            # Set position to timestamp
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_number = int(timestamp * fps)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                result = VisionAnalysisResult()
                result.error_message = "Could not extract frame from video"
                return result
            
            # Convert to RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # Convert to PIL Image
            pil_image = Image.fromarray(frame_rgb)
            
            # Analyze the frame as an image
            return await self.analyze_image_from_array(frame_rgb, pil_image)
            
        except Exception as e:
            logger.error(f"Error analyzing video frame: {e}")
            result = VisionAnalysisResult()
            result.error_message = str(e)
            return result
    
    async def analyze_image_from_array(self, image_rgb: np.ndarray, pil_image: Image.Image) -> VisionAnalysisResult:
        """Analyze image from numpy array and PIL image"""
        
        result = VisionAnalysisResult()
        start_time = asyncio.get_event_loop().time()
        
        try:
            if not self.models_loaded:
                result.error_message = "AI models not loaded"
                return result
            
            # Run analysis tasks concurrently
            tasks = [
                self._detect_objects(pil_image),
                self._detect_faces(image_rgb),
                self._classify_scene(pil_image),
                self._generate_description(pil_image),
                self._analyze_colors(image_rgb),
                self._assess_quality(image_rgb)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            result.objects = results[0] if not isinstance(results[0], Exception) else []
            result.faces = results[1] if not isinstance(results[1], Exception) else []
            result.scenes = results[2] if not isinstance(results[2], Exception) else []
            result.description = results[3] if not isinstance(results[3], Exception) else ""
            result.colors = results[4] if not isinstance(results[4], Exception) else {}
            result.quality_metrics = results[5] if not isinstance(results[5], Exception) else {}
            
            # Calculate overall confidence
            result.confidence_score = self._calculate_confidence(result)
            
            # Processing time
            result.processing_time = asyncio.get_event_loop().time() - start_time
            
        except Exception as e:
            logger.error(f"Error analyzing image from array: {e}")
            result.error_message = str(e)
        
        return result
    
    def is_ready(self) -> bool:
        """Check if the service is ready for analysis"""
        return self.models_loaded
    
    async def get_model_info(self) -> Dict[str, Any]:
        """Get information about loaded models"""
        
        return {
            "models_loaded": self.models_loaded,
            "device": str(self.device),
            "available_models": {
                "object_detection": self.object_detector is not None,
                "image_captioning": self.image_captioner is not None,
                "scene_classification": self.scene_classifier is not None,
                "face_recognition": True  # Always available
            }
        }

# Global vision service instance
vision_service = AIVisionService()
```

**Deliverables:**
- [ ] Comprehensive AI vision analysis service
- [ ] Object detection with bounding boxes
- [ ] Face detection and recognition
- [ ] Scene classification and description generation
- [ ] Color analysis and quality assessment
- [ ] Video frame analysis capability
- [ ] Confidence scoring and error handling

### Task 3: Storage & CDN Integration

#### 3.1 Media Storage Management

**Media Storage Service (apps/worker/storage/media_storage.py):**
```python
import logging
from typing import Dict, List, Optional, Any, Tuple
import asyncio
from pathlib import Path
import hashlib
import mimetypes
from datetime import datetime, timedelta
import json
import os
import shutil

import boto3
from botocore.exceptions import ClientError, NoCredentialsError
import aiofiles
from minio import Minio
from minio.error import S3Error

from core.config import settings

logger = logging.getLogger(__name__)

class StorageConfig:
    """Configuration for media storage"""
    
    def __init__(self):
        # Storage backend
        self.backend = settings.STORAGE_BACKEND  # 'local', 's3', 'minio'
        
        # Local storage settings
        self.local_base_path = settings.MEDIA_STORAGE_PATH
        
        # S3/MinIO settings
        self.s3_bucket = settings.S3_BUCKET_NAME
        self.s3_region = settings.S3_REGION
        self.s3_access_key = settings.S3_ACCESS_KEY
        self.s3_secret_key = settings.S3_SECRET_KEY
        self.s3_endpoint = settings.S3_ENDPOINT  # For MinIO
        
        # CDN settings
        self.cdn_base_url = settings.CDN_BASE_URL
        self.use_cdn = settings.USE_CDN
        
        # Storage organization
        self.organize_by_date = True
        self.organize_by_user = True
        self.organize_by_type = True
        
        # File naming
        self.preserve_original_names = False
        self.use_content_hash = True

class MediaStorageService:
    """Service for managing media file storage"""
    
    def __init__(self, config: Optional[StorageConfig] = None):
        self.config = config or StorageConfig()
        self.s3_client = None
        self.minio_client = None
        
        # Initialize storage backend
        asyncio.create_task(self._initialize_storage())
    
    async def _initialize_storage(self):
        """Initialize storage backend"""
        
        try:
            if self.config.backend == 's3':
                await self._initialize_s3()
            elif self.config.backend == 'minio':
                await self._initialize_minio()
            elif self.config.backend == 'local':
                await self._initialize_local()
            else:
                raise ValueError(f"Unsupported storage backend: {self.config.backend}")
            
            logger.info(f"Storage backend '{self.config.backend}' initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing storage backend: {e}")
            raise
    
    async def _initialize_s3(self):
        """Initialize AWS S3 client"""
        
        try:
            self.s3_client = boto3.client(
                's3',
                aws_access_key_id=self.config.s3_access_key,
                aws_secret_access_key=self.config.s3_secret_key,
                region_name=self.config.s3_region
            )
            
            # Test connection
            await asyncio.get_event_loop().run_in_executor(
                None, self.s3_client.head_bucket, Bucket=self.config.s3_bucket
            )
            
        except Exception as e:
            logger.error(f"Error initializing S3: {e}")
            raise
    
    async def _initialize_minio(self):
        """Initialize MinIO client"""
        
        try:
            self.minio_client = Minio(
                self.config.s3_endpoint,
                access_key=self.config.s3_access_key,
                secret_key=self.config.s3_secret_key,
                secure=self.config.s3_endpoint.startswith('https')
            )
            
            # Test connection
            await asyncio.get_event_loop().run_in_executor(
                None, self.minio_client.bucket_exists, self.config.s3_bucket
            )
            
        except Exception as e:
            logger.error(f"Error initializing MinIO: {e}")
            raise
    
    async def _initialize_local(self):
        """Initialize local storage"""
        
        try:
            # Create base directory if it doesn't exist
            base_path = Path(self.config.local_base_path)
            base_path.mkdir(parents=True, exist_ok=True)
            
            # Create subdirectories
            subdirs = ['originals', 'processed', 'thumbnails', 'temp']
            for subdir in subdirs:
                (base_path / subdir).mkdir(exist_ok=True)
            
        except Exception as e:
            logger.error(f"Error initializing local storage: {e}")
            raise
    
    async def store_media_file(
        self, 
        file_path: str, 
        user_id: str,
        file_type: str = "original",
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Store a media file and return storage information"""
        
        try:
            # Generate storage path
            storage_path = self._generate_storage_path(file_path, user_id, file_type)
            
            # Calculate file hash
            file_hash = await self._calculate_file_hash(file_path)
            
            # Check if file already exists (deduplication)
            existing_file = await self._check_existing_file(file_hash, user_id)
            if existing_file:
                logger.info(f"File already exists, using existing: {existing_file['storage_path']}")
                return existing_file
            
            # Store file based on backend
            if self.config.backend == 'local':
                stored_info = await self._store_local(file_path, storage_path, metadata)
            elif self.config.backend == 's3':
                stored_info = await self._store_s3(file_path, storage_path, metadata)
            elif self.config.backend == 'minio':
                stored_info = await self._store_minio(file_path, storage_path, metadata)
            else:
                raise ValueError(f"Unsupported storage backend: {self.config.backend}")
            
            # Add common information
            stored_info.update({
                "file_hash": file_hash,
                "user_id": user_id,
                "file_type": file_type,
                "stored_at": datetime.utcnow().isoformat(),
                "backend": self.config.backend
            })
            
            # Generate public URL
            stored_info["public_url"] = self._generate_public_url(storage_path)
            
            logger.debug(f"Stored media file: {file_path} -> {storage_path}")
            
            return stored_info
            
        except Exception as e:
            logger.error(f"Error storing media file {file_path}: {e}")
            raise
    
    def _generate_storage_path(self, file_path: str, user_id: str, file_type: str) -> str:
        """Generate storage path for file"""
        
        file_path_obj = Path(file_path)
        
        # Start with file type
        path_parts = [file_type]
        
        # Add user organization
        if self.config.organize_by_user:
            path_parts.append(f"user_{user_id}")
        
        # Add date organization
        if self.config.organize_by_date:
            now = datetime.utcnow()
            path_parts.extend([str(now.year), f"{now.month:02d}", f"{now.day:02d}"])
        
        # Add type organization
        if self.config.organize_by_type:
            mime_type, _ = mimetypes.guess_type(file_path)
            if mime_type:
                if mime_type.startswith('image'):
                    path_parts.append('images')
                elif mime_type.startswith('video'):
                    path_parts.append('videos')
                else:
                    path_parts.append('other')
        
        # Generate filename
        if self.config.use_content_hash:
            # Use hash as filename (will be calculated later)
            filename = f"content_hash{file_path_obj.suffix}"
        elif self.config.preserve_original_names:
            filename = file_path_obj.name
        else:
            # Use timestamp + random
            import uuid
            timestamp = int(datetime.utcnow().timestamp())
            filename = f"{timestamp}_{uuid.uuid4().hex[:8]}{file_path_obj.suffix}"
        
        path_parts.append(filename)
        
        return "/".join(path_parts)
    
    async def _calculate_file_hash(self, file_path: str) -> str:
        """Calculate SHA-256 hash of file"""
        
        hash_sha256 = hashlib.sha256()
        
        async with aiofiles.open(file_path, 'rb') as f:
            while chunk := await f.read(8192):
                hash_sha256.update(chunk)
        
        return hash_sha256.hexdigest()
    
    async def _check_existing_file(self, file_hash: str, user_id: str) -> Optional[Dict[str, Any]]:
        """Check if file with same hash already exists for user"""
        
        # This would typically check a database of stored files
        # For now, return None (no deduplication)
        return None
    
    async def _store_local(self, file_path: str, storage_path: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Store file in local filesystem"""
        
        try:
            # Full storage path
            full_storage_path = Path(self.config.local_base_path) / storage_path
            
            # Create directory if needed
            full_storage_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Copy file
            await asyncio.get_event_loop().run_in_executor(
                None, shutil.copy2, file_path, str(full_storage_path)
            )
            
            # Get file info
            stat = full_storage_path.stat()
            
            # Store metadata if provided
            if metadata:
                metadata_path = full_storage_path.with_suffix('.metadata.json')
                async with aiofiles.open(metadata_path, 'w') as f:
                    await f.write(json.dumps(metadata, indent=2))
            
            return {
                "storage_path": storage_path,
                "full_path": str(full_storage_path),
                "file_size": stat.st_size,
                "mime_type": mimetypes.guess_type(file_path)[0]
            }
            
        except Exception as e:
            logger.error(f"Error storing file locally: {e}")
            raise
    
    async def _store_s3(self, file_path: str, storage_path: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Store file in AWS S3"""
        
        try:
            # Prepare metadata for S3
            s3_metadata = {}
            if metadata:
                # S3 metadata keys must be strings and values must be strings
                for key, value in metadata.items():
                    if isinstance(value, (str, int, float)):
                        s3_metadata[f"x-amz-meta-{key}"] = str(value)
            
            # Upload file
            await asyncio.get_event_loop().run_in_executor(
                None,
                self.s3_client.upload_file,
                file_path,
                self.config.s3_bucket,
                storage_path,
                {'Metadata': s3_metadata}
            )
            
            # Get file info
            file_stat = Path(file_path).stat()
            
            return {
                "storage_path": storage_path,
                "bucket": self.config.s3_bucket,
                "file_size": file_stat.st_size,
                "mime_type": mimetypes.guess_type(file_path)[0]
            }
            
        except Exception as e:
            logger.error(f"Error storing file in S3: {e}")
            raise
    
    async def _store_minio(self, file_path: str, storage_path: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Store file in MinIO"""
        
        try:
            # Prepare metadata for MinIO
            minio_metadata = {}
            if metadata:
                for key, value in metadata.items():
                    if isinstance(value, (str, int, float)):
                        minio_metadata[key] = str(value)
            
            # Upload file
            await asyncio.get_event_loop().run_in_executor(
                None,
                self.minio_client.fput_object,
                self.config.s3_bucket,
                storage_path,
                file_path,
                metadata=minio_metadata
            )
            
            # Get file info
            file_stat = Path(file_path).stat()
            
            return {
                "storage_path": storage_path,
                "bucket": self.config.s3_bucket,
                "file_size": file_stat.st_size,
                "mime_type": mimetypes.guess_type(file_path)[0]
            }
            
        except Exception as e:
            logger.error(f"Error storing file in MinIO: {e}")
            raise
    
    def _generate_public_url(self, storage_path: str) -> str:
        """Generate public URL for stored file"""
        
        if self.config.use_cdn and self.config.cdn_base_url:
            return f"{self.config.cdn_base_url.rstrip('/')}/{storage_path}"
        elif self.config.backend == 'local':
            return f"/media/{storage_path}"
        elif self.config.backend in ['s3', 'minio']:
            if self.config.s3_endpoint:
                return f"https://{self.config.s3_endpoint}/{self.config.s3_bucket}/{storage_path}"
            else:
                return f"https://{self.config.s3_bucket}.s3.{self.config.s3_region}.amazonaws.com/{storage_path}"
        else:
            return storage_path
    
    async def retrieve_file(self, storage_path: str, local_path: str) -> bool:
        """Retrieve file from storage to local path"""
        
        try:
            if self.config.backend == 'local':
                return await self._retrieve_local(storage_path, local_path)
            elif self.config.backend == 's3':
                return await self._retrieve_s3(storage_path, local_path)
            elif self.config.backend == 'minio':
                return await self._retrieve_minio(storage_path, local_path)
            else:
                raise ValueError(f"Unsupported storage backend: {self.config.backend}")
                
        except Exception as e:
            logger.error(f"Error retrieving file {storage_path}: {e}")
            return False
    
    async def _retrieve_local(self, storage_path: str, local_path: str) -> bool:
        """Retrieve file from local storage"""
        
        try:
            full_storage_path = Path(self.config.local_base_path) / storage_path
            
            if not full_storage_path.exists():
                logger.error(f"File not found in local storage: {storage_path}")
                return False
            
            await asyncio.get_event_loop().run_in_executor(
                None, shutil.copy2, str(full_storage_path), local_path
            )
            
            return True
            
        except Exception as e:
            logger.error(f"Error retrieving file from local storage: {e}")
            return False
    
    async def _retrieve_s3(self, storage_path: str, local_path: str) -> bool:
        """Retrieve file from S3"""
        
        try:
            await asyncio.get_event_loop().run_in_executor(
                None,
                self.s3_client.download_file,
                self.config.s3_bucket,
                storage_path,
                local_path
            )
            
            return True
            
        except Exception as e:
            logger.error(f"Error retrieving file from S3: {e}")
            return False
    
    async def _retrieve_minio(self, storage_path: str, local_path: str) -> bool:
        """Retrieve file from MinIO"""
        
        try:
            await asyncio.get_event_loop().run_in_executor(
                None,
                self.minio_client.fget_object,
                self.config.s3_bucket,
                storage_path,
                local_path
            )
            
            return True
            
        except Exception as e:
            logger.error(f"Error retrieving file from MinIO: {e}")
            return False
    
    async def delete_file(self, storage_path: str) -> bool:
        """Delete file from storage"""
        
        try:
            if self.config.backend == 'local':
                return await self._delete_local(storage_path)
            elif self.config.backend == 's3':
                return await self._delete_s3(storage_path)
            elif self.config.backend == 'minio':
                return await self._delete_minio(storage_path)
            else:
                raise ValueError(f"Unsupported storage backend: {self.config.backend}")
                
        except Exception as e:
            logger.error(f"Error deleting file {storage_path}: {e}")
            return False
    
    async def _delete_local(self, storage_path: str) -> bool:
        """Delete file from local storage"""
        
        try:
            full_storage_path = Path(self.config.local_base_path) / storage_path
            
            if full_storage_path.exists():
                full_storage_path.unlink()
            
            # Also delete metadata file if it exists
            metadata_path = full_storage_path.with_suffix('.metadata.json')
            if metadata_path.exists():
                metadata_path.unlink()
            
            return True
            
        except Exception as e:
            logger.error(f"Error deleting file from local storage: {e}")
            return False
    
    async def _delete_s3(self, storage_path: str) -> bool:
        """Delete file from S3"""
        
        try:
            await asyncio.get_event_loop().run_in_executor(
                None,
                self.s3_client.delete_object,
                Bucket=self.config.s3_bucket,
                Key=storage_path
            )
            
            return True
            
        except Exception as e:
            logger.error(f"Error deleting file from S3: {e}")
            return False
    
    async def _delete_minio(self, storage_path: str) -> bool:
        """Delete file from MinIO"""
        
        try:
            await asyncio.get_event_loop().run_in_executor(
                None,
                self.minio_client.remove_object,
                self.config.s3_bucket,
                storage_path
            )
            
            return True
            
        except Exception as e:
            logger.error(f"Error deleting file from MinIO: {e}")
            return False
    
    async def get_file_info(self, storage_path: str) -> Optional[Dict[str, Any]]:
        """Get information about stored file"""
        
        try:
            if self.config.backend == 'local':
                return await self._get_local_file_info(storage_path)
            elif self.config.backend == 's3':
                return await self._get_s3_file_info(storage_path)
            elif self.config.backend == 'minio':
                return await self._get_minio_file_info(storage_path)
            else:
                raise ValueError(f"Unsupported storage backend: {self.config.backend}")
                
        except Exception as e:
            logger.error(f"Error getting file info for {storage_path}: {e}")
            return None
    
    async def _get_local_file_info(self, storage_path: str) -> Optional[Dict[str, Any]]:
        """Get local file information"""
        
        try:
            full_storage_path = Path(self.config.local_base_path) / storage_path
            
            if not full_storage_path.exists():
                return None
            
            stat = full_storage_path.stat()
            
            return {
                "storage_path": storage_path,
                "file_size": stat.st_size,
                "modified_at": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "mime_type": mimetypes.guess_type(str(full_storage_path))[0]
            }
            
        except Exception as e:
            logger.error(f"Error getting local file info: {e}")
            return None
    
    async def _get_s3_file_info(self, storage_path: str) -> Optional[Dict[str, Any]]:
        """Get S3 file information"""
        
        try:
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                self.s3_client.head_object,
                Bucket=self.config.s3_bucket,
                Key=storage_path
            )
            
            return {
                "storage_path": storage_path,
                "file_size": response['ContentLength'],
                "modified_at": response['LastModified'].isoformat(),
                "mime_type": response.get('ContentType'),
                "etag": response.get('ETag', '').strip('"')
            }
            
        except ClientError as e:
            if e.response['Error']['Code'] == '404':
                return None
            raise
    
    async def _get_minio_file_info(self, storage_path: str) -> Optional[Dict[str, Any]]:
        """Get MinIO file information"""
        
        try:
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                self.minio_client.stat_object,
                self.config.s3_bucket,
                storage_path
            )
            
            return {
                "storage_path": storage_path,
                "file_size": response.size,
                "modified_at": response.last_modified.isoformat(),
                "mime_type": response.content_type,
                "etag": response.etag
            }
            
        except S3Error as e:
            if e.code == 'NoSuchKey':
                return None
            raise
    
    async def list_user_files(self, user_id: str, file_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """List all files for a user"""
        
        try:
            prefix = f"user_{user_id}/"
            if file_type:
                prefix = f"{file_type}/{prefix}"
            
            if self.config.backend == 'local':
                return await self._list_local_files(prefix)
            elif self.config.backend == 's3':
                return await self._list_s3_files(prefix)
            elif self.config.backend == 'minio':
                return await self._list_minio_files(prefix)
            else:
                raise ValueError(f"Unsupported storage backend: {self.config.backend}")
                
        except Exception as e:
            logger.error(f"Error listing user files: {e}")
            return []
    
    async def _list_local_files(self, prefix: str) -> List[Dict[str, Any]]:
        """List local files with prefix"""
        
        try:
            base_path = Path(self.config.local_base_path)
            search_path = base_path / prefix
            
            files = []
            if search_path.exists():
                for file_path in search_path.rglob("*"):
                    if file_path.is_file() and not file_path.name.endswith('.metadata.json'):
                        relative_path = file_path.relative_to(base_path)
                        stat = file_path.stat()
                        
                        files.append({
                            "storage_path": str(relative_path),
                            "file_size": stat.st_size,
                            "modified_at": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                            "mime_type": mimetypes.guess_type(str(file_path))[0]
                        })
            
            return files
            
        except Exception as e:
            logger.error(f"Error listing local files: {e}")
            return []
    
    async def _list_s3_files(self, prefix: str) -> List[Dict[str, Any]]:
        """List S3 files with prefix"""
        
        try:
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                self.s3_client.list_objects_v2,
                Bucket=self.config.s3_bucket,
                Prefix=prefix
            )
            
            files = []
            for obj in response.get('Contents', []):
                files.append({
                    "storage_path": obj['Key'],
                    "file_size": obj['Size'],
                    "modified_at": obj['LastModified'].isoformat(),
                    "etag": obj.get('ETag', '').strip('"')
                })
            
            return files
            
        except Exception as e:
            logger.error(f"Error listing S3 files: {e}")
            return []
    
    async def _list_minio_files(self, prefix: str) -> List[Dict[str, Any]]:
        """List MinIO files with prefix"""
        
        try:
            objects = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: list(self.minio_client.list_objects(self.config.s3_bucket, prefix=prefix, recursive=True))
            )
            
            files = []
            for obj in objects:
                files.append({
                    "storage_path": obj.object_name,
                    "file_size": obj.size,
                    "modified_at": obj.last_modified.isoformat(),
                    "etag": obj.etag
                })
            
            return files
            
        except Exception as e:
            logger.error(f"Error listing MinIO files: {e}")
            return []

# Global storage service instance
media_storage_service = MediaStorageService()
```

**Deliverables:**
- [ ] Multi-backend storage service (local, S3, MinIO)
- [ ] Organized file storage with user/date/type hierarchy
- [ ] File deduplication using content hashing
- [ ] CDN integration for fast delivery
- [ ] Metadata storage and retrieval
- [ ] File management operations (store, retrieve, delete, list)
- [ ] Public URL generation for media access

---

## Final Deliverables Summary

### 1. Core Media Processing Engine
- [ ] Multi-format media file handler with validation
- [ ] Comprehensive metadata extraction (EXIF, GPS, technical)
- [ ] File integrity validation with checksums
- [ ] Support for images (JPEG, PNG, GIF, WebP, HEIC) and videos (MP4, MOV, AVI, etc.)

### 2. Thumbnail Generation & Optimization
- [ ] Multi-size thumbnail generation (150px, 300px, 600px, 1200px)
- [ ] Smart cropping with face detection and entropy analysis
- [ ] Image optimization for web display
- [ ] Video frame extraction for thumbnails
- [ ] Progressive JPEG generation
- [ ] Quality assessment and optimization

### 3. AI-Powered Media Analysis
- [ ] Object detection with bounding boxes
- [ ] Face detection and recognition
- [ ] Scene classification and description generation
- [ ] Color analysis and quality assessment
- [ ] Video frame analysis capability
- [ ] Confidence scoring and comprehensive error handling

### 4. Storage & CDN Integration
- [ ] Multi-backend storage (local filesystem, AWS S3, MinIO)
- [ ] Organized file hierarchy (user/date/type)
- [ ] File deduplication using content hashing
- [ ] CDN integration for global delivery
- [ ] Metadata storage and retrieval
- [ ] Complete file management operations

### 5. Privacy & Security Features
- [ ] Configurable privacy settings for AI analysis
- [ ] Face blurring capabilities
- [ ] Location data scrubbing options
- [ ] Content filtering and sensitive data detection
- [ ] User consent management for AI processing

### 6. Performance & Scalability
- [ ] Asynchronous processing for all operations
- [ ] Concurrent processing with thread pools
- [ ] Memory-efficient streaming for large files
- [ ] Batch processing capabilities
- [ ] Queue management for high-volume processing

---

## Success Validation

To validate successful completion of this epic:

1. **Format Support**: Successfully process 95%+ of common image/video formats
2. **Processing Performance**: Images < 30 seconds, videos < 2 minutes
3. **AI Accuracy**: 90%+ accuracy in object/face detection
4. **Storage Efficiency**: 50%+ size reduction while maintaining quality
5. **Thumbnail Quality**: High-quality thumbnails generated for all sizes
6. **Metadata Completeness**: Complete extraction of EXIF and technical data
7. **Privacy Compliance**: All privacy features working correctly
8. **Scalability**: Handle concurrent processing of multiple files

---

**Epic Owner**: Backend Developer + Media Processing Engineer  
**Stakeholders**: AI Team, Infrastructure Team, Privacy Team  
**Dependencies**: 1.1.2 Database Architecture, 1.1.3 Core API Framework  
**Risk Level**: Medium-High (AI model complexity, storage scalability, privacy requirements)