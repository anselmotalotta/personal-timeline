# Epic 1.1.3: Core API Framework

**Phase**: 1 - Foundation & Core Infrastructure  
**Epic**: 1.1.3 Core API Framework  
**Duration**: 2 weeks  
**Team Size**: 2 developers (Backend Lead + API Developer)  

---

## Goal

Build a robust, scalable FastAPI-based backend framework with GraphQL capabilities, comprehensive authentication/authorization, API documentation, rate limiting, and monitoring - designed specifically for AI-augmented personal data processing with privacy-first architecture.

---

## Scope Assumptions

### API Architecture
- **Framework**: FastAPI with async/await support
- **API Styles**: RESTful endpoints + GraphQL for complex queries
- **Authentication**: JWT-based with refresh tokens, OAuth2 integration
- **Authorization**: Role-based access control (RBAC) with user data isolation
- **Documentation**: Auto-generated OpenAPI/Swagger with examples

### Performance Requirements
- **Response Time**: < 200ms for simple queries, < 1s for complex operations
- **Throughput**: Handle 1000+ concurrent requests
- **Rate Limiting**: Per-user and per-endpoint limits
- **Caching**: Intelligent caching for expensive operations

### Security & Privacy
- **Data Isolation**: Complete user data separation
- **Input Validation**: Comprehensive request validation and sanitization
- **CORS**: Configurable cross-origin resource sharing
- **Security Headers**: OWASP-compliant security headers
- **Audit Logging**: All API access logged for security monitoring

---

## Success Criteria

- [ ] **API Performance**: All endpoints respond within performance targets
- [ ] **Authentication**: Secure JWT-based auth with proper token management
- [ ] **Authorization**: User data completely isolated, proper permission checks
- [ ] **Documentation**: Complete API documentation with examples and testing interface
- [ ] **Validation**: All inputs validated, proper error handling and responses
- [ ] **Monitoring**: API metrics, logging, and health checks implemented
- [ ] **Testing**: Comprehensive test suite with >90% coverage
- [ ] **Security**: All OWASP security best practices implemented

---

## Non-Goals

- Real-time WebSocket connections (HTTP-based for MVP)
- Advanced API versioning (single version initially)
- Multi-tenant architecture (single-tenant per user)
- Advanced caching strategies (basic Redis caching)
- Microservices architecture (monolithic API initially)

---

## Risks & Mitigations

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| JWT token security vulnerabilities | High | Low | Use secure token generation, short expiry, refresh tokens |
| API performance under load | Medium | Medium | Implement caching, connection pooling, load testing |
| Complex GraphQL query performance | Medium | Medium | Query complexity analysis, depth limiting, caching |
| User data leakage between accounts | High | Low | Comprehensive authorization testing, data isolation validation |
| API documentation becoming outdated | Low | High | Auto-generated docs, integration tests for examples |

---

## Detailed Tasks

### Task 1: FastAPI Core Setup & Configuration

#### 1.1 FastAPI Application Structure

**Main Application (apps/api/main.py):**
```python
from fastapi import FastAPI, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError, HTTPException
from starlette.exceptions import HTTPException as StarletteHTTPException
import uvicorn
import logging
from contextlib import asynccontextmanager
import time

from core.config import settings
from core.database import init_db
from core.logging_config import setup_logging
from core.security import SecurityHeaders
from api.v1.api import api_router
from api.health import health_router
from api.auth import auth_router
from middleware.request_logging import RequestLoggingMiddleware
from middleware.rate_limiting import RateLimitingMiddleware
from middleware.user_context import UserContextMiddleware
from services.redis_service import redis_service
from services.vector_service import vector_service

# Setup logging
setup_logging(level=settings.LOG_LEVEL, service_name="api")
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan events"""
    # Startup
    logger.info("Starting Personal Timeline API...")
    
    # Initialize database
    await init_db()
    
    # Test Redis connection
    if not await redis_service.ping():
        logger.error("Failed to connect to Redis")
        raise Exception("Redis connection failed")
    
    # Initialize vector service
    try:
        vector_service._initialize_client()
        logger.info("Vector service initialized")
    except Exception as e:
        logger.error(f"Vector service initialization failed: {e}")
        # Don't fail startup, but log the error
    
    logger.info("API startup complete")
    
    yield
    
    # Shutdown
    logger.info("Shutting down Personal Timeline API...")
    await redis_service.close()
    logger.info("API shutdown complete")

# Create FastAPI application
app = FastAPI(
    title="Personal Timeline API",
    description="AI-Augmented Personal Archive API for memory exploration and storytelling",
    version="1.0.0",
    docs_url="/docs" if settings.ENVIRONMENT != "production" else None,
    redoc_url="/redoc" if settings.ENVIRONMENT != "production" else None,
    openapi_url="/openapi.json" if settings.ENVIRONMENT != "production" else None,
    lifespan=lifespan,
    # Custom OpenAPI schema
    openapi_tags=[
        {
            "name": "Authentication",
            "description": "User authentication and authorization endpoints"
        },
        {
            "name": "Memories",
            "description": "Personal memory management and search"
        },
        {
            "name": "Stories",
            "description": "AI-generated story creation and management"
        },
        {
            "name": "People",
            "description": "People recognition and relationship management"
        },
        {
            "name": "Places",
            "description": "Location-based memory organization"
        },
        {
            "name": "Data Import",
            "description": "Data source import and processing"
        },
        {
            "name": "Health",
            "description": "System health and monitoring endpoints"
        }
    ]
)

# Security Middleware
app.add_middleware(SecurityHeaders)
app.add_middleware(
    TrustedHostMiddleware, 
    allowed_hosts=settings.ALLOWED_HOSTS
)

# CORS Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["X-Request-ID", "X-Rate-Limit-Remaining"]
)

# Compression Middleware
app.add_middleware(GZipMiddleware, minimum_size=1000)

# Custom Middleware
app.add_middleware(UserContextMiddleware)
app.add_middleware(RateLimitingMiddleware)
app.add_middleware(RequestLoggingMiddleware)

# Exception Handlers
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle request validation errors"""
    logger.warning(f"Validation error: {exc.errors()}", extra={
        "path": request.url.path,
        "method": request.method,
        "errors": exc.errors()
    })
    
    return JSONResponse(
        status_code=422,
        content={
            "error": "Validation Error",
            "message": "The request contains invalid data",
            "details": exc.errors(),
            "request_id": getattr(request.state, "request_id", None)
        }
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """Handle HTTP exceptions"""
    logger.warning(f"HTTP exception: {exc.status_code} - {exc.detail}", extra={
        "path": request.url.path,
        "method": request.method,
        "status_code": exc.status_code
    })
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": "HTTP Error",
            "message": exc.detail,
            "status_code": exc.status_code,
            "request_id": getattr(request.state, "request_id", None)
        }
    )

@app.exception_handler(StarletteHTTPException)
async def starlette_exception_handler(request: Request, exc: StarletteHTTPException):
    """Handle Starlette HTTP exceptions"""
    logger.error(f"Starlette exception: {exc.status_code} - {exc.detail}", extra={
        "path": request.url.path,
        "method": request.method,
        "status_code": exc.status_code
    })
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": "Server Error",
            "message": "An unexpected error occurred",
            "status_code": exc.status_code,
            "request_id": getattr(request.state, "request_id", None)
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    logger.error(f"Unexpected exception: {str(exc)}", extra={
        "path": request.url.path,
        "method": request.method,
        "exception_type": type(exc).__name__
    }, exc_info=True)
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": "An unexpected error occurred",
            "request_id": getattr(request.state, "request_id", None)
        }
    )

# Include routers
app.include_router(health_router, prefix="/health", tags=["Health"])
app.include_router(auth_router, prefix="/auth", tags=["Authentication"])
app.include_router(api_router, prefix="/api/v1")

# Root endpoint
@app.get("/", include_in_schema=False)
async def root():
    """Root endpoint"""
    return {
        "message": "Personal Timeline API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.DEBUG,
        log_config=None,  # Use our custom logging
        access_log=False,  # Handled by our middleware
    )
```

**Configuration Management (apps/api/core/config.py):**
```python
import os
from typing import List, Optional, Union
from pydantic import BaseSettings, validator, AnyHttpUrl
from functools import lru_cache

class Settings(BaseSettings):
    """Application settings"""
    
    # Environment
    ENVIRONMENT: str = "development"
    DEBUG: bool = False
    
    # API Configuration
    API_HOST: str = "0.0.0.0"
    API_PORT: int = 8000
    API_WORKERS: int = 1
    SECRET_KEY: str
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    REFRESH_TOKEN_EXPIRE_DAYS: int = 7
    
    # Database
    DATABASE_URL: str
    DATABASE_POOL_SIZE: int = 20
    DATABASE_MAX_OVERFLOW: int = 30
    
    # Redis
    REDIS_URL: str = "redis://localhost:6379"
    
    # Vector Database
    CHROMA_HOST: str = "localhost"
    CHROMA_PORT: int = 8001
    CLICKHOUSE_HOST: str = "localhost"
    CLICKHOUSE_PORT: int = 8123
    
    # AI Services
    OPENAI_API_KEY: Optional[str] = None
    ANTHROPIC_API_KEY: Optional[str] = None
    
    # File Storage
    MINIO_ENDPOINT: str = "localhost:9000"
    MINIO_ACCESS_KEY: str = "minioadmin"
    MINIO_SECRET_KEY: str = "minioadmin"
    MINIO_BUCKET_NAME: str = "personal-timeline"
    MINIO_SECURE: bool = False
    
    # Security
    ALLOWED_HOSTS: List[str] = ["*"]
    CORS_ORIGINS: List[Union[str, AnyHttpUrl]] = ["*"]
    
    # Rate Limiting
    RATE_LIMIT_REQUESTS: int = 100
    RATE_LIMIT_WINDOW: int = 60  # seconds
    
    # Logging
    LOG_LEVEL: str = "INFO"
    
    # Monitoring
    PROMETHEUS_ENABLED: bool = True
    SENTRY_DSN: Optional[str] = None
    
    @validator("CORS_ORIGINS", pre=True)
    def assemble_cors_origins(cls, v: Union[str, List[str]]) -> Union[List[str], str]:
        if isinstance(v, str) and not v.startswith("["):
            return [i.strip() for i in v.split(",")]
        elif isinstance(v, (list, str)):
            return v
        raise ValueError(v)
    
    @validator("ALLOWED_HOSTS", pre=True)
    def assemble_allowed_hosts(cls, v: Union[str, List[str]]) -> Union[List[str], str]:
        if isinstance(v, str) and not v.startswith("["):
            return [i.strip() for i in v.split(",")]
        elif isinstance(v, (list, str)):
            return v
        raise ValueError(v)
    
    @validator("DEBUG", pre=True)
    def set_debug_from_env(cls, v: Union[bool, str]) -> bool:
        if isinstance(v, str):
            return v.lower() in ("true", "1", "yes", "on")
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = True

@lru_cache()
def get_settings() -> Settings:
    """Get cached settings instance"""
    return Settings()

settings = get_settings()
```

**Deliverables:**
- [ ] FastAPI application with proper structure and configuration
- [ ] Comprehensive middleware stack for security and monitoring
- [ ] Exception handling with proper error responses
- [ ] Environment-based configuration management
- [ ] Application lifecycle management

#### 1.2 Security Framework Implementation

**Security Headers Middleware (apps/api/middleware/security.py):**
```python
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import Response as StarletteResponse
import secrets
import hashlib

class SecurityHeaders(BaseHTTPMiddleware):
    """Add security headers to all responses"""
    
    async def dispatch(self, request: Request, call_next):
        response: StarletteResponse = await call_next(request)
        
        # Generate nonce for CSP
        nonce = secrets.token_urlsafe(16)
        
        # Content Security Policy
        csp_policy = (
            f"default-src 'self'; "
            f"script-src 'self' 'nonce-{nonce}' 'unsafe-inline'; "
            f"style-src 'self' 'unsafe-inline'; "
            f"img-src 'self' data: https:; "
            f"font-src 'self' data:; "
            f"connect-src 'self' https:; "
            f"media-src 'self'; "
            f"object-src 'none'; "
            f"frame-ancestors 'none'; "
            f"base-uri 'self'; "
            f"form-action 'self'"
        )
        
        # Security headers
        security_headers = {
            "X-Content-Type-Options": "nosniff",
            "X-Frame-Options": "DENY",
            "X-XSS-Protection": "1; mode=block",
            "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
            "Referrer-Policy": "strict-origin-when-cross-origin",
            "Content-Security-Policy": csp_policy,
            "Permissions-Policy": (
                "geolocation=(), "
                "microphone=(), "
                "camera=(), "
                "payment=(), "
                "usb=(), "
                "magnetometer=(), "
                "gyroscope=(), "
                "speaker=()"
            ),
            "X-Permitted-Cross-Domain-Policies": "none",
            "Cross-Origin-Embedder-Policy": "require-corp",
            "Cross-Origin-Opener-Policy": "same-origin",
            "Cross-Origin-Resource-Policy": "same-origin"
        }
        
        # Add headers to response
        for header, value in security_headers.items():
            response.headers[header] = value
        
        # Add nonce to request state for templates
        request.state.csp_nonce = nonce
        
        return response
```

**Authentication System (apps/api/core/auth.py):**
```python
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from jose import JWTError, jwt
from passlib.context import CryptContext
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
import secrets
import hashlib

from core.config import settings
from core.database import get_db
from models.database import User
from services.redis_service import redis_service

# Password hashing
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# JWT token handling
security = HTTPBearer(auto_error=False)

class AuthService:
    """Authentication service"""
    
    @staticmethod
    def verify_password(plain_password: str, hashed_password: str) -> bool:
        """Verify password against hash"""
        return pwd_context.verify(plain_password, hashed_password)
    
    @staticmethod
    def get_password_hash(password: str) -> str:
        """Generate password hash"""
        return pwd_context.hash(password)
    
    @staticmethod
    def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
        """Create JWT access token"""
        to_encode = data.copy()
        
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
        
        to_encode.update({"exp": expire, "type": "access"})
        
        encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm="HS256")
        return encoded_jwt
    
    @staticmethod
    def create_refresh_token(user_id: str) -> str:
        """Create refresh token"""
        token_data = {
            "sub": user_id,
            "type": "refresh",
            "exp": datetime.utcnow() + timedelta(days=settings.REFRESH_TOKEN_EXPIRE_DAYS),
            "jti": secrets.token_urlsafe(32)  # JWT ID for revocation
        }
        
        encoded_jwt = jwt.encode(token_data, settings.SECRET_KEY, algorithm="HS256")
        return encoded_jwt
    
    @staticmethod
    async def verify_token(token: str, token_type: str = "access") -> Optional[Dict[str, Any]]:
        """Verify JWT token"""
        try:
            payload = jwt.decode(token, settings.SECRET_KEY, algorithms=["HS256"])
            
            # Check token type
            if payload.get("type") != token_type:
                return None
            
            # Check expiration
            exp = payload.get("exp")
            if exp is None or datetime.utcnow() > datetime.fromtimestamp(exp):
                return None
            
            # Check if refresh token is revoked (for refresh tokens)
            if token_type == "refresh":
                jti = payload.get("jti")
                if jti and await redis_service.exists_cache(f"revoked_token:{jti}"):
                    return None
            
            return payload
            
        except JWTError:
            return None
    
    @staticmethod
    async def revoke_refresh_token(token: str) -> bool:
        """Revoke refresh token"""
        try:
            payload = jwt.decode(token, settings.SECRET_KEY, algorithms=["HS256"])
            jti = payload.get("jti")
            
            if jti:
                # Store revoked token ID with expiration
                exp = payload.get("exp")
                if exp:
                    ttl = max(0, exp - int(datetime.utcnow().timestamp()))
                    await redis_service.set_cache(f"revoked_token:{jti}", "revoked", expire=ttl)
                    return True
            
            return False
            
        except JWTError:
            return False
    
    @staticmethod
    async def authenticate_user(db: AsyncSession, email: str, password: str) -> Optional[User]:
        """Authenticate user with email and password"""
        # Get user by email
        result = await db.execute(
            select(User).where(User.email == email, User.is_active == True)
        )
        user = result.scalar_one_or_none()
        
        if not user:
            return None
        
        # Verify password
        if not AuthService.verify_password(password, user.password_hash):
            return None
        
        # Update last login
        user.last_login = datetime.utcnow()
        await db.commit()
        
        return user

async def get_current_user(
    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security),
    db: AsyncSession = Depends(get_db)
) -> User:
    """Get current authenticated user"""
    
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    
    if not credentials:
        raise credentials_exception
    
    # Verify token
    payload = await AuthService.verify_token(credentials.credentials, "access")
    if payload is None:
        raise credentials_exception
    
    user_id = payload.get("sub")
    if user_id is None:
        raise credentials_exception
    
    # Get user from database
    result = await db.execute(
        select(User).where(User.id == user_id, User.is_active == True)
    )
    user = result.scalar_one_or_none()
    
    if user is None:
        raise credentials_exception
    
    return user

async def get_current_active_user(current_user: User = Depends(get_current_user)) -> User:
    """Get current active user"""
    if not current_user.is_active:
        raise HTTPException(status_code=400, detail="Inactive user")
    return current_user

# Rate limiting decorator
def rate_limit(requests: int = 100, window: int = 60):
    """Rate limiting decorator"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            # Get user from request context
            request = kwargs.get('request') or args[0] if args else None
            if hasattr(request, 'state') and hasattr(request.state, 'user'):
                user_id = str(request.state.user.id)
                key = f"rate_limit:{user_id}:{func.__name__}"
            else:
                # Fallback to IP-based rate limiting
                client_ip = request.client.host if request else "unknown"
                key = f"rate_limit:ip:{client_ip}:{func.__name__}"
            
            # Check rate limit
            allowed, remaining, window_time = await redis_service.check_rate_limit(
                key, requests, window
            )
            
            if not allowed:
                raise HTTPException(
                    status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                    detail="Rate limit exceeded",
                    headers={
                        "X-Rate-Limit-Remaining": "0",
                        "X-Rate-Limit-Window": str(window_time),
                        "Retry-After": str(window_time)
                    }
                )
            
            # Add rate limit headers to response
            response = await func(*args, **kwargs)
            if hasattr(response, 'headers'):
                response.headers["X-Rate-Limit-Remaining"] = str(remaining)
                response.headers["X-Rate-Limit-Window"] = str(window_time)
            
            return response
        
        return wrapper
    return decorator
```

**User Context Middleware (apps/api/middleware/user_context.py):**
```python
from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import Response
import uuid
from contextvars import ContextVar

from core.logging_config import request_id_var, user_id_var

class UserContextMiddleware(BaseHTTPMiddleware):
    """Middleware to set user context for logging and request tracking"""
    
    async def dispatch(self, request: Request, call_next):
        # Generate request ID
        request_id = str(uuid.uuid4())
        request_id_var.set(request_id)
        request.state.request_id = request_id
        
        # Try to extract user ID from token (if present)
        user_id = None
        auth_header = request.headers.get("Authorization")
        if auth_header and auth_header.startswith("Bearer "):
            try:
                from core.auth import AuthService
                token = auth_header.split(" ")[1]
                payload = await AuthService.verify_token(token, "access")
                if payload:
                    user_id = payload.get("sub")
                    user_id_var.set(user_id)
                    request.state.user_id = user_id
            except Exception:
                # Ignore token parsing errors in middleware
                pass
        
        response = await call_next(request)
        
        # Add request ID to response headers
        response.headers["X-Request-ID"] = request_id
        
        return response
```

**Deliverables:**
- [ ] Comprehensive security headers middleware
- [ ] JWT-based authentication with refresh tokens
- [ ] Password hashing and verification
- [ ] User context middleware for request tracking
- [ ] Rate limiting implementation
- [ ] Token revocation system

### Task 2: API Endpoints & Validation

#### 2.1 Core API Models & Validation

**Pydantic Models (apps/api/models/api_models.py):**
```python
from pydantic import BaseModel, Field, validator, EmailStr
from typing import Optional, List, Dict, Any, Union
from datetime import datetime
from uuid import UUID
from enum import Enum

# Base Models
class BaseResponse(BaseModel):
    """Base response model"""
    success: bool = True
    message: Optional[str] = None
    request_id: Optional[str] = None

class PaginationParams(BaseModel):
    """Pagination parameters"""
    page: int = Field(1, ge=1, description="Page number")
    size: int = Field(20, ge=1, le=100, description="Items per page")
    
    @property
    def offset(self) -> int:
        return (self.page - 1) * self.size

class PaginatedResponse(BaseResponse):
    """Paginated response model"""
    page: int
    size: int
    total: int
    pages: int
    has_next: bool
    has_prev: bool

# Authentication Models
class UserRegistration(BaseModel):
    """User registration model"""
    email: EmailStr = Field(..., description="User email address")
    password: str = Field(..., min_length=8, max_length=128, description="User password")
    confirm_password: str = Field(..., description="Password confirmation")
    
    @validator('confirm_password')
    def passwords_match(cls, v, values, **kwargs):
        if 'password' in values and v != values['password']:
            raise ValueError('Passwords do not match')
        return v
    
    @validator('password')
    def validate_password_strength(cls, v):
        """Validate password strength"""
        if len(v) < 8:
            raise ValueError('Password must be at least 8 characters long')
        
        has_upper = any(c.isupper() for c in v)
        has_lower = any(c.islower() for c in v)
        has_digit = any(c.isdigit() for c in v)
        has_special = any(c in "!@#$%^&*()_+-=[]{}|;:,.<>?" for c in v)
        
        if not (has_upper and has_lower and has_digit and has_special):
            raise ValueError(
                'Password must contain at least one uppercase letter, '
                'one lowercase letter, one digit, and one special character'
            )
        
        return v

class UserLogin(BaseModel):
    """User login model"""
    email: EmailStr = Field(..., description="User email address")
    password: str = Field(..., description="User password")

class TokenResponse(BaseResponse):
    """Token response model"""
    access_token: str = Field(..., description="JWT access token")
    refresh_token: str = Field(..., description="JWT refresh token")
    token_type: str = Field("bearer", description="Token type")
    expires_in: int = Field(..., description="Token expiration in seconds")

class RefreshTokenRequest(BaseModel):
    """Refresh token request"""
    refresh_token: str = Field(..., description="Refresh token")

# User Models
class UserProfile(BaseModel):
    """User profile model"""
    id: UUID
    email: str
    created_at: datetime
    last_login: Optional[datetime]
    preferences: Dict[str, Any] = {}
    privacy_settings: Dict[str, Any] = {}
    
    class Config:
        from_attributes = True

class UserPreferencesUpdate(BaseModel):
    """User preferences update model"""
    preferences: Dict[str, Any] = Field(..., description="User preferences")
    privacy_settings: Optional[Dict[str, Any]] = Field(None, description="Privacy settings")

# Memory Models
class ContentType(str, Enum):
    """Content type enumeration"""
    POST = "post"
    PHOTO = "photo"
    VIDEO = "video"
    CHECK_IN = "check_in"
    STORY = "story"

class MemoryBase(BaseModel):
    """Base memory model"""
    title: Optional[str] = Field(None, max_length=500, description="Memory title")
    description: Optional[str] = Field(None, description="Memory description")
    content_type: ContentType = Field(..., description="Type of content")
    timestamp: datetime = Field(..., description="Memory timestamp")
    latitude: Optional[float] = Field(None, ge=-90, le=90, description="Latitude")
    longitude: Optional[float] = Field(None, ge=-180, le=180, description="Longitude")
    location_name: Optional[str] = Field(None, max_length=255, description="Location name")

class MemoryCreate(MemoryBase):
    """Memory creation model"""
    original_content: Dict[str, Any] = Field(..., description="Original content data")

class MemoryUpdate(BaseModel):
    """Memory update model"""
    title: Optional[str] = Field(None, max_length=500)
    description: Optional[str] = None
    ai_tags: Optional[List[str]] = None
    
class MemoryResponse(MemoryBase):
    """Memory response model"""
    id: UUID
    user_id: UUID
    ai_summary: Optional[str] = None
    ai_tags: Optional[List[str]] = None
    sentiment_score: Optional[float] = None
    created_at: datetime
    updated_at: datetime
    media_files: List['MediaFileResponse'] = []
    people: List['PersonResponse'] = []
    
    class Config:
        from_attributes = True

class MemorySearchRequest(BaseModel):
    """Memory search request"""
    query: str = Field(..., min_length=1, max_length=500, description="Search query")
    content_types: Optional[List[ContentType]] = Field(None, description="Filter by content types")
    start_date: Optional[datetime] = Field(None, description="Start date filter")
    end_date: Optional[datetime] = Field(None, description="End date filter")
    has_media: Optional[bool] = Field(None, description="Filter by media presence")
    people: Optional[List[str]] = Field(None, description="Filter by people names")
    location_radius_km: Optional[float] = Field(None, ge=0, le=1000, description="Location radius in km")
    latitude: Optional[float] = Field(None, ge=-90, le=90)
    longitude: Optional[float] = Field(None, ge=-180, le=180)

class MemorySearchResponse(PaginatedResponse):
    """Memory search response"""
    data: List[MemoryResponse]
    query: str
    filters_applied: Dict[str, Any]

# Media Models
class MediaFileResponse(BaseModel):
    """Media file response model"""
    id: UUID
    file_type: str
    original_filename: Optional[str]
    file_path: str
    thumbnail_path: Optional[str]
    file_size: Optional[int]
    dimensions: Optional[Dict[str, int]]
    duration: Optional[int]
    ai_analysis: Dict[str, Any] = {}
    
    class Config:
        from_attributes = True

# People Models
class PersonResponse(BaseModel):
    """Person response model"""
    id: UUID
    name: str
    relationship_type: Optional[str]
    interaction_count: int
    first_appearance: Optional[datetime]
    last_appearance: Optional[datetime]
    
    class Config:
        from_attributes = True

# Story Models
class StoryType(str, Enum):
    """Story type enumeration"""
    CHRONOLOGICAL = "chronological"
    THEMATIC = "thematic"
    PEOPLE_CENTERED = "people_centered"
    PLACE_CENTERED = "place_centered"
    PARALLEL = "parallel"

class NarrativeStyle(str, Enum):
    """Narrative style enumeration"""
    DOCUMENTARY = "documentary"
    MEMOIR = "memoir"
    CINEMATIC = "cinematic"
    MINIMALIST = "minimalist"

class StoryGenerationRequest(BaseModel):
    """Story generation request"""
    title: str = Field(..., min_length=1, max_length=255, description="Story title")
    story_type: StoryType = Field(..., description="Type of story to generate")
    narrative_style: NarrativeStyle = Field(NarrativeStyle.MEMOIR, description="Narrative style")
    
    # Content filters
    start_date: Optional[datetime] = Field(None, description="Include memories from this date")
    end_date: Optional[datetime] = Field(None, description="Include memories until this date")
    content_types: Optional[List[ContentType]] = Field(None, description="Include specific content types")
    people: Optional[List[str]] = Field(None, description="Focus on specific people")
    places: Optional[List[str]] = Field(None, description="Focus on specific places")
    themes: Optional[List[str]] = Field(None, description="Focus on specific themes")
    
    # Generation options
    max_memories: int = Field(20, ge=5, le=100, description="Maximum memories to include")
    include_voice_narration: bool = Field(True, description="Generate voice narration")
    include_video: bool = Field(False, description="Generate video version")
    
    # Style preferences
    tone: Optional[str] = Field("warm", description="Story tone (warm, neutral, dramatic)")
    length: Optional[str] = Field("medium", description="Story length (short, medium, long)")

class StoryResponse(BaseModel):
    """Story response model"""
    id: UUID
    user_id: UUID
    title: str
    story_type: StoryType
    narrative_style: NarrativeStyle
    status: str
    content: Dict[str, Any]
    audio_narration_url: Optional[str]
    video_url: Optional[str]
    thumbnail_url: Optional[str]
    quality_score: Optional[float]
    user_rating: Optional[int]
    view_count: int
    created_at: datetime
    updated_at: datetime
    
    class Config:
        from_attributes = True

class StoryGenerationStatus(BaseModel):
    """Story generation status"""
    task_id: UUID
    status: str  # pending, processing, completed, failed
    progress: int = Field(0, ge=0, le=100, description="Progress percentage")
    message: Optional[str] = None
    estimated_completion: Optional[datetime] = None
    result: Optional[StoryResponse] = None

# Data Import Models
class DataSourceType(str, Enum):
    """Data source type enumeration"""
    FACEBOOK = "facebook"
    INSTAGRAM = "instagram"
    GOOGLE_PHOTOS = "google_photos"
    TWITTER = "twitter"
    MANUAL = "manual"

class DataImportRequest(BaseModel):
    """Data import request"""
    source_type: DataSourceType = Field(..., description="Type of data source")
    source_name: str = Field(..., max_length=255, description="Name of the data source")
    file_path: Optional[str] = Field(None, description="Path to uploaded file")
    
class DataImportResponse(BaseModel):
    """Data import response"""
    id: UUID
    source_type: DataSourceType
    source_name: str
    status: str
    total_items: int
    processed_items: int
    failed_items: int
    processing_started_at: Optional[datetime]
    processing_completed_at: Optional[datetime]
    error_log: Optional[str]
    
    class Config:
        from_attributes = True

# Health Models
class HealthStatus(BaseModel):
    """Health status model"""
    status: str = Field(..., description="Overall health status")
    timestamp: datetime = Field(..., description="Health check timestamp")
    version: str = Field(..., description="API version")
    environment: str = Field(..., description="Environment name")
    
class HealthDetail(HealthStatus):
    """Detailed health status"""
    services: Dict[str, Dict[str, Any]] = Field(..., description="Service health details")
    system: Dict[str, Any] = Field(..., description="System information")

# Error Models
class ErrorResponse(BaseModel):
    """Error response model"""
    success: bool = False
    error: str = Field(..., description="Error type")
    message: str = Field(..., description="Error message")
    details: Optional[Dict[str, Any]] = Field(None, description="Error details")
    request_id: Optional[str] = Field(None, description="Request ID for tracking")

# Update forward references
MemoryResponse.model_rebuild()
```

**Input Validation Utilities (apps/api/utils/validation.py):**
```python
from typing import Any, Dict, List, Optional, Union
from pydantic import BaseModel, ValidationError
from fastapi import HTTPException, status
import re
import bleach
from urllib.parse import urlparse

class ValidationUtils:
    """Utilities for input validation and sanitization"""
    
    @staticmethod
    def sanitize_html(text: str, allowed_tags: Optional[List[str]] = None) -> str:
        """Sanitize HTML content"""
        if allowed_tags is None:
            allowed_tags = ['b', 'i', 'u', 'em', 'strong', 'p', 'br']
        
        return bleach.clean(text, tags=allowed_tags, strip=True)
    
    @staticmethod
    def validate_email(email: str) -> bool:
        """Validate email format"""
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return re.match(pattern, email) is not None
    
    @staticmethod
    def validate_url(url: str) -> bool:
        """Validate URL format"""
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except Exception:
            return False
    
    @staticmethod
    def validate_file_type(filename: str, allowed_types: List[str]) -> bool:
        """Validate file type by extension"""
        if not filename:
            return False
        
        extension = filename.lower().split('.')[-1]
        return extension in [t.lower() for t in allowed_types]
    
    @staticmethod
    def validate_image_dimensions(width: int, height: int, max_size: int = 4096) -> bool:
        """Validate image dimensions"""
        return 0 < width <= max_size and 0 < height <= max_size
    
    @staticmethod
    def validate_coordinates(latitude: float, longitude: float) -> bool:
        """Validate geographic coordinates"""
        return -90 <= latitude <= 90 and -180 <= longitude <= 180
    
    @staticmethod
    def sanitize_search_query(query: str) -> str:
        """Sanitize search query"""
        # Remove potentially dangerous characters
        sanitized = re.sub(r'[<>"\';\\]', '', query)
        
        # Limit length
        sanitized = sanitized[:500]
        
        # Remove excessive whitespace
        sanitized = ' '.join(sanitized.split())
        
        return sanitized
    
    @staticmethod
    def validate_json_structure(data: Dict[str, Any], required_fields: List[str]) -> bool:
        """Validate JSON structure has required fields"""
        return all(field in data for field in required_fields)
    
    @staticmethod
    def validate_date_range(start_date: Optional[str], end_date: Optional[str]) -> bool:
        """Validate date range"""
        if not start_date or not end_date:
            return True
        
        try:
            from datetime import datetime
            start = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
            end = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
            return start <= end
        except Exception:
            return False

def validate_request_model(model_class: BaseModel, data: Dict[str, Any]) -> BaseModel:
    """Validate request data against Pydantic model"""
    try:
        return model_class(**data)
    except ValidationError as e:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail={
                "error": "Validation Error",
                "message": "The request contains invalid data",
                "details": e.errors()
            }
        )

def validate_pagination(page: int, size: int, max_size: int = 100) -> tuple:
    """Validate pagination parameters"""
    if page < 1:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Page number must be greater than 0"
        )
    
    if size < 1 or size > max_size:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Page size must be between 1 and {max_size}"
        )
    
    offset = (page - 1) * size
    return offset, size
```

**Deliverables:**
- [ ] Comprehensive Pydantic models for all API endpoints
- [ ] Input validation and sanitization utilities
- [ ] Error handling and response models
- [ ] Type-safe request/response models
- [ ] Validation decorators and helpers

#### 2.2 Core API Endpoints Implementation

**Memory Management API (apps/api/api/v1/memories.py):**
```python
from fastapi import APIRouter, Depends, HTTPException, status, Query, Body
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_, or_
from sqlalchemy.orm import selectinload
from typing import List, Optional
from uuid import UUID
import logging

from core.database import get_db
from core.auth import get_current_active_user
from models.database import User, Memory, MediaFile, Person, MemoryPerson
from models.api_models import (
    MemoryResponse, MemoryCreate, MemoryUpdate, MemorySearchRequest, 
    MemorySearchResponse, PaginationParams, BaseResponse
)
from services.vector_service import vector_service
from services.redis_service import redis_service
from utils.validation import ValidationUtils
from utils.query_utils import QueryOptimizer

router = APIRouter()
logger = logging.getLogger(__name__)

@router.get("/", response_model=MemorySearchResponse)
async def get_memories(
    pagination: PaginationParams = Depends(),
    content_types: Optional[List[str]] = Query(None, description="Filter by content types"),
    start_date: Optional[str] = Query(None, description="Start date (ISO format)"),
    end_date: Optional[str] = Query(None, description="End date (ISO format)"),
    has_media: Optional[bool] = Query(None, description="Filter by media presence"),
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db)
):
    """Get user's memories with filtering and pagination"""
    
    # Validate date range
    if not ValidationUtils.validate_date_range(start_date, end_date):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid date range"
        )
    
    # Check cache first
    cache_key = f"memories:{current_user.id}:{pagination.page}:{pagination.size}:{content_types}:{start_date}:{end_date}:{has_media}"
    cached_result = await redis_service.get_cache(cache_key)
    
    if cached_result:
        logger.debug(f"Returning cached memories for user {current_user.id}")
        return cached_result
    
    try:
        # Convert date strings to datetime objects
        start_datetime = None
        end_datetime = None
        if start_date:
            from datetime import datetime
            start_datetime = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
        if end_date:
            from datetime import datetime
            end_datetime = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
        
        # Use optimized query
        memories, total = await QueryOptimizer.get_timeline_memories(
            db,
            str(current_user.id),
            limit=pagination.size,
            offset=pagination.offset,
            start_date=start_datetime,
            end_date=end_datetime,
            content_types=content_types
        )
        
        # Calculate pagination info
        pages = (total + pagination.size - 1) // pagination.size
        has_next = pagination.page < pages
        has_prev = pagination.page > 1
        
        # Convert to response models
        memory_responses = [MemoryResponse.from_orm(memory) for memory in memories]
        
        response = MemorySearchResponse(
            data=memory_responses,
            page=pagination.page,
            size=pagination.size,
            total=total,
            pages=pages,
            has_next=has_next,
            has_prev=has_prev,
            query="",
            filters_applied={
                "content_types": content_types,
                "start_date": start_date,
                "end_date": end_date,
                "has_media": has_media
            }
        )
        
        # Cache result for 5 minutes
        await redis_service.set_cache(cache_key, response.dict(), expire=300)
        
        logger.info(f"Retrieved {len(memory_responses)} memories for user {current_user.id}")
        return response
        
    except Exception as e:
        logger.error(f"Error retrieving memories: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve memories"
        )

@router.post("/search", response_model=MemorySearchResponse)
async def search_memories(
    search_request: MemorySearchRequest,
    pagination: PaginationParams = Depends(),
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db)
):
    """Search memories using natural language query"""
    
    # Sanitize search query
    sanitized_query = ValidationUtils.sanitize_search_query(search_request.query)
    
    if not sanitized_query:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Search query cannot be empty"
        )
    
    try:
        # Build filters for vector search
        filters = {}
        
        if search_request.content_types:
            filters["content_types"] = [ct.value for ct in search_request.content_types]
        
        if search_request.start_date and search_request.end_date:
            filters["date_range"] = (search_request.start_date, search_request.end_date)
        
        if search_request.has_media is not None:
            filters["has_media"] = search_request.has_media
        
        # Perform vector similarity search
        vector_results = await vector_service.similarity_search(
            user_id=current_user.id,
            query_text=sanitized_query,
            limit=pagination.size * 2,  # Get more candidates for re-ranking
            filters=filters
        )
        
        # Extract memory IDs from vector results
        memory_ids = [UUID(result["memory_id"]) for result in vector_results]
        
        if not memory_ids:
            return MemorySearchResponse(
                data=[],
                page=pagination.page,
                size=pagination.size,
                total=0,
                pages=0,
                has_next=False,
                has_prev=False,
                query=sanitized_query,
                filters_applied=filters
            )
        
        # Get full memory objects from database
        query = select(Memory).options(
            selectinload(Memory.media_files),
            selectinload(Memory.memory_people).selectinload(MemoryPerson.person)
        ).where(
            and_(
                Memory.id.in_(memory_ids),
                Memory.user_id == current_user.id
            )
        )
        
        result = await db.execute(query)
        memories = result.scalars().all()
        
        # Sort memories by vector similarity score
        memory_dict = {str(memory.id): memory for memory in memories}
        sorted_memories = []
        
        for vector_result in vector_results:
            memory_id = vector_result["memory_id"]
            if memory_id in memory_dict:
                memory = memory_dict[memory_id]
                # Add similarity score to memory object
                memory.similarity_score = vector_result["similarity_score"]
                sorted_memories.append(memory)
        
        # Apply pagination
        start_idx = pagination.offset
        end_idx = start_idx + pagination.size
        paginated_memories = sorted_memories[start_idx:end_idx]
        
        # Calculate pagination info
        total = len(sorted_memories)
        pages = (total + pagination.size - 1) // pagination.size
        has_next = pagination.page < pages
        has_prev = pagination.page > 1
        
        # Convert to response models
        memory_responses = []
        for memory in paginated_memories:
            memory_response = MemoryResponse.from_orm(memory)
            # Add similarity score to response
            memory_response.similarity_score = getattr(memory, 'similarity_score', 0.0)
            memory_responses.append(memory_response)
        
        response = MemorySearchResponse(
            data=memory_responses,
            page=pagination.page,
            size=pagination.size,
            total=total,
            pages=pages,
            has_next=has_next,
            has_prev=has_prev,
            query=sanitized_query,
            filters_applied=filters
        )
        
        logger.info(f"Search '{sanitized_query}' returned {len(memory_responses)} memories for user {current_user.id}")
        return response
        
    except Exception as e:
        logger.error(f"Error searching memories: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to search memories"
        )

@router.get("/{memory_id}", response_model=MemoryResponse)
async def get_memory(
    memory_id: UUID,
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db)
):
    """Get a specific memory by ID"""
    
    # Check cache first
    cache_key = f"memory:{memory_id}:{current_user.id}"
    cached_memory = await redis_service.get_cache(cache_key)
    
    if cached_memory:
        return MemoryResponse(**cached_memory)
    
    try:
        # Query memory with related data
        query = select(Memory).options(
            selectinload(Memory.media_files),
            selectinload(Memory.memory_people).selectinload(MemoryPerson.person)
        ).where(
            and_(
                Memory.id == memory_id,
                Memory.user_id == current_user.id
            )
        )
        
        result = await db.execute(query)
        memory = result.scalar_one_or_none()
        
        if not memory:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Memory not found"
            )
        
        memory_response = MemoryResponse.from_orm(memory)
        
        # Cache for 10 minutes
        await redis_service.set_cache(cache_key, memory_response.dict(), expire=600)
        
        return memory_response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving memory {memory_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve memory"
        )

@router.put("/{memory_id}", response_model=MemoryResponse)
async def update_memory(
    memory_id: UUID,
    memory_update: MemoryUpdate,
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db)
):
    """Update a memory"""
    
    try:
        # Get existing memory
        query = select(Memory).where(
            and_(
                Memory.id == memory_id,
                Memory.user_id == current_user.id
            )
        )
        
        result = await db.execute(query)
        memory = result.scalar_one_or_none()
        
        if not memory:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Memory not found"
            )
        
        # Update fields
        update_data = memory_update.dict(exclude_unset=True)
        for field, value in update_data.items():
            setattr(memory, field, value)
        
        # Update timestamp
        from datetime import datetime
        memory.updated_at = datetime.utcnow()
        
        await db.commit()
        await db.refresh(memory)
        
        # Update vector embedding if content changed
        if 'title' in update_data or 'description' in update_data or 'ai_tags' in update_data:
            await vector_service.update_memory_embedding(current_user.id, memory)
        
        # Invalidate cache
        cache_key = f"memory:{memory_id}:{current_user.id}"
        await redis_service.delete_cache(cache_key)
        
        # Get updated memory with relations
        query = select(Memory).options(
            selectinload(Memory.media_files),
            selectinload(Memory.memory_people).selectinload(MemoryPerson.person)
        ).where(Memory.id == memory_id)
        
        result = await db.execute(query)
        updated_memory = result.scalar_one()
        
        logger.info(f"Updated memory {memory_id} for user {current_user.id}")
        return MemoryResponse.from_orm(updated_memory)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating memory {memory_id}: {e}")
        await db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to update memory"
        )

@router.delete("/{memory_id}", response_model=BaseResponse)
async def delete_memory(
    memory_id: UUID,
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db)
):
    """Delete a memory"""
    
    try:
        # Get memory to verify ownership
        query = select(Memory).where(
            and_(
                Memory.id == memory_id,
                Memory.user_id == current_user.id
            )
        )
        
        result = await db.execute(query)
        memory = result.scalar_one_or_none()
        
        if not memory:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Memory not found"
            )
        
        # Delete from vector database
        await vector_service.delete_memory_embedding(current_user.id, memory_id)
        
        # Delete from database (cascade will handle related records)
        await db.delete(memory)
        await db.commit()
        
        # Invalidate cache
        cache_key = f"memory:{memory_id}:{current_user.id}"
        await redis_service.delete_cache(cache_key)
        
        logger.info(f"Deleted memory {memory_id} for user {current_user.id}")
        return BaseResponse(message="Memory deleted successfully")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting memory {memory_id}: {e}")
        await db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to delete memory"
        )

@router.get("/statistics/overview")
async def get_memory_statistics(
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db)
):
    """Get user's memory statistics"""
    
    # Check cache first
    cache_key = f"memory_stats:{current_user.id}"
    cached_stats = await redis_service.get_cache(cache_key)
    
    if cached_stats:
        return cached_stats
    
    try:
        stats = await QueryOptimizer.get_memory_statistics(db, str(current_user.id))
        
        # Cache for 1 hour
        await redis_service.set_cache(cache_key, stats, expire=3600)
        
        return stats
        
    except Exception as e:
        logger.error(f"Error getting memory statistics: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to get memory statistics"
        )
```

**Authentication API (apps/api/api/auth.py):**
```python
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import HTTPBearer
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from datetime import datetime, timedelta
import logging

from core.database import get_db
from core.auth import AuthService, get_current_user
from models.database import User
from models.api_models import (
    UserRegistration, UserLogin, TokenResponse, RefreshTokenRequest,
    UserProfile, UserPreferencesUpdate, BaseResponse
)
from services.redis_service import redis_service

router = APIRouter()
security = HTTPBearer()
logger = logging.getLogger(__name__)

@router.post("/register", response_model=TokenResponse)
async def register_user(
    user_data: UserRegistration,
    db: AsyncSession = Depends(get_db)
):
    """Register a new user"""
    
    try:
        # Check if user already exists
        existing_user = await db.execute(
            select(User).where(User.email == user_data.email)
        )
        
        if existing_user.scalar_one_or_none():
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Email already registered"
            )
        
        # Create new user
        hashed_password = AuthService.get_password_hash(user_data.password)
        
        new_user = User(
            email=user_data.email,
            password_hash=hashed_password,
            is_active=True,
            is_verified=False,  # Email verification required
            created_at=datetime.utcnow()
        )
        
        db.add(new_user)
        await db.commit()
        await db.refresh(new_user)
        
        # Generate tokens
        access_token = AuthService.create_access_token(
            data={"sub": str(new_user.id)}
        )
        refresh_token = AuthService.create_refresh_token(str(new_user.id))
        
        logger.info(f"New user registered: {user_data.email}")
        
        return TokenResponse(
            access_token=access_token,
            refresh_token=refresh_token,
            expires_in=30 * 60  # 30 minutes
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Registration error: {e}")
        await db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Registration failed"
        )

@router.post("/login", response_model=TokenResponse)
async def login_user(
    user_credentials: UserLogin,
    db: AsyncSession = Depends(get_db)
):
    """Authenticate user and return tokens"""
    
    try:
        # Authenticate user
        user = await AuthService.authenticate_user(
            db, user_credentials.email, user_credentials.password
        )
        
        if not user:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Incorrect email or password"
            )
        
        # Generate tokens
        access_token = AuthService.create_access_token(
            data={"sub": str(user.id)}
        )
        refresh_token = AuthService.create_refresh_token(str(user.id))
        
        # Store refresh token in Redis for tracking
        await redis_service.set_cache(
            f"refresh_token:{user.id}",
            refresh_token,
            expire=7 * 24 * 60 * 60  # 7 days
        )
        
        logger.info(f"User logged in: {user.email}")
        
        return TokenResponse(
            access_token=access_token,
            refresh_token=refresh_token,
            expires_in=30 * 60  # 30 minutes
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Login error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Login failed"
        )

@router.post("/refresh", response_model=TokenResponse)
async def refresh_access_token(
    refresh_request: RefreshTokenRequest,
    db: AsyncSession = Depends(get_db)
):
    """Refresh access token using refresh token"""
    
    try:
        # Verify refresh token
        payload = await AuthService.verify_token(refresh_request.refresh_token, "refresh")
        
        if not payload:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid refresh token"
            )
        
        user_id = payload.get("sub")
        
        # Verify user still exists and is active
        user = await db.execute(
            select(User).where(User.id == user_id, User.is_active == True)
        )
        user = user.scalar_one_or_none()
        
        if not user:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="User not found or inactive"
            )
        
        # Generate new access token
        access_token = AuthService.create_access_token(
            data={"sub": str(user.id)}
        )
        
        return TokenResponse(
            access_token=access_token,
            refresh_token=refresh_request.refresh_token,  # Keep same refresh token
            expires_in=30 * 60  # 30 minutes
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Token refresh error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Token refresh failed"
        )

@router.post("/logout", response_model=BaseResponse)
async def logout_user(
    refresh_request: RefreshTokenRequest,
    current_user: User = Depends(get_current_user)
):
    """Logout user and revoke refresh token"""
    
    try:
        # Revoke refresh token
        await AuthService.revoke_refresh_token(refresh_request.refresh_token)
        
        # Remove from Redis
        await redis_service.delete_cache(f"refresh_token:{current_user.id}")
        
        logger.info(f"User logged out: {current_user.email}")
        
        return BaseResponse(message="Logged out successfully")
        
    except Exception as e:
        logger.error(f"Logout error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Logout failed"
        )

@router.get("/profile", response_model=UserProfile)
async def get_user_profile(
    current_user: User = Depends(get_current_user)
):
    """Get current user's profile"""
    return UserProfile.from_orm(current_user)

@router.put("/profile", response_model=UserProfile)
async def update_user_profile(
    profile_update: UserPreferencesUpdate,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Update user's profile and preferences"""
    
    try:
        # Update preferences
        if profile_update.preferences:
            current_user.preferences = profile_update.preferences
        
        if profile_update.privacy_settings:
            current_user.privacy_settings = profile_update.privacy_settings
        
        current_user.updated_at = datetime.utcnow()
        
        await db.commit()
        await db.refresh(current_user)
        
        logger.info(f"Profile updated for user: {current_user.email}")
        
        return UserProfile.from_orm(current_user)
        
    except Exception as e:
        logger.error(f"Profile update error: {e}")
        await db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Profile update failed"
        )
```

**Deliverables:**
- [ ] Complete memory management API with CRUD operations
- [ ] Advanced search functionality with vector similarity
- [ ] Authentication API with JWT tokens and refresh mechanism
- [ ] User profile management
- [ ] Comprehensive error handling and validation
- [ ] Caching integration for performance
- [ ] Proper logging and monitoring

### Task 3: API Documentation & Testing

#### 3.1 OpenAPI Documentation Enhancement

**Custom OpenAPI Schema (apps/api/core/openapi.py):**
```python
from fastapi.openapi.utils import get_openapi
from fastapi import FastAPI
from typing import Dict, Any

def custom_openapi(app: FastAPI) -> Dict[str, Any]:
    """Generate custom OpenAPI schema with enhanced documentation"""
    
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title="Personal Timeline API",
        version="1.0.0",
        description="""
        # AI-Augmented Personal Archive API
        
        This API provides comprehensive access to your personal timeline data with AI-powered features for memory exploration, story generation, and intelligent search.
        
        ## Features
        
        - **Memory Management**: Store, organize, and retrieve personal memories
        - **AI-Powered Search**: Natural language search across your entire timeline
        - **Story Generation**: AI-generated narratives from your memories
        - **People & Places**: Automatic recognition and organization
        - **Privacy First**: Complete user data isolation and control
        
        ## Authentication
        
        This API uses JWT (JSON Web Tokens) for authentication. Include the token in the Authorization header:
        
        ```
        Authorization: Bearer <your-jwt-token>
        ```
        
        ## Rate Limiting
        
        API requests are rate limited per user:
        - 100 requests per minute for authenticated users
        - 10 requests per minute for unauthenticated endpoints
        
        ## Error Handling
        
        All errors follow a consistent format:
        
        ```json
        {
            "success": false,
            "error": "Error Type",
            "message": "Human readable error message",
            "details": {},
            "request_id": "uuid-for-tracking"
        }
        ```
        
        ## Data Privacy
        
        - All user data is completely isolated
        - No cross-user data access possible
        - Optional local processing for sensitive operations
        - Full data export and deletion capabilities
        """,
        routes=app.routes,
        servers=[
            {
                "url": "http://localhost:8000",
                "description": "Development server"
            },
            {
                "url": "https://api.personal-timeline.com",
                "description": "Production server"
            }
        ]
    )
    
    # Add security schemes
    openapi_schema["components"]["securitySchemes"] = {
        "BearerAuth": {
            "type": "http",
            "scheme": "bearer",
            "bearerFormat": "JWT",
            "description": "JWT token obtained from /auth/login endpoint"
        }
    }
    
    # Add global security requirement
    openapi_schema["security"] = [{"BearerAuth": []}]
    
    # Add custom examples
    openapi_schema["components"]["examples"] = {
        "MemorySearchExample": {
            "summary": "Natural language memory search",
            "description": "Example of searching memories using natural language",
            "value": {
                "query": "photos from my trip to Paris with Sarah",
                "content_types": ["photo"],
                "start_date": "2023-01-01T00:00:00Z",
                "end_date": "2023-12-31T23:59:59Z"
            }
        },
        "StoryGenerationExample": {
            "summary": "Generate a travel story",
            "description": "Example of generating a story about travels",
            "value": {
                "title": "My European Adventure",
                "story_type": "thematic",
                "narrative_style": "memoir",
                "themes": ["travel", "friendship"],
                "max_memories": 15,
                "include_voice_narration": True
            }
        },
        "UserRegistrationExample": {
            "summary": "User registration",
            "description": "Example of user registration",
            "value": {
                "email": "user@example.com",
                "password": "SecurePass123!",
                "confirm_password": "SecurePass123!"
            }
        }
    }
    
    # Add response examples
    openapi_schema["components"]["responses"] = {
        "UnauthorizedError": {
            "description": "Authentication required",
            "content": {
                "application/json": {
                    "example": {
                        "success": False,
                        "error": "Unauthorized",
                        "message": "Could not validate credentials",
                        "request_id": "550e8400-e29b-41d4-a716-446655440000"
                    }
                }
            }
        },
        "ValidationError": {
            "description": "Request validation failed",
            "content": {
                "application/json": {
                    "example": {
                        "success": False,
                        "error": "Validation Error",
                        "message": "The request contains invalid data",
                        "details": [
                            {
                                "loc": ["body", "email"],
                                "msg": "field required",
                                "type": "value_error.missing"
                            }
                        ],
                        "request_id": "550e8400-e29b-41d4-a716-446655440000"
                    }
                }
            }
        },
        "RateLimitError": {
            "description": "Rate limit exceeded",
            "content": {
                "application/json": {
                    "example": {
                        "success": False,
                        "error": "Rate Limit Exceeded",
                        "message": "Too many requests",
                        "request_id": "550e8400-e29b-41d4-a716-446655440000"
                    }
                }
            },
            "headers": {
                "X-Rate-Limit-Remaining": {
                    "description": "Number of requests remaining in current window",
                    "schema": {"type": "integer"}
                },
                "Retry-After": {
                    "description": "Seconds to wait before making another request",
                    "schema": {"type": "integer"}
                }
            }
        }
    }
    
    app.openapi_schema = openapi_schema
    return app.openapi_schema
```

**API Documentation Examples (apps/api/docs/examples.py):**
```python
from typing import Dict, Any

class APIExamples:
    """API request/response examples for documentation"""
    
    MEMORY_SEARCH_REQUEST = {
        "query": "photos from my birthday party last year",
        "content_types": ["photo", "video"],
        "start_date": "2023-01-01T00:00:00Z",
        "end_date": "2023-12-31T23:59:59Z",
        "has_media": True
    }
    
    MEMORY_SEARCH_RESPONSE = {
        "success": True,
        "data": [
            {
                "id": "550e8400-e29b-41d4-a716-446655440000",
                "user_id": "123e4567-e89b-12d3-a456-426614174000",
                "title": "Birthday celebration with friends",
                "description": "Amazing birthday party with all my favorite people!",
                "content_type": "photo",
                "timestamp": "2023-06-15T19:30:00Z",
                "ai_summary": "A joyful birthday celebration with friends, featuring cake, decorations, and group photos",
                "ai_tags": ["birthday", "celebration", "friends", "party"],
                "sentiment_score": 0.95,
                "similarity_score": 0.87,
                "media_files": [
                    {
                        "id": "media-123",
                        "file_type": "image",
                        "file_path": "/media/photos/birthday_2023.jpg",
                        "thumbnail_path": "/media/thumbnails/birthday_2023_thumb.jpg",
                        "dimensions": {"width": 1920, "height": 1080}
                    }
                ],
                "people": [
                    {
                        "id": "person-456",
                        "name": "Sarah Johnson",
                        "relationship_type": "friend"
                    }
                ]
            }
        ],
        "page": 1,
        "size": 20,
        "total": 1,
        "pages": 1,
        "has_next": False,
        "has_prev": False,
        "query": "photos from my birthday party last year",
        "filters_applied": {
            "content_types": ["photo", "video"],
            "has_media": True
        }
    }
    
    STORY_GENERATION_REQUEST = {
        "title": "My Journey Through College",
        "story_type": "chronological",
        "narrative_style": "memoir",
        "start_date": "2019-09-01T00:00:00Z",
        "end_date": "2023-05-31T23:59:59Z",
        "themes": ["education", "growth", "friendship"],
        "max_memories": 25,
        "include_voice_narration": True,
        "tone": "warm",
        "length": "medium"
    }
    
    STORY_GENERATION_RESPONSE = {
        "success": True,
        "task_id": "task-789",
        "status": "processing",
        "message": "Story generation started. Check status with task_id.",
        "estimated_completion": "2024-01-15T10:35:00Z"
    }
    
    USER_REGISTRATION_REQUEST = {
        "email": "newuser@example.com",
        "password": "SecurePassword123!",
        "confirm_password": "SecurePassword123!"
    }
    
    TOKEN_RESPONSE = {
        "success": True,
        "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
        "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
        "token_type": "bearer",
        "expires_in": 1800
    }
    
    ERROR_RESPONSE = {
        "success": False,
        "error": "Validation Error",
        "message": "The request contains invalid data",
        "details": [
            {
                "loc": ["body", "email"],
                "msg": "field required",
                "type": "value_error.missing"
            }
        ],
        "request_id": "550e8400-e29b-41d4-a716-446655440000"
    }
    
    HEALTH_CHECK_RESPONSE = {
        "status": "healthy",
        "timestamp": "2024-01-15T10:30:00Z",
        "version": "1.0.0",
        "environment": "production",
        "services": {
            "database": {
                "status": "healthy",
                "response_time_ms": 12,
                "connections": {
                    "active": 5,
                    "idle": 15,
                    "total": 20
                }
            },
            "redis": {
                "status": "healthy",
                "response_time_ms": 3,
                "memory_usage": "45MB",
                "connected_clients": 8
            },
            "vector_db": {
                "status": "healthy",
                "response_time_ms": 25,
                "collections": 150,
                "total_vectors": 50000
            }
        },
        "system": {
            "cpu_usage": 25.5,
            "memory_usage": 68.2,
            "disk_usage": 45.8,
            "uptime_seconds": 86400
        }
    }

def add_examples_to_routes(app):
    """Add examples to API routes"""
    
    # Add examples to OpenAPI schema
    if hasattr(app, 'openapi_schema') and app.openapi_schema:
        paths = app.openapi_schema.get('paths', {})
        
        # Memory search endpoint
        if '/api/v1/memories/search' in paths:
            search_path = paths['/api/v1/memories/search']['post']
            search_path['requestBody']['content']['application/json']['example'] = APIExamples.MEMORY_SEARCH_REQUEST
            search_path['responses']['200']['content']['application/json']['example'] = APIExamples.MEMORY_SEARCH_RESPONSE
        
        # Story generation endpoint
        if '/api/v1/stories/generate' in paths:
            story_path = paths['/api/v1/stories/generate']['post']
            story_path['requestBody']['content']['application/json']['example'] = APIExamples.STORY_GENERATION_REQUEST
            story_path['responses']['200']['content']['application/json']['example'] = APIExamples.STORY_GENERATION_RESPONSE
        
        # User registration endpoint
        if '/auth/register' in paths:
            register_path = paths['/auth/register']['post']
            register_path['requestBody']['content']['application/json']['example'] = APIExamples.USER_REGISTRATION_REQUEST
            register_path['responses']['200']['content']['application/json']['example'] = APIExamples.TOKEN_RESPONSE
```

**Deliverables:**
- [ ] Enhanced OpenAPI schema with comprehensive documentation
- [ ] Request/response examples for all endpoints
- [ ] Interactive API documentation with Swagger UI
- [ ] Authentication flow documentation
- [ ] Error response documentation

#### 3.2 Comprehensive Test Suite

**Test Configuration (apps/api/tests/conftest.py):**
```python
import pytest
import asyncio
from typing import AsyncGenerator, Generator
from fastapi.testclient import TestClient
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from sqlalchemy.pool import StaticPool
import redis.asyncio as redis
from unittest.mock import AsyncMock, MagicMock

from main import app
from core.database import get_db, Base
from core.auth import get_current_active_user
from models.database import User
from services.redis_service import redis_service
from services.vector_service import vector_service

# Test database URL (SQLite in memory for speed)
TEST_DATABASE_URL = "sqlite+aiosqlite:///:memory:"

# Create test engine
test_engine = create_async_engine(
    TEST_DATABASE_URL,
    poolclass=StaticPool,
    connect_args={"check_same_thread": False},
    echo=False
)

TestSessionLocal = async_sessionmaker(
    test_engine,
    class_=AsyncSession,
    expire_on_commit=False
)

@pytest.fixture(scope="session")
def event_loop() -> Generator:
    """Create an instance of the default event loop for the test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
async def db_session() -> AsyncGenerator[AsyncSession, None]:
    """Create a test database session."""
    async with test_engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    
    async with TestSessionLocal() as session:
        yield session
    
    async with test_engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)

@pytest.fixture
def override_get_db(db_session: AsyncSession):
    """Override the get_db dependency."""
    async def _override_get_db():
        yield db_session
    return _override_get_db

@pytest.fixture
def test_user() -> User:
    """Create a test user."""
    from datetime import datetime
    return User(
        id="550e8400-e29b-41d4-a716-446655440000",
        email="test@example.com",
        password_hash="$2b$12$hashed_password",
        is_active=True,
        is_verified=True,
        created_at=datetime.utcnow()
    )

@pytest.fixture
def override_get_current_user(test_user: User):
    """Override the get_current_active_user dependency."""
    async def _override_get_current_user():
        return test_user
    return _override_get_current_user

@pytest.fixture
def mock_redis_service():
    """Mock Redis service."""
    mock_redis = AsyncMock()
    mock_redis.ping.return_value = True
    mock_redis.get_cache.return_value = None
    mock_redis.set_cache.return_value = True
    mock_redis.delete_cache.return_value = True
    mock_redis.exists_cache.return_value = False
    return mock_redis

@pytest.fixture
def mock_vector_service():
    """Mock Vector service."""
    mock_vector = AsyncMock()
    mock_vector.similarity_search.return_value = []
    mock_vector.add_memory_embedding.return_value = True
    mock_vector.update_memory_embedding.return_value = True
    mock_vector.delete_memory_embedding.return_value = True
    return mock_vector

@pytest.fixture
def client(
    override_get_db,
    override_get_current_user,
    mock_redis_service,
    mock_vector_service,
    db_session: AsyncSession
) -> TestClient:
    """Create a test client with overridden dependencies."""
    
    # Override dependencies
    app.dependency_overrides[get_db] = override_get_db
    app.dependency_overrides[get_current_active_user] = override_get_current_user
    
    # Mock services
    app.state.redis_service = mock_redis_service
    app.state.vector_service = mock_vector_service
    
    with TestClient(app) as test_client:
        yield test_client
    
    # Clean up overrides
    app.dependency_overrides.clear()

@pytest.fixture
def auth_headers() -> dict:
    """Create authentication headers for testing."""
    return {
        "Authorization": "Bearer test_token",
        "Content-Type": "application/json"
    }

@pytest.fixture
async def sample_memories(db_session: AsyncSession, test_user: User) -> list:
    """Create sample memories for testing."""
    from models.database import Memory
    from datetime import datetime, timedelta
    
    memories = []
    base_date = datetime.utcnow() - timedelta(days=30)
    
    for i in range(5):
        memory = Memory(
            user_id=test_user.id,
            title=f"Test Memory {i+1}",
            description=f"This is test memory number {i+1}",
            content_type="post",
            timestamp=base_date + timedelta(days=i*7),
            original_content={"text": f"Original content {i+1}"},
            ai_summary=f"AI summary for memory {i+1}",
            ai_tags=[f"tag{i+1}", "test"],
            sentiment_score=0.5 + (i * 0.1)
        )
        db_session.add(memory)
        memories.append(memory)
    
    await db_session.commit()
    return memories

class TestDataFactory:
    """Factory for creating test data."""
    
    @staticmethod
    def create_memory_data(**kwargs):
        """Create memory test data."""
        default_data = {
            "title": "Test Memory",
            "description": "Test memory description",
            "content_type": "post",
            "timestamp": "2024-01-15T10:30:00Z",
            "original_content": {"text": "Test content"}
        }
        default_data.update(kwargs)
        return default_data
    
    @staticmethod
    def create_user_data(**kwargs):
        """Create user test data."""
        default_data = {
            "email": "test@example.com",
            "password": "TestPassword123!",
            "confirm_password": "TestPassword123!"
        }
        default_data.update(kwargs)
        return default_data
    
    @staticmethod
    def create_story_request(**kwargs):
        """Create story generation request data."""
        default_data = {
            "title": "Test Story",
            "story_type": "chronological",
            "narrative_style": "memoir",
            "max_memories": 10,
            "include_voice_narration": True
        }
        default_data.update(kwargs)
        return default_data
```

**API Endpoint Tests (apps/api/tests/test_memories.py):**
```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import AsyncMock, patch
import json
from datetime import datetime

from tests.conftest import TestDataFactory

class TestMemoriesAPI:
    """Test memory management API endpoints."""
    
    def test_get_memories_success(self, client: TestClient, auth_headers: dict, sample_memories):
        """Test successful memory retrieval."""
        response = client.get("/api/v1/memories/", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "data" in data
        assert data["page"] == 1
        assert data["size"] == 20
        assert len(data["data"]) <= 20
    
    def test_get_memories_with_filters(self, client: TestClient, auth_headers: dict):
        """Test memory retrieval with filters."""
        params = {
            "content_types": ["photo", "video"],
            "start_date": "2024-01-01T00:00:00Z",
            "end_date": "2024-12-31T23:59:59Z",
            "has_media": True
        }
        
        response = client.get("/api/v1/memories/", headers=auth_headers, params=params)
        
        assert response.status_code == 200
        data = response.json()
        assert "filters_applied" in data
        assert data["filters_applied"]["content_types"] == ["photo", "video"]
    
    def test_get_memories_pagination(self, client: TestClient, auth_headers: dict):
        """Test memory pagination."""
        params = {"page": 2, "size": 10}
        
        response = client.get("/api/v1/memories/", headers=auth_headers, params=params)
        
        assert response.status_code == 200
        data = response.json()
        assert data["page"] == 2
        assert data["size"] == 10
    
    def test_get_memories_invalid_pagination(self, client: TestClient, auth_headers: dict):
        """Test invalid pagination parameters."""
        params = {"page": 0, "size": 101}
        
        response = client.get("/api/v1/memories/", headers=auth_headers, params=params)
        
        assert response.status_code == 400
    
    def test_search_memories_success(self, client: TestClient, auth_headers: dict):
        """Test successful memory search."""
        search_data = {
            "query": "birthday party photos",
            "content_types": ["photo"],
            "has_media": True
        }
        
        with patch('services.vector_service.vector_service.similarity_search') as mock_search:
            mock_search.return_value = [
                {
                    "memory_id": "550e8400-e29b-41d4-a716-446655440000",
                    "similarity_score": 0.85,
                    "document": "Birthday party with friends",
                    "metadata": {"content_type": "photo"}
                }
            ]
            
            response = client.post(
                "/api/v1/memories/search",
                headers=auth_headers,
                json=search_data
            )
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert data["query"] == "birthday party photos"
    
    def test_search_memories_empty_query(self, client: TestClient, auth_headers: dict):
        """Test search with empty query."""
        search_data = {"query": ""}
        
        response = client.post(
            "/api/v1/memories/search",
            headers=auth_headers,
            json=search_data
        )
        
        assert response.status_code == 400
        assert "empty" in response.json()["detail"].lower()
    
    def test_get_memory_by_id_success(self, client: TestClient, auth_headers: dict, sample_memories):
        """Test successful memory retrieval by ID."""
        memory_id = str(sample_memories[0].id)
        
        response = client.get(f"/api/v1/memories/{memory_id}", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["id"] == memory_id
        assert data["title"] == sample_memories[0].title
    
    def test_get_memory_not_found(self, client: TestClient, auth_headers: dict):
        """Test memory not found."""
        fake_id = "550e8400-e29b-41d4-a716-446655440999"
        
        response = client.get(f"/api/v1/memories/{fake_id}", headers=auth_headers)
        
        assert response.status_code == 404
        assert "not found" in response.json()["detail"].lower()
    
    def test_update_memory_success(self, client: TestClient, auth_headers: dict, sample_memories):
        """Test successful memory update."""
        memory_id = str(sample_memories[0].id)
        update_data = {
            "title": "Updated Memory Title",
            "description": "Updated description",
            "ai_tags": ["updated", "test"]
        }
        
        response = client.put(
            f"/api/v1/memories/{memory_id}",
            headers=auth_headers,
            json=update_data
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["title"] == "Updated Memory Title"
        assert data["description"] == "Updated description"
    
    def test_delete_memory_success(self, client: TestClient, auth_headers: dict, sample_memories):
        """Test successful memory deletion."""
        memory_id = str(sample_memories[0].id)
        
        with patch('services.vector_service.vector_service.delete_memory_embedding') as mock_delete:
            mock_delete.return_value = True
            
            response = client.delete(f"/api/v1/memories/{memory_id}", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "deleted" in data["message"].lower()
    
    def test_get_memory_statistics(self, client: TestClient, auth_headers: dict):
        """Test memory statistics endpoint."""
        with patch('utils.query_utils.QueryOptimizer.get_memory_statistics') as mock_stats:
            mock_stats.return_value = {
                "total_memories": 100,
                "photo_count": 60,
                "video_count": 20,
                "post_count": 20,
                "geotagged_count": 40,
                "active_days": 150
            }
            
            response = client.get("/api/v1/memories/statistics/overview", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["total_memories"] == 100
        assert data["photo_count"] == 60
    
    def test_unauthorized_access(self, client: TestClient):
        """Test unauthorized access to protected endpoints."""
        response = client.get("/api/v1/memories/")
        
        assert response.status_code == 401
        assert "credentials" in response.json()["detail"].lower()
    
    def test_rate_limiting(self, client: TestClient, auth_headers: dict):
        """Test rate limiting functionality."""
        # This would require mocking the rate limiting service
        # and making multiple rapid requests
        pass

class TestMemoryValidation:
    """Test memory data validation."""
    
    def test_valid_memory_data(self):
        """Test valid memory data validation."""
        from models.api_models import MemoryCreate
        
        valid_data = TestDataFactory.create_memory_data()
        memory = MemoryCreate(**valid_data)
        
        assert memory.title == "Test Memory"
        assert memory.content_type == "post"
    
    def test_invalid_coordinates(self):
        """Test invalid coordinate validation."""
        from models.api_models import MemoryCreate
        from pydantic import ValidationError
        
        invalid_data = TestDataFactory.create_memory_data(
            latitude=91.0,  # Invalid latitude
            longitude=181.0  # Invalid longitude
        )
        
        with pytest.raises(ValidationError):
            MemoryCreate(**invalid_data)
    
    def test_missing_required_fields(self):
        """Test missing required fields validation."""
        from models.api_models import MemoryCreate
        from pydantic import ValidationError
        
        invalid_data = {"title": "Test"}  # Missing required fields
        
        with pytest.raises(ValidationError):
            MemoryCreate(**invalid_data)
```

**Authentication Tests (apps/api/tests/test_auth.py):**
```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import patch, AsyncMock
from datetime import datetime, timedelta

from tests.conftest import TestDataFactory

class TestAuthenticationAPI:
    """Test authentication API endpoints."""
    
    def test_user_registration_success(self, client: TestClient):
        """Test successful user registration."""
        user_data = TestDataFactory.create_user_data()
        
        with patch('core.auth.AuthService.get_password_hash') as mock_hash:
            mock_hash.return_value = "hashed_password"
            
            response = client.post("/auth/register", json=user_data)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "access_token" in data
        assert "refresh_token" in data
        assert data["token_type"] == "bearer"
    
    def test_user_registration_duplicate_email(self, client: TestClient):
        """Test registration with duplicate email."""
        user_data = TestDataFactory.create_user_data()
        
        # First registration
        with patch('core.auth.AuthService.get_password_hash') as mock_hash:
            mock_hash.return_value = "hashed_password"
            client.post("/auth/register", json=user_data)
        
        # Second registration with same email
        response = client.post("/auth/register", json=user_data)
        
        assert response.status_code == 400
        assert "already registered" in response.json()["detail"].lower()
    
    def test_user_registration_weak_password(self, client: TestClient):
        """Test registration with weak password."""
        user_data = TestDataFactory.create_user_data(
            password="weak",
            confirm_password="weak"
        )
        
        response = client.post("/auth/register", json=user_data)
        
        assert response.status_code == 422
        assert "password" in str(response.json()["detail"]).lower()
    
    def test_user_registration_password_mismatch(self, client: TestClient):
        """Test registration with password mismatch."""
        user_data = TestDataFactory.create_user_data(
            password="StrongPassword123!",
            confirm_password="DifferentPassword123!"
        )
        
        response = client.post("/auth/register", json=user_data)
        
        assert response.status_code == 422
        assert "match" in str(response.json()["detail"]).lower()
    
    def test_user_login_success(self, client: TestClient):
        """Test successful user login."""
        login_data = {
            "email": "test@example.com",
            "password": "TestPassword123!"
        }
        
        with patch('core.auth.AuthService.authenticate_user') as mock_auth:
            from models.database import User
            mock_user = User(
                id="550e8400-e29b-41d4-a716-446655440000",
                email="test@example.com",
                is_active=True
            )
            mock_auth.return_value = mock_user
            
            response = client.post("/auth/login", json=login_data)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "access_token" in data
        assert "refresh_token" in data
    
    def test_user_login_invalid_credentials(self, client: TestClient):
        """Test login with invalid credentials."""
        login_data = {
            "email": "test@example.com",
            "password": "WrongPassword"
        }
        
        with patch('core.auth.AuthService.authenticate_user') as mock_auth:
            mock_auth.return_value = None
            
            response = client.post("/auth/login", json=login_data)
        
        assert response.status_code == 401
        assert "incorrect" in response.json()["detail"].lower()
    
    def test_token_refresh_success(self, client: TestClient):
        """Test successful token refresh."""
        refresh_data = {
            "refresh_token": "valid_refresh_token"
        }
        
        with patch('core.auth.AuthService.verify_token') as mock_verify:
            mock_verify.return_value = {"sub": "550e8400-e29b-41d4-a716-446655440000"}
            
            response = client.post("/auth/refresh", json=refresh_data)
        
        assert response.status_code == 200
        data = response.json()
        assert "access_token" in data
        assert "refresh_token" in data
    
    def test_token_refresh_invalid_token(self, client: TestClient):
        """Test token refresh with invalid token."""
        refresh_data = {
            "refresh_token": "invalid_refresh_token"
        }
        
        with patch('core.auth.AuthService.verify_token') as mock_verify:
            mock_verify.return_value = None
            
            response = client.post("/auth/refresh", json=refresh_data)
        
        assert response.status_code == 401
        assert "invalid" in response.json()["detail"].lower()
    
    def test_user_logout_success(self, client: TestClient, auth_headers: dict):
        """Test successful user logout."""
        logout_data = {
            "refresh_token": "valid_refresh_token"
        }
        
        with patch('core.auth.AuthService.revoke_refresh_token') as mock_revoke:
            mock_revoke.return_value = True
            
            response = client.post("/auth/logout", headers=auth_headers, json=logout_data)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "logged out" in data["message"].lower()
    
    def test_get_user_profile(self, client: TestClient, auth_headers: dict):
        """Test getting user profile."""
        response = client.get("/auth/profile", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert "id" in data
        assert "email" in data
        assert "created_at" in data
    
    def test_update_user_profile(self, client: TestClient, auth_headers: dict):
        """Test updating user profile."""
        update_data = {
            "preferences": {
                "theme": "dark",
                "notifications": True
            },
            "privacy_settings": {
                "data_sharing": False,
                "analytics": True
            }
        }
        
        response = client.put("/auth/profile", headers=auth_headers, json=update_data)
        
        assert response.status_code == 200
        data = response.json()
        assert data["preferences"]["theme"] == "dark"
        assert data["privacy_settings"]["data_sharing"] is False

class TestJWTTokens:
    """Test JWT token functionality."""
    
    def test_create_access_token(self):
        """Test access token creation."""
        from core.auth import AuthService
        
        token_data = {"sub": "user123"}
        token = AuthService.create_access_token(token_data)
        
        assert isinstance(token, str)
        assert len(token) > 0
    
    def test_create_refresh_token(self):
        """Test refresh token creation."""
        from core.auth import AuthService
        
        user_id = "user123"
        token = AuthService.create_refresh_token(user_id)
        
        assert isinstance(token, str)
        assert len(token) > 0
    
    @pytest.mark.asyncio
    async def test_verify_valid_token(self):
        """Test verifying valid token."""
        from core.auth import AuthService
        
        token_data = {"sub": "user123"}
        token = AuthService.create_access_token(token_data)
        
        payload = await AuthService.verify_token(token, "access")
        
        assert payload is not None
        assert payload["sub"] == "user123"
        assert payload["type"] == "access"
    
    @pytest.mark.asyncio
    async def test_verify_invalid_token(self):
        """Test verifying invalid token."""
        from core.auth import AuthService
        
        invalid_token = "invalid.jwt.token"
        
        payload = await AuthService.verify_token(invalid_token, "access")
        
        assert payload is None
    
    @pytest.mark.asyncio
    async def test_verify_expired_token(self):
        """Test verifying expired token."""
        from core.auth import AuthService
        from datetime import timedelta
        
        token_data = {"sub": "user123"}
        # Create token that expires immediately
        token = AuthService.create_access_token(token_data, timedelta(seconds=-1))
        
        payload = await AuthService.verify_token(token, "access")
        
        assert payload is None
```

**Performance Tests (apps/api/tests/test_performance.py):**
```python
import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from fastapi.testclient import TestClient

class TestAPIPerformance:
    """Test API performance characteristics."""
    
    def test_memory_retrieval_performance(self, client: TestClient, auth_headers: dict):
        """Test memory retrieval response time."""
        start_time = time.time()
        
        response = client.get("/api/v1/memories/", headers=auth_headers)
        
        end_time = time.time()
        response_time = end_time - start_time
        
        assert response.status_code == 200
        assert response_time < 1.0  # Should respond within 1 second
    
    def test_search_performance(self, client: TestClient, auth_headers: dict):
        """Test search endpoint performance."""
        search_data = {"query": "test search query"}
        
        start_time = time.time()
        
        response = client.post(
            "/api/v1/memories/search",
            headers=auth_headers,
            json=search_data
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        assert response.status_code == 200
        assert response_time < 2.0  # Search should complete within 2 seconds
    
    def test_concurrent_requests(self, client: TestClient, auth_headers: dict):
        """Test handling concurrent requests."""
        def make_request():
            return client.get("/api/v1/memories/", headers=auth_headers)
        
        # Make 10 concurrent requests
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(make_request) for _ in range(10)]
            responses = [future.result() for future in futures]
        
        # All requests should succeed
        for response in responses:
            assert response.status_code == 200
    
    def test_large_payload_handling(self, client: TestClient, auth_headers: dict):
        """Test handling of large request payloads."""
        # Create a large search request
        large_search_data = {
            "query": "test " * 100,  # Large query string
            "content_types": ["photo", "video", "post"] * 10,
            "themes": ["theme" + str(i) for i in range(50)]
        }
        
        response = client.post(
            "/api/v1/memories/search",
            headers=auth_headers,
            json=large_search_data
        )
        
        # Should handle large payload gracefully
        assert response.status_code in [200, 422]  # Either success or validation error
    
    def test_pagination_performance(self, client: TestClient, auth_headers: dict):
        """Test pagination performance with large page sizes."""
        params = {"page": 1, "size": 100}  # Large page size
        
        start_time = time.time()
        
        response = client.get("/api/v1/memories/", headers=auth_headers, params=params)
        
        end_time = time.time()
        response_time = end_time - start_time
        
        assert response.status_code == 200
        assert response_time < 2.0  # Should handle large pages efficiently

class TestLoadTesting:
    """Load testing scenarios."""
    
    @pytest.mark.slow
    def test_sustained_load(self, client: TestClient, auth_headers: dict):
        """Test sustained load over time."""
        def make_requests():
            responses = []
            for _ in range(50):  # 50 requests per thread
                response = client.get("/api/v1/memories/", headers=auth_headers)
                responses.append(response.status_code)
                time.sleep(0.1)  # Small delay between requests
            return responses
        
        # Run with 5 concurrent threads
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(make_requests) for _ in range(5)]
            all_responses = []
            for future in futures:
                all_responses.extend(future.result())
        
        # Calculate success rate
        success_count = sum(1 for status in all_responses if status == 200)
        success_rate = success_count / len(all_responses)
        
        assert success_rate > 0.95  # 95% success rate under load
```

**Deliverables:**
- [ ] Comprehensive test suite with >90% coverage
- [ ] Unit tests for all API endpoints
- [ ] Integration tests for complex workflows
- [ ] Performance tests for response times
- [ ] Load testing for concurrent requests
- [ ] Authentication and authorization tests
- [ ] Input validation and error handling tests

---

## Final Deliverables Summary

### 1. FastAPI Core Framework
- [ ] FastAPI application with async/await support
- [ ] Comprehensive middleware stack (security, CORS, compression, logging)
- [ ] Exception handling with proper error responses
- [ ] Environment-based configuration management
- [ ] Application lifecycle management

### 2. Security & Authentication
- [ ] JWT-based authentication with refresh tokens
- [ ] Password hashing and verification
- [ ] Security headers middleware (OWASP compliant)
- [ ] Rate limiting per user and endpoint
- [ ] User context middleware for request tracking
- [ ] Token revocation system

### 3. API Endpoints & Validation
- [ ] Complete memory management API (CRUD operations)
- [ ] Advanced search with vector similarity
- [ ] Authentication API with registration/login
- [ ] User profile management
- [ ] Comprehensive Pydantic models for validation
- [ ] Input sanitization and validation utilities

### 4. Documentation & Testing
- [ ] Enhanced OpenAPI schema with examples
- [ ] Interactive Swagger UI documentation
- [ ] Comprehensive test suite (>90% coverage)
- [ ] Performance and load testing
- [ ] API examples and usage documentation

### 5. Performance & Monitoring
- [ ] Redis caching integration
- [ ] Database connection pooling
- [ ] Request/response logging with correlation IDs
- [ ] Performance metrics collection
- [ ] Health check endpoints

### 6. GraphQL Integration (Future)
- [ ] GraphQL schema definition
- [ ] Resolver implementation
- [ ] Query complexity analysis
- [ ] GraphQL playground interface

---

## Success Validation

To validate successful completion of this epic:

1. **API Performance**: All endpoints respond within performance targets (< 200ms simple, < 1s complex)
2. **Authentication Security**: JWT tokens work correctly, proper session management
3. **Data Validation**: All inputs validated, proper error responses
4. **Documentation Quality**: Complete API docs with working examples
5. **Test Coverage**: >90% test coverage with passing tests
6. **Security Compliance**: All OWASP security headers, proper authorization
7. **Load Testing**: System handles expected concurrent load

---

**Epic Owner**: Backend Lead + API Developer  
**Stakeholders**: Frontend Team, DevOps Team, Security Team  
**Dependencies**: 1.1.1 Development Environment, 1.1.2 Database Architecture  
**Risk Level**: Medium (API complexity, security requirements)