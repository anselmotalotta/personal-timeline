# Epic 1.1.1: Development Environment & DevOps

**Phase**: 1 - Foundation & Core Infrastructure  
**Epic**: 1.1.1 Development Environment & DevOps  
**Duration**: 2 weeks  
**Team Size**: 1-2 developers (DevOps + Backend)  

---

## Goal

Provide a reproducible local development setup, automated CI/CD pipeline, and production-grade observability for a privacy-sensitive "AI-Augmented Personal Archive" application with web interface and background AI processing workers.

---

## Scope Assumptions

### Repository Structure
- **Monorepo** containing:
  - Web application (React frontend + FastAPI backend)
  - Background workers (data ingestion, AI processing, story generation)
  - Infrastructure modules (Terraform/Pulumi IaC)
  - Shared libraries and utilities

### Technology Stack
- **Storage**: S3-compatible object store (AWS S3 or MinIO for local)
- **Databases**: 
  - PostgreSQL (metadata, user data, stories)
  - Vector Database (Chroma/Weaviate for embeddings)
  - Redis (queues, caching, sessions)
- **Compute**: Docker containers, deployable to managed platforms (ECS/Fargate, EKS, or similar)
- **Observability**: OpenTelemetry + Prometheus + Grafana + Loki (or CloudWatch equivalent)
- **Security**: Secrets managed by environment/secret manager, minimal local secrets exposure

### Privacy & Security Considerations
- **Local-first option**: Complete stack runnable locally for privacy-conscious users
- **Data encryption**: At rest and in transit
- **Secret management**: No secrets in code, proper rotation procedures
- **Audit trails**: All deployments and admin actions logged

---

## Success Criteria

- [ ] **Developer Onboarding**: New developer can run full stack locally in < 30 minutes
- [ ] **Code Quality**: CI runs lint/typecheck/tests on every PR and blocks merges on failures
- [ ] **Automated Deployment**: CD deploys automatically to staging; production deploy is gated with approval
- [ ] **Observability**: Health dashboards exist for API/worker/DB/queue/object-store with throughput and error rates
- [ ] **Rollback Capability**: Rollbacks are one command, releases traceable to git SHAs
- [ ] **Security**: No secrets in logs, proper secret rotation documented
- [ ] **Performance**: Local dev environment starts in < 5 minutes, CI pipeline completes in < 10 minutes

---

## Non-Goals

- Building product features (AI agents, story generation, UI components) beyond infrastructure scaffolding
- Mobile application distribution pipeline
- Full SOC2/ISO compliance implementation (but lay groundwork for future compliance)
- Multi-region deployment (single region for MVP)
- Advanced cost optimization (focus on functionality first)

---

## Risks & Mitigations

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Over-engineering too early | High | Medium | Use minimal but scalable baseline, avoid premature optimization |
| Secrets leakage in CI logs | High | Low | Strict secret handling, audit CI configurations, use OIDC where possible |
| High operational burden | Medium | Medium | Choose managed services over self-hosted, automate common tasks |
| Docker performance on local dev | Medium | Medium | Optimize Dockerfiles, use volume mounts for hot reload |
| CI/CD pipeline complexity | Medium | Low | Start simple, iterate based on team needs |

---

## Detailed Tasks

### Task 1: Repository Structure & Standards

#### 1.1 Monorepo Layout & Tooling
```
/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                 # React frontend
â”‚   â”œâ”€â”€ api/                 # FastAPI backend
â”‚   â””â”€â”€ worker/              # Background processing
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ shared/              # Shared utilities
â”‚   â””â”€â”€ types/               # TypeScript type definitions
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ terraform/           # Infrastructure as Code
â”‚   â””â”€â”€ docker/              # Docker configurations
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ dev-setup.md
â”‚   â”œâ”€â”€ runbooks.md
â”‚   â””â”€â”€ security.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ dev/                 # Development scripts
â”‚   â”œâ”€â”€ infra/               # Infrastructure scripts
â”‚   â””â”€â”€ ci/                  # CI/CD scripts
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/           # GitHub Actions
â”œâ”€â”€ docker-compose.yml       # Local development
â”œâ”€â”€ Makefile                 # Common commands
â””â”€â”€ README.md
```

**Deliverables:**
- [ ] Repository structure created with placeholder files
- [ ] README.md with quick start guide
- [ ] .gitignore with comprehensive exclusions for all technologies
- [ ] .editorconfig for consistent formatting

#### 1.2 Common Makefile Targets
```makefile
# Development
.PHONY: dev up down logs clean
dev: up                      # Start development environment
up:                          # Start all services
	docker-compose up -d
down:                        # Stop all services
	docker-compose down
logs:                        # View logs from all services
	docker-compose logs -f
clean:                       # Clean up containers and volumes
	docker-compose down -v --remove-orphans

# Code Quality
.PHONY: lint fmt typecheck test test-watch
lint:                        # Run linters
	cd apps/api && ruff check .
	cd apps/web && npm run lint
fmt:                         # Format code
	cd apps/api && ruff format .
	cd apps/web && npm run format
typecheck:                   # Type checking
	cd apps/api && mypy .
	cd apps/web && npm run typecheck
test:                        # Run all tests
	cd apps/api && pytest
	cd apps/web && npm test
test-watch:                  # Run tests in watch mode
	cd apps/api && pytest-watch
	cd apps/web && npm run test:watch

# Infrastructure
.PHONY: infra-plan infra-apply infra-destroy
infra-plan:                  # Plan infrastructure changes
	cd infra/terraform && terraform plan
infra-apply:                 # Apply infrastructure changes
	cd infra/terraform && terraform apply
infra-destroy:               # Destroy infrastructure (staging only)
	cd infra/terraform && terraform destroy

# Database
.PHONY: db-migrate db-seed db-reset
db-migrate:                  # Run database migrations
	cd apps/api && alembic upgrade head
db-seed:                     # Seed database with test data
	cd apps/api && python scripts/seed_db.py
db-reset:                    # Reset database
	docker-compose down postgres
	docker volume rm personal-timeline_postgres_data
	docker-compose up -d postgres
	sleep 10
	$(MAKE) db-migrate db-seed
```

**Deliverables:**
- [ ] Comprehensive Makefile with all common operations
- [ ] Scripts for each Makefile target
- [ ] Documentation for each command

#### 1.3 Code Quality Standards
```yaml
# Backend (Python)
Tools:
  - Ruff: Linting and formatting
  - MyPy: Type checking
  - Pytest: Testing framework
  - Coverage: Test coverage reporting
  - Bandit: Security linting

Configuration:
  - pyproject.toml with strict settings
  - 90%+ test coverage requirement
  - Type hints mandatory for public APIs
  - Docstrings for all public functions

# Frontend (TypeScript/React)
Tools:
  - ESLint: Linting
  - Prettier: Code formatting
  - TypeScript: Type checking (strict mode)
  - Jest + Testing Library: Testing
  - Husky: Git hooks

Configuration:
  - .eslintrc.js with React and accessibility rules
  - .prettierrc with consistent formatting
  - tsconfig.json with strict type checking
  - 80%+ test coverage for components

# Security
Tools:
  - Trivy: Container vulnerability scanning
  - Gitleaks: Secret detection
  - Semgrep: Static analysis security testing
  - OWASP Dependency Check: Dependency vulnerabilities

# Pre-commit Hooks
Hooks:
  - Format code (Ruff, Prettier)
  - Lint code (Ruff, ESLint)
  - Type check (MyPy, TypeScript)
  - Check for secrets (Gitleaks)
  - Validate commit message format
```

**Deliverables:**
- [ ] pyproject.toml with Ruff, MyPy, Pytest configuration
- [ ] package.json with ESLint, Prettier, TypeScript configuration
- [ ] .pre-commit-config.yaml with all hooks
- [ ] GitHub Actions workflow for code quality checks

### Task 2: Local Development Environment (Docker)

#### 2.1 Dockerfiles for Each Service

**API Dockerfile (apps/api/Dockerfile):**
```dockerfile
# Multi-stage build for development and production
FROM python:3.11-slim as base

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    libffi-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install Python dependencies
COPY requirements.txt requirements-dev.txt ./
RUN pip install --no-cache-dir -r requirements-dev.txt

# Development stage
FROM base as development
ENV PYTHONPATH=/app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Install development tools
RUN pip install watchdog

# Copy source code
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash app
RUN chown -R app:app /app
USER app

EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

# Production stage
FROM base as production
ENV PYTHONPATH=/app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Copy only requirements and install
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy source code
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash app
RUN chown -R app:app /app
USER app

EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Worker Dockerfile (apps/worker/Dockerfile):**
```dockerfile
FROM python:3.11-slim as base

# Install system dependencies for AI/ML libraries
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    libffi-dev \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install Python dependencies
COPY requirements.txt requirements-dev.txt ./
RUN pip install --no-cache-dir -r requirements-dev.txt

# Development stage
FROM base as development
ENV PYTHONPATH=/app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Copy source code
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash worker
RUN chown -R worker:worker /app
USER worker

CMD ["python", "worker.py"]

# Production stage
FROM base as production
ENV PYTHONPATH=/app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Copy only requirements and install
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy source code
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash worker
RUN chown -R worker:worker /app
USER worker

CMD ["python", "worker.py"]
```

**Web Dockerfile (apps/web/Dockerfile):**
```dockerfile
FROM node:18-alpine as base

WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm ci

# Development stage
FROM base as development
ENV NODE_ENV=development

# Copy source code
COPY . .

EXPOSE 3000
CMD ["npm", "run", "dev"]

# Build stage
FROM base as build
ENV NODE_ENV=production

# Copy source code and build
COPY . .
RUN npm run build

# Production stage
FROM nginx:alpine as production
COPY --from=build /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

**Deliverables:**
- [ ] Multi-stage Dockerfiles for all services
- [ ] Optimized layer caching for faster builds
- [ ] Non-root user configuration for security
- [ ] Development and production variants

#### 2.2 Docker Compose Configuration

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  # Core Application Services
  api:
    build:
      context: ./apps/api
      target: development
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@postgres:5432/personal_timeline
      - REDIS_URL=redis://redis:6379
      - VECTOR_DB_URL=http://chroma:8000
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - ENVIRONMENT=development
    volumes:
      - ./apps/api:/app
      - ./packages:/app/packages
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      chroma:
        condition: service_started
      minio:
        condition: service_healthy
    networks:
      - personal-timeline
    restart: unless-stopped

  worker:
    build:
      context: ./apps/worker
      target: development
    environment:
      - DATABASE_URL=postgresql://user:password@postgres:5432/personal_timeline
      - REDIS_URL=redis://redis:6379
      - VECTOR_DB_URL=http://chroma:8000
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - ENVIRONMENT=development
    volumes:
      - ./apps/worker:/app
      - ./packages:/app/packages
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      chroma:
        condition: service_started
    networks:
      - personal-timeline
    restart: unless-stopped

  web:
    build:
      context: ./apps/web
      target: development
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://localhost:8000
      - NODE_ENV=development
    volumes:
      - ./apps/web:/app
      - /app/node_modules
    depends_on:
      - api
    networks:
      - personal-timeline
    restart: unless-stopped

  # Data Services
  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=personal_timeline
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/dev/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d personal_timeline"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - personal-timeline
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - personal-timeline
    restart: unless-stopped

  chroma:
    image: chromadb/chroma:latest
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
    networks:
      - personal-timeline
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - personal-timeline
    restart: unless-stopped

  # Observability Services (Optional for local dev)
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./infra/docker/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - personal-timeline
    restart: unless-stopped
    profiles:
      - observability

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infra/docker/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - personal-timeline
    restart: unless-stopped
    profiles:
      - observability

networks:
  personal-timeline:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  chroma_data:
  minio_data:
  prometheus_data:
  grafana_data:
```

**Deliverables:**
- [ ] Complete docker-compose.yml with all services
- [ ] Health checks for all critical services
- [ ] Proper networking and volume configuration
- [ ] Optional observability stack with profiles

#### 2.3 Local Configuration Management

**.env.example:**
```bash
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/personal_timeline
POSTGRES_DB=personal_timeline
POSTGRES_USER=user
POSTGRES_PASSWORD=password

# Redis
REDIS_URL=redis://localhost:6379

# Vector Database
VECTOR_DB_URL=http://localhost:8001

# Object Storage (MinIO for local development)
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET_NAME=personal-timeline-dev

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1
SECRET_KEY=your-secret-key-here-change-in-production

# Frontend Configuration
VITE_API_URL=http://localhost:8000
VITE_ENVIRONMENT=development

# AI/ML Configuration (Optional for local dev)
OPENAI_API_KEY=your-openai-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Observability (Optional)
PROMETHEUS_URL=http://localhost:9090
GRAFANA_URL=http://localhost:3001

# Development Settings
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=DEBUG
```

**Development Scripts:**

**scripts/dev/bootstrap.sh:**
```bash
#!/bin/bash
set -e

echo "ðŸš€ Bootstrapping Personal Timeline development environment..."

# Check prerequisites
command -v docker >/dev/null 2>&1 || { echo "âŒ Docker is required but not installed. Aborting." >&2; exit 1; }
command -v docker-compose >/dev/null 2>&1 || { echo "âŒ Docker Compose is required but not installed. Aborting." >&2; exit 1; }

# Copy environment file if it doesn't exist
if [ ! -f .env ]; then
    echo "ðŸ“ Creating .env file from template..."
    cp .env.example .env
    echo "âš ï¸  Please review and update .env file with your configuration"
fi

# Build and start services
echo "ðŸ—ï¸  Building Docker images..."
docker-compose build

echo "ðŸš€ Starting services..."
docker-compose up -d

# Wait for services to be healthy
echo "â³ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "ðŸ—„ï¸  Running database migrations..."
make db-migrate

# Seed database with test data
echo "ðŸŒ± Seeding database with test data..."
make db-seed

# Run smoke tests
echo "ðŸ§ª Running smoke tests..."
./scripts/dev/smoke-test.sh

echo "âœ… Development environment is ready!"
echo ""
echo "ðŸŒ Services available at:"
echo "   - Web App: http://localhost:3000"
echo "   - API: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - MinIO Console: http://localhost:9001"
echo "   - Grafana (optional): http://localhost:3001"
echo ""
echo "ðŸ“š Next steps:"
echo "   - Review .env file and update configuration"
echo "   - Run 'make test' to run the test suite"
echo "   - Check 'make help' for available commands"
```

**scripts/dev/smoke-test.sh:**
```bash
#!/bin/bash
set -e

echo "ðŸ§ª Running smoke tests..."

# Test API health
echo "Testing API health endpoint..."
curl -f http://localhost:8000/health || { echo "âŒ API health check failed"; exit 1; }

# Test database connection
echo "Testing database connection..."
curl -f http://localhost:8000/health/db || { echo "âŒ Database connection failed"; exit 1; }

# Test Redis connection
echo "Testing Redis connection..."
curl -f http://localhost:8000/health/redis || { echo "âŒ Redis connection failed"; exit 1; }

# Test Vector DB connection
echo "Testing Vector DB connection..."
curl -f http://localhost:8000/health/vector-db || { echo "âŒ Vector DB connection failed"; exit 1; }

# Test MinIO connection
echo "Testing MinIO connection..."
curl -f http://localhost:8000/health/storage || { echo "âŒ MinIO connection failed"; exit 1; }

# Test frontend
echo "Testing frontend..."
curl -f http://localhost:3000 || { echo "âŒ Frontend not accessible"; exit 1; }

echo "âœ… All smoke tests passed!"
```

**scripts/dev/reset.sh:**
```bash
#!/bin/bash
set -e

echo "ðŸ”„ Resetting development environment..."

# Stop all services
echo "ðŸ›‘ Stopping services..."
docker-compose down

# Remove volumes (this will delete all data!)
read -p "âš ï¸  This will delete all local data. Are you sure? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ðŸ—‘ï¸  Removing volumes..."
    docker-compose down -v --remove-orphans
    
    # Remove any dangling images
    echo "ðŸ§¹ Cleaning up Docker images..."
    docker system prune -f
    
    echo "âœ… Environment reset complete!"
    echo "Run './scripts/dev/bootstrap.sh' to set up again."
else
    echo "âŒ Reset cancelled."
fi
```

**Deliverables:**
- [ ] .env.example with all configuration options
- [ ] Bootstrap script for one-command setup
- [ ] Smoke test script for health verification
- [ ] Reset script for clean environment
- [ ] Documentation for local development workflow

### Task 3: Environment Strategy & Infrastructure as Code

#### 3.1 Environment Definitions

**Environment Configurations:**

| Environment | Purpose | Deployment | Data Retention | Monitoring |
|-------------|---------|------------|----------------|------------|
| **Development** | Local development | Docker Compose | Ephemeral | Basic logging |
| **Staging** | Integration testing | Auto-deploy on main | 30 days | Full observability |
| **Production** | Live application | Manual approval | Permanent | Full observability + alerting |

**Environment Naming Convention:**
- Resources: `personal-timeline-{env}-{service}`
- Domains: `{env}.personal-timeline.com` (staging), `personal-timeline.com` (prod)
- Databases: `personal-timeline-{env}`
- Storage: `personal-timeline-{env}-storage`

#### 3.2 Infrastructure as Code (Terraform)

**infra/terraform/modules/networking/main.tf:**
```hcl
# VPC and Networking Module
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name        = "${var.project_name}-${var.environment}-vpc"
    Environment = var.environment
    Project     = var.project_name
  }
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = {
    Name        = "${var.project_name}-${var.environment}-igw"
    Environment = var.environment
  }
}

# Public subnets for load balancers
resource "aws_subnet" "public" {
  count = length(var.availability_zones)

  vpc_id                  = aws_vpc.main.id
  cidr_block              = var.public_subnet_cidrs[count.index]
  availability_zone       = var.availability_zones[count.index]
  map_public_ip_on_launch = true

  tags = {
    Name        = "${var.project_name}-${var.environment}-public-${count.index + 1}"
    Environment = var.environment
    Type        = "public"
  }
}

# Private subnets for application services
resource "aws_subnet" "private" {
  count = length(var.availability_zones)

  vpc_id            = aws_vpc.main.id
  cidr_block        = var.private_subnet_cidrs[count.index]
  availability_zone = var.availability_zones[count.index]

  tags = {
    Name        = "${var.project_name}-${var.environment}-private-${count.index + 1}"
    Environment = var.environment
    Type        = "private"
  }
}

# NAT Gateway for private subnet internet access
resource "aws_eip" "nat" {
  count = var.enable_nat_gateway ? length(var.availability_zones) : 0

  domain = "vpc"
  
  tags = {
    Name        = "${var.project_name}-${var.environment}-nat-eip-${count.index + 1}"
    Environment = var.environment
  }
}

resource "aws_nat_gateway" "main" {
  count = var.enable_nat_gateway ? length(var.availability_zones) : 0

  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id

  tags = {
    Name        = "${var.project_name}-${var.environment}-nat-${count.index + 1}"
    Environment = var.environment
  }

  depends_on = [aws_internet_gateway.main]
}

# Route tables
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  tags = {
    Name        = "${var.project_name}-${var.environment}-public-rt"
    Environment = var.environment
  }
}

resource "aws_route_table" "private" {
  count = length(var.availability_zones)

  vpc_id = aws_vpc.main.id

  dynamic "route" {
    for_each = var.enable_nat_gateway ? [1] : []
    content {
      cidr_block     = "0.0.0.0/0"
      nat_gateway_id = aws_nat_gateway.main[count.index].id
    }
  }

  tags = {
    Name        = "${var.project_name}-${var.environment}-private-rt-${count.index + 1}"
    Environment = var.environment
  }
}

# Route table associations
resource "aws_route_table_association" "public" {
  count = length(aws_subnet.public)

  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

resource "aws_route_table_association" "private" {
  count = length(aws_subnet.private)

  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = aws_route_table.private[count.index].id
}

# Security Groups
resource "aws_security_group" "alb" {
  name_prefix = "${var.project_name}-${var.environment}-alb-"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name        = "${var.project_name}-${var.environment}-alb-sg"
    Environment = var.environment
  }
}

resource "aws_security_group" "app" {
  name_prefix = "${var.project_name}-${var.environment}-app-"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port       = 8000
    to_port         = 8000
    protocol        = "tcp"
    security_groups = [aws_security_group.alb.id]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name        = "${var.project_name}-${var.environment}-app-sg"
    Environment = var.environment
  }
}

resource "aws_security_group" "database" {
  name_prefix = "${var.project_name}-${var.environment}-db-"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [aws_security_group.app.id]
  }

  tags = {
    Name        = "${var.project_name}-${var.environment}-db-sg"
    Environment = var.environment
  }
}
```

**infra/terraform/environments/staging/main.tf:**
```hcl
terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }

  backend "s3" {
    bucket         = "personal-timeline-terraform-state"
    key            = "staging/terraform.tfstate"
    region         = "us-west-2"
    dynamodb_table = "personal-timeline-terraform-locks"
    encrypt        = true
  }
}

provider "aws" {
  region = var.aws_region

  default_tags {
    tags = {
      Project     = "personal-timeline"
      Environment = "staging"
      ManagedBy   = "terraform"
    }
  }
}

# Local variables
locals {
  project_name = "personal-timeline"
  environment  = "staging"
  
  common_tags = {
    Project     = local.project_name
    Environment = local.environment
    ManagedBy   = "terraform"
  }
}

# Networking
module "networking" {
  source = "../../modules/networking"

  project_name       = local.project_name
  environment        = local.environment
  vpc_cidr          = "10.0.0.0/16"
  availability_zones = ["us-west-2a", "us-west-2b"]
  
  public_subnet_cidrs  = ["10.0.1.0/24", "10.0.2.0/24"]
  private_subnet_cidrs = ["10.0.10.0/24", "10.0.20.0/24"]
  
  enable_nat_gateway = true
}

# Compute
module "compute" {
  source = "../../modules/compute"

  project_name = local.project_name
  environment  = local.environment
  
  vpc_id             = module.networking.vpc_id
  private_subnet_ids = module.networking.private_subnet_ids
  public_subnet_ids  = module.networking.public_subnet_ids
  
  app_security_group_id = module.networking.app_security_group_id
  alb_security_group_id = module.networking.alb_security_group_id
  
  # ECS Configuration
  api_image    = var.api_image
  worker_image = var.worker_image
  web_image    = var.web_image
  
  api_cpu    = 512
  api_memory = 1024
  
  worker_cpu    = 1024
  worker_memory = 2048
  
  # Auto Scaling
  api_min_capacity     = 1
  api_max_capacity     = 5
  api_desired_capacity = 2
  
  worker_min_capacity     = 1
  worker_max_capacity     = 3
  worker_desired_capacity = 1
}

# Data
module "data" {
  source = "../../modules/data"

  project_name = local.project_name
  environment  = local.environment
  
  vpc_id                   = module.networking.vpc_id
  private_subnet_ids       = module.networking.private_subnet_ids
  database_security_group_id = module.networking.database_security_group_id
  
  # PostgreSQL Configuration
  postgres_instance_class = "db.t3.micro"
  postgres_allocated_storage = 20
  postgres_max_allocated_storage = 100
  
  # Redis Configuration
  redis_node_type = "cache.t3.micro"
  redis_num_cache_nodes = 1
  
  # S3 Configuration
  s3_bucket_name = "${local.project_name}-${local.environment}-storage"
  
  # Backup Configuration
  backup_retention_period = 7
  backup_window = "03:00-04:00"
  maintenance_window = "sun:04:00-sun:05:00"
}

# Observability
module "observability" {
  source = "../../modules/observability"

  project_name = local.project_name
  environment  = local.environment
  
  # CloudWatch Configuration
  log_retention_in_days = 30
  
  # Alerting Configuration
  alert_email = var.alert_email
  
  # Metrics Configuration
  enable_detailed_monitoring = true
}

# Secrets
module "secrets" {
  source = "../../modules/secrets"

  project_name = local.project_name
  environment  = local.environment
  
  secrets = {
    database_password = {
      description = "PostgreSQL database password"
      generate    = true
    }
    secret_key = {
      description = "Application secret key"
      generate    = true
    }
    openai_api_key = {
      description = "OpenAI API key"
      generate    = false
    }
  }
}
```

**Deliverables:**
- [ ] Terraform modules for networking, compute, data, observability, secrets
- [ ] Environment-specific configurations for staging and production
- [ ] Remote state management with S3 and DynamoDB
- [ ] IAM roles and policies with least privilege
- [ ] Infrastructure provisioning scripts

### Task 4: CI/CD Pipeline Implementation

#### 4.1 GitHub Actions Workflows

**.github/workflows/ci.yml:**
```yaml
name: Continuous Integration

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main, develop]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Code Quality Checks
  lint-and-typecheck:
    name: Lint and Type Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: apps/web/package-lock.json

    - name: Install Python dependencies
      run: |
        cd apps/api
        pip install -r requirements-dev.txt

    - name: Install Node.js dependencies
      run: |
        cd apps/web
        npm ci

    - name: Lint Python code
      run: |
        cd apps/api
        ruff check .
        ruff format --check .

    - name: Type check Python code
      run: |
        cd apps/api
        mypy .

    - name: Lint TypeScript code
      run: |
        cd apps/web
        npm run lint

    - name: Type check TypeScript code
      run: |
        cd apps/web
        npm run typecheck

  # Security Scans
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Gitleaks
      uses: gitleaks/gitleaks-action@v2
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Run Semgrep
      uses: semgrep/semgrep-action@v1
      with:
        config: >-
          p/security-audit
          p/secrets
          p/owasp-top-ten

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  # Unit Tests
  test-api:
    name: Test API
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        cd apps/api
        pip install -r requirements-dev.txt

    - name: Run tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        SECRET_KEY: test-secret-key
      run: |
        cd apps/api
        pytest --cov=. --cov-report=xml --cov-report=html

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: apps/api/coverage.xml
        flags: api
        name: api-coverage

  test-web:
    name: Test Web
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: apps/web/package-lock.json

    - name: Install dependencies
      run: |
        cd apps/web
        npm ci

    - name: Run tests
      run: |
        cd apps/web
        npm run test:coverage

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: apps/web/coverage/lcov.info
        flags: web
        name: web-coverage

  # Build Docker Images
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [lint-and-typecheck, security-scan, test-api, test-web]
    
    strategy:
      matrix:
        service: [api, worker, web]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      if: github.event_name != 'pull_request'
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: apps/${{ matrix.service }}
        target: production
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [build-images]
    if: github.event_name != 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Start test environment
      run: |
        # Use built images for integration tests
        export API_IMAGE=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-api:${{ github.sha }}
        export WORKER_IMAGE=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-worker:${{ github.sha }}
        export WEB_IMAGE=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-web:${{ github.sha }}
        
        docker-compose -f docker-compose.test.yml up -d

    - name: Wait for services
      run: |
        sleep 60
        ./scripts/dev/smoke-test.sh

    - name: Run integration tests
      run: |
        # Run API integration tests
        docker-compose -f docker-compose.test.yml exec -T api pytest tests/integration/
        
        # Run end-to-end tests
        docker-compose -f docker-compose.test.yml exec -T web npm run test:e2e

    - name: Cleanup
      if: always()
      run: |
        docker-compose -f docker-compose.test.yml down -v
```

**.github/workflows/cd.yml:**
```yaml
name: Continuous Deployment

on:
  push:
    branches: [main]
    tags: ['v*']

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
        aws-region: us-west-2

    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.0

    - name: Deploy infrastructure
      run: |
        cd infra/terraform/environments/staging
        terraform init
        terraform plan -var="api_image=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-api:${{ github.sha }}"
        terraform apply -auto-approve -var="api_image=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-api:${{ github.sha }}"

    - name: Run database migrations
      run: |
        # Get ECS cluster and service names from Terraform output
        CLUSTER_NAME=$(cd infra/terraform/environments/staging && terraform output -raw ecs_cluster_name)
        SERVICE_NAME=$(cd infra/terraform/environments/staging && terraform output -raw api_service_name)
        
        # Run migration task
        aws ecs run-task \
          --cluster $CLUSTER_NAME \
          --task-definition personal-timeline-staging-migration \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$(cd infra/terraform/environments/staging && terraform output -raw private_subnet_ids | tr ',' ' ')],securityGroups=[$(cd infra/terraform/environments/staging && terraform output -raw app_security_group_id)]}"

    - name: Run smoke tests
      run: |
        STAGING_URL=$(cd infra/terraform/environments/staging && terraform output -raw application_url)
        curl -f $STAGING_URL/health || exit 1

    - name: Notify deployment
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
      if: always()

  # Deploy to Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    environment: production
    needs: [deploy-staging]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
        aws-region: us-west-2

    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.0

    - name: Deploy infrastructure
      run: |
        cd infra/terraform/environments/production
        terraform init
        terraform plan -var="api_image=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-api:${{ github.sha }}"
        terraform apply -auto-approve -var="api_image=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-api:${{ github.sha }}"

    - name: Run database migrations
      run: |
        # Production migration with extra safety checks
        CLUSTER_NAME=$(cd infra/terraform/environments/production && terraform output -raw ecs_cluster_name)
        
        # Create database backup before migration
        aws rds create-db-snapshot \
          --db-instance-identifier personal-timeline-production \
          --db-snapshot-identifier personal-timeline-production-pre-migration-$(date +%Y%m%d%H%M%S)
        
        # Wait for backup to complete
        aws rds wait db-snapshot-completed \
          --db-snapshot-identifier personal-timeline-production-pre-migration-$(date +%Y%m%d%H%M%S)
        
        # Run migration
        aws ecs run-task \
          --cluster $CLUSTER_NAME \
          --task-definition personal-timeline-production-migration \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$(cd infra/terraform/environments/production && terraform output -raw private_subnet_ids | tr ',' ' ')],securityGroups=[$(cd infra/terraform/environments/production && terraform output -raw app_security_group_id)]}"

    - name: Run production smoke tests
      run: |
        PRODUCTION_URL=$(cd infra/terraform/environments/production && terraform output -raw application_url)
        curl -f $PRODUCTION_URL/health || exit 1
        
        # Additional production-specific tests
        curl -f $PRODUCTION_URL/health/db || exit 1
        curl -f $PRODUCTION_URL/health/redis || exit 1

    - name: Create GitHub release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        draft: false
        prerelease: false

    - name: Notify production deployment
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#production-deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
      if: always()
```

**Deliverables:**
- [ ] Complete CI pipeline with quality gates
- [ ] Automated security scanning
- [ ] Multi-stage Docker image builds
- [ ] Integration test automation
- [ ] Staging auto-deployment
- [ ] Production deployment with approval gates
- [ ] Database migration automation
- [ ] Rollback procedures

### Task 5: Observability Implementation

#### 5.1 Application Monitoring

**Structured Logging Configuration:**

**apps/api/logging_config.py:**
```python
import logging
import json
import sys
from datetime import datetime
from typing import Any, Dict
import uuid
from contextvars import ContextVar

# Context variables for request tracking
request_id_var: ContextVar[str] = ContextVar('request_id', default='')
user_id_var: ContextVar[str] = ContextVar('user_id', default='')

class StructuredFormatter(logging.Formatter):
    """
    Custom formatter for structured JSON logging
    """
    
    def format(self, record: logging.LogRecord) -> str:
        # Base log structure
        log_entry = {
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
        }
        
        # Add request context if available
        request_id = request_id_var.get('')
        if request_id:
            log_entry['request_id'] = request_id
            
        user_id = user_id_var.get('')
        if user_id:
            log_entry['user_id'] = user_id
        
        # Add exception info if present
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
        
        # Add extra fields from record
        for key, value in record.__dict__.items():
            if key not in ['name', 'msg', 'args', 'levelname', 'levelno', 
                          'pathname', 'filename', 'module', 'lineno', 
                          'funcName', 'created', 'msecs', 'relativeCreated', 
                          'thread', 'threadName', 'processName', 'process',
                          'getMessage', 'exc_info', 'exc_text', 'stack_info']:
                log_entry[key] = value
        
        return json.dumps(log_entry, default=str)

def setup_logging(level: str = "INFO", service_name: str = "api") -> None:
    """
    Set up structured logging for the application
    """
    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, level.upper()))
    
    # Remove existing handlers
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # Create console handler with structured formatter
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(StructuredFormatter())
    root_logger.addHandler(console_handler)
    
    # Set service name in all logs
    logging.getLogger().addFilter(lambda record: setattr(record, 'service', service_name) or True)
    
    # Configure specific loggers
    logging.getLogger('uvicorn.access').setLevel(logging.WARNING)
    logging.getLogger('sqlalchemy.engine').setLevel(logging.WARNING)

class RequestLoggingMiddleware:
    """
    Middleware to add request context to logs
    """
    
    def __init__(self, app):
        self.app = app
    
    async def __call__(self, scope, receive, send):
        if scope["type"] == "http":
            # Generate request ID
            request_id = str(uuid.uuid4())
            request_id_var.set(request_id)
            
            # Log request start
            logger = logging.getLogger(__name__)
            logger.info(
                "Request started",
                extra={
                    'method': scope['method'],
                    'path': scope['path'],
                    'query_string': scope.get('query_string', b'').decode(),
                    'client_ip': scope.get('client', ['unknown'])[0],
                    'user_agent': dict(scope.get('headers', [])).get(b'user-agent', b'').decode(),
                }
            )
            
            # Add request ID to response headers
            async def send_wrapper(message):
                if message["type"] == "http.response.start":
                    headers = list(message.get("headers", []))
                    headers.append([b"x-request-id", request_id.encode()])
                    message["headers"] = headers
                await send(message)
            
            await self.app(scope, receive, send_wrapper)
        else:
            await self.app(scope, receive, send)
```

**Metrics Collection:**

**apps/api/metrics.py:**
```python
from prometheus_client import Counter, Histogram, Gauge, generate_latest
import time
from functools import wraps
from typing import Callable, Any
import logging

# Define metrics
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status_code']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint']
)

ACTIVE_CONNECTIONS = Gauge(
    'active_connections',
    'Number of active connections'
)

DATABASE_CONNECTIONS = Gauge(
    'database_connections_active',
    'Number of active database connections'
)

QUEUE_SIZE = Gauge(
    'queue_size',
    'Number of items in processing queue',
    ['queue_name']
)

AI_PROCESSING_DURATION = Histogram(
    'ai_processing_duration_seconds',
    'AI processing duration in seconds',
    ['agent_type', 'operation']
)

AI_TOKEN_USAGE = Counter(
    'ai_tokens_used_total',
    'Total AI tokens used',
    ['provider', 'model']
)

MEMORY_PROCESSING_COUNT = Counter(
    'memory_processing_total',
    'Total memories processed',
    ['source_type', 'status']
)

STORY_GENERATION_COUNT = Counter(
    'story_generation_total',
    'Total stories generated',
    ['story_type', 'status']
)

def track_request_metrics(func: Callable) -> Callable:
    """
    Decorator to track HTTP request metrics
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            result = await func(*args, **kwargs)
            status_code = getattr(result, 'status_code', 200)
            REQUEST_COUNT.labels(
                method=kwargs.get('method', 'unknown'),
                endpoint=kwargs.get('endpoint', 'unknown'),
                status_code=status_code
            ).inc()
            return result
        except Exception as e:
            REQUEST_COUNT.labels(
                method=kwargs.get('method', 'unknown'),
                endpoint=kwargs.get('endpoint', 'unknown'),
                status_code=500
            ).inc()
            raise
        finally:
            REQUEST_DURATION.labels(
                method=kwargs.get('method', 'unknown'),
                endpoint=kwargs.get('endpoint', 'unknown')
            ).observe(time.time() - start_time)
    
    return wrapper

def track_ai_processing(agent_type: str, operation: str):
    """
    Decorator to track AI processing metrics
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            
            try:
                result = await func(*args, **kwargs)
                
                # Track token usage if available in result
                if hasattr(result, 'token_usage'):
                    AI_TOKEN_USAGE.labels(
                        provider=result.token_usage.get('provider', 'unknown'),
                        model=result.token_usage.get('model', 'unknown')
                    ).inc(result.token_usage.get('total_tokens', 0))
                
                return result
            finally:
                AI_PROCESSING_DURATION.labels(
                    agent_type=agent_type,
                    operation=operation
                ).observe(time.time() - start_time)
        
        return wrapper
    return decorator

class MetricsCollector:
    """
    Collect and expose application metrics
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def update_database_connections(self, count: int):
        """Update database connection count"""
        DATABASE_CONNECTIONS.set(count)
    
    def update_queue_size(self, queue_name: str, size: int):
        """Update queue size metric"""
        QUEUE_SIZE.labels(queue_name=queue_name).set(size)
    
    def increment_memory_processing(self, source_type: str, status: str):
        """Increment memory processing counter"""
        MEMORY_PROCESSING_COUNT.labels(
            source_type=source_type,
            status=status
        ).inc()
    
    def increment_story_generation(self, story_type: str, status: str):
        """Increment story generation counter"""
        STORY_GENERATION_COUNT.labels(
            story_type=story_type,
            status=status
        ).inc()
    
    def get_metrics(self) -> str:
        """Get Prometheus metrics in text format"""
        return generate_latest()

# Global metrics collector instance
metrics_collector = MetricsCollector()
```

#### 5.2 Grafana Dashboards

**infra/docker/grafana/provisioning/dashboards/api-overview.json:**
```json
{
  "dashboard": {
    "id": null,
    "title": "Personal Timeline - API Overview",
    "tags": ["personal-timeline", "api"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Request Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m]))",
            "legendFormat": "Requests/sec"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "reqps"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Response Time (95th percentile)",
        "type": "stat",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))",
            "legendFormat": "95th percentile"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "s"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 6, "y": 0}
      },
      {
        "id": 3,
        "title": "Error Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status_code=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) * 100",
            "legendFormat": "Error Rate %"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 12, "y": 0}
      },
      {
        "id": 4,
        "title": "Active Connections",
        "type": "stat",
        "targets": [
          {
            "expr": "active_connections",
            "legendFormat": "Active Connections"
          }
        ],
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 0}
      },
      {
        "id": 5,
        "title": "Request Rate by Endpoint",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m])) by (endpoint)",
            "legendFormat": "{{endpoint}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 6,
        "title": "Response Time Distribution",
        "type": "heatmap",
        "targets": [
          {
            "expr": "sum(rate(http_request_duration_seconds_bucket[5m])) by (le)",
            "format": "heatmap",
            "legendFormat": "{{le}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
      },
      {
        "id": 7,
        "title": "AI Processing Metrics",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(ai_processing_duration_seconds_count[5m])) by (agent_type)",
            "legendFormat": "{{agent_type}} requests/sec"
          },
          {
            "expr": "sum(rate(ai_tokens_used_total[5m])) by (provider)",
            "legendFormat": "{{provider}} tokens/sec"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

#### 5.3 Alerting Configuration

**infra/docker/prometheus/alerts.yml:**
```yaml
groups:
- name: personal-timeline-api
  rules:
  - alert: HighErrorRate
    expr: sum(rate(http_requests_total{status_code=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) > 0.05
    for: 5m
    labels:
      severity: warning
      service: api
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"

  - alert: HighResponseTime
    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 2
    for: 5m
    labels:
      severity: warning
      service: api
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }}s"

  - alert: DatabaseConnectionsHigh
    expr: database_connections_active > 80
    for: 2m
    labels:
      severity: warning
      service: database
    annotations:
      summary: "High database connection usage"
      description: "Database connections are at {{ $value }}"

  - alert: QueueSizeGrowing
    expr: increase(queue_size[10m]) > 100
    for: 5m
    labels:
      severity: warning
      service: worker
    annotations:
      summary: "Queue size growing rapidly"
      description: "Queue {{ $labels.queue_name }} has grown by {{ $value }} items in 10 minutes"

- name: personal-timeline-infrastructure
  rules:
  - alert: HighCPUUsage
    expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
    for: 5m
    labels:
      severity: warning
      service: infrastructure
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
      service: infrastructure
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

  - alert: DiskSpaceLow
    expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
      service: infrastructure
    annotations:
      summary: "Low disk space detected"
      description: "Disk usage is {{ $value }}% on {{ $labels.instance }} {{ $labels.mountpoint }}"
```

**Deliverables:**
- [ ] Structured JSON logging with request correlation
- [ ] Comprehensive Prometheus metrics collection
- [ ] Grafana dashboards for API, worker, and infrastructure monitoring
- [ ] Alert rules for critical system metrics
- [ ] Log aggregation with Loki (optional for local dev)
- [ ] Distributed tracing with OpenTelemetry
- [ ] Performance monitoring and optimization recommendations

---

## Final Deliverables Summary

### 1. Repository & Development Environment
- [ ] Complete monorepo structure with all services
- [ ] Docker Compose setup for local development
- [ ] One-command bootstrap script (`./scripts/dev/bootstrap.sh`)
- [ ] Comprehensive Makefile with all common operations
- [ ] Pre-commit hooks for code quality

### 2. Code Quality & Security
- [ ] Linting and formatting for Python and TypeScript
- [ ] Type checking with MyPy and TypeScript strict mode
- [ ] Security scanning with Trivy, Gitleaks, and Semgrep
- [ ] Test coverage requirements (90% backend, 80% frontend)

### 3. Infrastructure as Code
- [ ] Terraform modules for all AWS resources
- [ ] Environment-specific configurations (staging, production)
- [ ] Remote state management with S3 and DynamoDB
- [ ] IAM roles with least privilege access

### 4. CI/CD Pipeline
- [ ] GitHub Actions workflows for CI and CD
- [ ] Automated testing and security scanning
- [ ] Multi-stage Docker builds with caching
- [ ] Staging auto-deployment and production approval gates
- [ ] Database migration automation

### 5. Observability
- [ ] Structured logging with request correlation
- [ ] Prometheus metrics for golden signals
- [ ] Grafana dashboards for monitoring
- [ ] Alert rules for critical issues
- [ ] Performance monitoring and optimization

### 6. Documentation
- [ ] Complete development setup guide
- [ ] Operational runbooks for common issues
- [ ] Security and secrets management procedures
- [ ] Architecture decision records (ADRs)

---

## Success Validation

To validate successful completion of this epic:

1. **Developer Experience Test**: New team member can run full stack locally in < 30 minutes
2. **CI/CD Test**: Code changes deploy automatically to staging and require approval for production
3. **Monitoring Test**: All dashboards show meaningful data and alerts fire correctly
4. **Security Test**: No secrets in logs, all scans pass, proper access controls in place
5. **Performance Test**: Local environment starts in < 5 minutes, CI completes in < 10 minutes

---

**Epic Owner**: DevOps Engineer  
**Stakeholders**: Development Team, Security Team, Operations Team  
**Dependencies**: None (foundational epic)  
**Risk Level**: Medium (complexity of integration, but well-established patterns)